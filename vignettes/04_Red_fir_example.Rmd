---
title: 'flexsdm: Red Fir example'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{flexsdm: Red Fir example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  #out.width = "100%",
  fig.width = 6,
  fig.height = 6,
  echo = TRUE,
  warning = FALSE,
  eval = T
)
```

```{r dependencies, include = FALSE}
library(devtools)
#devtools::install_github('goldingn/GRaF')
library(GRaF)
library(terra)
library(dplyr)
devtools::load_all()
library(knitr)
```

# Example of full modeling process

## Study species & overview of methods

Here, we used the *flexsdm* package to model the current and future distribution of California red fir (*Abies magnifica*) under two climate change scenarios. Red fir is a high-elevation conifer species that's geographic range extends through the Sierra Nevada in California into the southern portion of the Cascade Range of Oregon. For this species, we used presence-absence data compiled by James Thorne, California Department of Fish and Wildlife, and Calflora. We built the distribution models using four climatic variables: actual evapotranspiration (CFP_1), climatic water deficit (CFP_2), maximum temperature of the warmest month (CFP_3), and minimum temperature of the coldest month (CFP_4). All variables were resampled to a 1890m spatial resolution to improve processing time.

## Occurrence filtering

Sample bias in species occurrence data has long been a recognized issue in SDM. However, environmental filtering of observation data can improve model predictions by reducing climatic redundancy (Varela et al. 2014). Here we will use the function occfilt_env() to thin the red fir presence and absence points based on environmental space. This function is unique to *flexsdm*, as it is able to use any number of environmental dimensions and does not perform a PCA before filtering. In this case, the number of unfiltered records (1266) was reduced to 324 filtered records.

```{r raw data}
somevar <- system.file("external/somevar.tif", package = "flexsdm")
somevar <- terra::rast(somevar) # environmental data
names(somevar) <- c('aet', 'cwd', 'tmx', 'tmn')

regions <- system.file("external/regions.tif", package = "flexsdm")
regions <- terra::rast(regions)

data(abies)
abies_df <- abies %>% select(x, y, pr_ab) %>% dplyr::filter(pr_ab==1)

somevar[[1]] %>% plot()
points(abies_df %>% select(x, y))
```

```{r occurrence filtering}

abies_df$id <- 1:nrow(abies_df) # adding unique id to each row

abies_df2 <- abies_df %>%
  occfilt_env(
    data = .,
    x = 'x',
    y = 'y',
    id = 'id',
    nbins = 8,
    env_layer = somevar,
    cores = 1
  ) %>%
  left_join(abies_df, by = c('id', 'x', 'y'))


somevar[[1]] %>% plot()
points(abies_df2 %>% select('x', 'y'))
```

## Block partition with 4 folds

Data partitioning, or dividing data into model testing and training groups, is a key step in building SDMs. *flexsdm* offers multiple options for data partitioning but here we use a spatial block method. Geographically structured data partitioning methods are especially useful if users want to evaluate model transferability to different regions or time periods. The part_sblock() function explores spatial blocks with different raster cells sizes and returns the one that is best suited for the input datset based on spatial autocorrelation, environmental similarity, and the number of presence/absence records in each block partition. The function's output is also very useful, as it provides users with 1) a tibble with presence/absence locations and the assigned partition number, 2) a tibble with information about the best partition, and 3) a SpatRaster showing the selected grid. Here we want to divide the data into 4 different partitions using the spatial block method.

```{r block partition}
set.seed(10)
occ_part <- abies_df2 %>%
  part_sblock(
    data = .,
    env_layer = somevar,
    pr_ab = 'pr_ab',
    x = 'x',
    y = 'y',
    n_part = 4,
    min_res_mult = 3,
    max_res_mult = 200,
    num_grids = 30,
    prop = 1
  ) 

abies_df2 <- occ_part$part


# Transform best block partition to a raster layer with same resolution and extent than 
# predictor variables 
block_layer <- get_block(env_layer = somevar, best_grid = occ_part$grid)
plot(block_layer)

```

## Pseduo-absence/background points (using partition previously created as a mask)

In this example, we only have presence data. However, most SDM methods require either pseudo-absence or background data. Here, we will use the spatial block partition we just created to generate pseudo-absence and background points.

```{r pseudo/absence and background data}
# Spatial blocks where species occurs
# Sample background points throughout study area with random method
set.seed(10)
bg <- lapply(1:4, function(x) sample_background(
    data = abies_df2,
    x = "x",
    y = "y",
    n = sum(abies_df2$.part==x) * 10,
    method = "random",
    rlayer = block_layer, 
    maskval = x
  )) %>% 
  bind_rows() %>% 
  mutate(pr_ab = 0)

plot(block_layer)
points(bg)

bg <- sdm_extract(data = bg, x='x', y='y', env_layer = block_layer)


# Sampling a number of pseudo-absences equal to the presence in each partition
set.seed(10)
psa <- lapply(1:4, function(x) sample_pseudoabs(
    data = abies_df2,
    x = "x",
    y = "y",
    n = sum(abies_df2$.part==x),
    method = "random",
    rlayer = block_layer, 
    maskval = x
  )) %>% 
  bind_rows() %>% 
  mutate(pr_ab = 0)  

psa <- sdm_extract(data = psa, x='x', y='y', env_layer = block_layer)
  
plot(block_layer)
points(psa)


# Bind a presences and pseudo-absences
abies_df2 <- bind_rows(abies_df2, psa)


abies_df2 # Presence-Pseudo-absence database
bg # Backgroun points

```

```{r extract environmental data for two datasets}

abies_df2 <- abies_df2 %>%
  sdm_extract(
    data = .,
    x = 'x',
    y = 'y',
    env_layer = somevar,
    filter_na = TRUE
  ) 

bg <- bg %>%
  sdm_extract(
    data = .,
    x = 'x',
    y = 'y',
    env_layer = somevar,
    filter_na = TRUE
  ) 

plot(block_layer)
points(occ_part$part[c("x", "y")],
       col = 'black',
       cex = 1,
       pch = 19)

```

## Fit models with tune_max, fit_gau, and third one

Now it's time to fit our models! The *flexsdm* package offers a wide range of modeling options, from traditional statistical methods like GLMs and GAMs, to machine learning methods like random forest and support vector machines. For each modeling method, *flexsdm* provides both fit\_ and tune\_ functions, which allow users to adjust hyperparameters or use default settings depending on their modeling needs. Here, we will test out tune_max() (tuned Maximum Entropy model), fit_gau() (fit Guassian Process model), and fit_glm (fit Generalized Linear Model).

```{r fitting models}
t_1 <- tune_max(
  
)

```

## Create an ensemble

```{r ensemble model}
```

## Project the model

```{r project models}
```

## Constrain it with msdm_posterior

```{r constrain with msdm}
```


## Block partition with 4 folds
Data partitioning, or dividing data into model testing and training groups, is a key step in building SDMs. *flexsdm* offers multiple options for data partitioning but here we use a spatial block method. Geographically structured data partitioning methods are especially useful if users want to evaluate model transferability to different regions or time periods. The part_sblock() function  explores spatial blocks with different raster cells sizes and returns the one that is best suited for the input datset based on spatial autocorrelation, environmental similarity, and the number of presence/absence records in each block partition. The function's output is also very useful, as it provides users with 1) a tibble with presence/absence locations and the assigned partition number, 2) a tibble with information about the best partition, and 3) a SpatRaster showing the selected grid. Here we want to divide the data into 4 different partitions using the spatial block method. 

```{r block partition}
occ_part <- filt %>%
  part_sblock(
    data = .,
    env_layer = somevar,
    pr_ab = 'pr_ab',
    x = 'x',
    y = 'y',
    n_part = 4,
    min_res_mult = 3,
    max_res_mult = 200,
    num_grids = 30,
    prop = 1
  ) 

occ_extract <- occ_part$part %>%
  sdm_extract(
    data = .,
    x = 'x',
    y = 'y',
    env_layer = somevar,
    filter_na = TRUE
  ) # extract variables values, this will be the model dataset


plot(occ_part$grid)
points(occ_part$part[c("x", "y")],
       col = rainbow(5)[occ$part$.part],
       cex = 1,
       pch = 19)
```

## Pseduo-absence/background points (using partition previously created as a mask)
In this example, we only have presence data. However, most SDM methods require either pseudo-absence or background data. Here, we will use the spatial block partition we just created to generate pseudo-absence and background points. 

```{r pseudo/absence and background data}
# Spatial blocks where species occurs
# Sample background points throughout study area with random method

spp_p <- occ_extract %>% dplyr::filter(pr_ab == 1)

bg <-
  sample_background(
    data = spp_p,
    x = "x",
    y = "y",
    n = 1000,
    method = "random",
    rlayer = somevar[[1]]
  )
plot(somevar[[1]])
points(bg)

# Sample random background points constrained to a region with a give set of values
plot(occ_part$grid)
sample_background(
  data = spp_p,
  x = "x",
  y = "y",
  n = 1000,
  method = "random",
  rlayer = occ_part$grid,
  maskval = 1
) %>% points()

plot(grid_env)
sample_background(
  data = spp_p,
  x = "x",
  y = "y",
  n = 500,
  method = "random",
  rlayer = grid_env,
  maskval = 2
) %>% points()

sample_background(
  data = spp_p,
  x = "x",
  y = "y",
  n = 500,
  method = "random",
  rlayer = grid_env,
  maskval = 2
) %>% points()

```


## Fit models with tune_max, fit_gau, and third one
Now it's time to fit our models! The *flexsdm* package offers a wide range of modeling options, from traditional statistical methods like GLMs and GAMs, to machine learning methods like random forest and support vector machines. For each modeling method, *flexsdm* provides both fit_ and tune_ functions, which allow users to adjust hyperparameters or use default settings depending on their modeling needs. Here, we will test out tune_max() (tuned Maximum Entropy model), fit_gau() (fit Guassian Process model), and fit_glm (fit Generalized Linear Model).

```{r fitting models}
t_1 <- tune_max(
  
)

```
## Create an ensemble
```{r ensemble model}
```
## Project the model
```{r project models}
```
## Constrain it with msdm_posterior 
```{r constrain with msdm}
```

