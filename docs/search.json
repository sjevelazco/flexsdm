[{"path":"https://sjevelazco.github.io/flexsdm/articles/pkg_citation.html","id":"cite-our-package-as","dir":"Articles","previous_headings":"","what":"Cite our package as","title":"Where flexsdm was cited?","text":"Velazco, S.J.E., Rose, M.B., Andrade, .F.., Minoli, ., Franklin, J. (2022). flexsdm: R package supporting comprehensive flexible species distribution modelling workflow. Methods Ecology Evolution, 13(8) 1661–1669. https://doi.org/10.1111/2041-210X.13874 Thanks authors citing package.","code":"@article{velazco_flexsdm_2022,     title = {flexsdm: An r package for supporting a comprehensive and flexible species distribution modelling workflow},     volume = {13},     rights = {© 2022 The Authors. Methods in Ecology and Evolution published by John Wiley \\& Sons Ltd on behalf of British Ecological Society.},     issn = {2041-210X},     url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13874},     doi = {10.1111/2041-210X.13874},     pages = {1661--1669},     number = {8},     journaltitle = {Methods in Ecology and Evolution},     author = {Velazco, Santiago José Elías and Rose, Miranda Brooke and de Andrade, André Felipe Alves and Minoli, Ignacio and Franklin, Janet},     date = {2022},     note = {\\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13874} }"},{"path":"https://sjevelazco.github.io/flexsdm/articles/pkg_citation.html","id":"section","dir":"Articles","previous_headings":"","what":"2025","title":"Where flexsdm was cited?","text":"Rahimi, E., Ahmadzadeh, F., 2025. Investigating climate-driven corridor networks Golden Jackal (Canis aureus) Northern Parts Iran. Journal Wildlife Biodiversity 9, 1–16. https://www.wildlife-biodiversity.com/index.php/jwb/article/view/728 Kass, J.M., Smith, .B., Warren, D.L., Vignali, S., Schmitt, S., Aiello‐Lammens, M.E., Arlé, E., Márcia Barbosa, ., Broennimann, O., Cobos, M.E. Guéguen, M., 2025. Achieving higher standards species distribution modeling leveraging diversity available software. Ecography, 2025(2), p.e07346. https://nsojournals.onlinelibrary.wiley.com/doi/full/10.1111/ecog.07346 Hesabi, ., Alavi, S.J. Esmailzadeh, O., 2025. Evaluation accuracy climatic data WorldClim Chelsa databases three northern provinces Iran. Forest Research Development, 11(1), pp.109-132. https://jfrd.urmia.ac.ir/article_121653.html?lang=en Withers, .J., Croft, S., Budgey, R., Warren, D. Johnson, N., 2025. Predicting West Nile Virus risk across Europe current future conditions. bioRxiv, pp.2025-03. https://www.biorxiv.org/content/10.1101/2025.03.04.640552v1.abstract da Mota Porto, .C. Novaes, E., 2025. Prediction current future environmental suitability Toona ciliata cultivation Brazil. Discover Forests, 1(1), pp.1-14. https://link.springer.com/article/10.1007/s44415-025-00029-w Demir, M.. Kabalak, M., 2025. Predicting suitable habitats Alosimus marginicollis (Haag-Rutenberg, 1880)(Coleoptera: Meloidae) evaluating potential distribution relation geographical climatic barriers. Turkish Journal Zoology, 49(2), pp.75-91. https://journals.tubitak.gov.tr/zoology/vol49/iss2/3/ Antonio, .., de Oliveira Junior, .C., Villalobos, F. Velazco, S.J.E., 2025. Environmental heterogeneity determinant bee diversity patterns Atlantic Forest. Frontiers Biogeography, 18, p.e142410. https://doi.org/10.21425/fob.18.142410 Bayraktarov, E., Low-Choy, S., Singh, .R., Beaumont, L.J., Williams, K.J., Baumgartner, J.B., Laffan, S.W., Vasco, D., Cosgrove, R., Wraith, J. Antunes, J.F., 2025. EcoCommons Australia virtual laboratories cloud computing: Meeting diverse user needs ecological modeling decision-making. Environmental Modelling & Software, 183, p.106255. https://www.sciencedirect.com/science/article/pii/S1364815224003165 Rahimi, E. Jung, C., 2025. Mapping co-occurrence dynamics crops honeybees climate change North America. Community Ecology, pp.1-11. https://link.springer.com/article/10.1007/s42974-025-00262-5 Castillo, D.S.C. Higa, M., 2025. Effectiveness implications spatial background restrictions model performance predictions: special reference Rattus species. Landscape Ecological Engineering, pp.1-15. https://link.springer.com/article/10.1007/s11355-025-00653-w Shitara, T., Aihara, T., Momohara, ., Tsuyama, . Matsui, T., 2025. disjunct populations Betula costata Japanese Archipelago glacial relict? attempt verification species distribution modeling. Ecological Research. https://esj-journals.onlinelibrary.wiley.com/doi/abs/10.1111/1440-1703.12541 Somerville, R., MacNeil, C. Lee, F., 2025. Habitat suitability Aotearoa New Zealand recently invaded gold clam (Corbicula fluminea). New Zealand Journal Marine Freshwater Research, 59(4), pp.762-779. https://www.tandfonline.com/doi/abs/10.1080/00288330.2024.2368856 Porto, .C., Santos, M.L., Lima, R.P., Filho, D.S., Souza, .M., da Silva, J.C. de Oliveira, .C., 2025. Modelled potential changes climate-related geographic distribution species Passiflora genus Brazil. Plant Ecology & Diversity, pp.1-14. https://www.tandfonline.com/doi/abs/10.1080/17550874.2025.2505425 Chartois, M., Fried, G. Rossi, J.P., 2025. Climate host plant availability favourable establishment Lycorma delicatula Europe. Agricultural Forest Entomology, 27(2), pp.316-328. https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/afe.12665 Fisher, R. J. (2025). Changes urban landcover picks winners losers non-invasive bird community. Urban Ecosystems, 28(2), 95. https://link.springer.com/article/10.1007/s11252-025-01710-w Rahimi, E. Jung, C., 2025. Investigating Spatial Biases Temporal Trends Insect Pollinator Occurrence Data GBIF. Insects, 16(8), p.769. https://www.mdpi.com/2075-4450/16/8/769 de Brito Reis, K.H., Picanço, M.M., Pereira, P.S., de Souza, H.D.D., de Sá, M.C., Amaro, G.C., da Silva, R.S., Picanço, M.C. Sarmento, R.., 2025. Mapping potential distribution invasion risk Watermelon mosaic virus using MaxEnt ecological niche modeling. Theoretical Applied Climatology, 156(1), p.45. https://link.springer.com/article/10.1007/s00704-024-05289-8 Georgopoulou, E., Kougioumoutzis, K. Simaiakis, S.M., 2025. Impact Climate Land Use Change Greek Centipede Biodiversity Conservation. Land, 14, p1685. https://www.mdpi.com/2073-445X/14/8/1685 Dos Santos, J.C.B., Ramos, R.S., DAS GRAÇAS CARMO, D....N.E., Picanco, M.C., Guedes, E.P., Junior, P..S., Sarmento, R.., De SOUZA RIBAS, N..T.Á.L...X., Correa Amaro, G. Da SILVA, R.S., 2025. Assessing impact climate changes distribution two corn diseases: corn stunt corn reddening. Canadian Journal Plant Pathology, pp.1-20. https://www.tandfonline.com/doi/abs/10.1080/07060661.2025.2533964 Withers, .J., Croft, S., Budgey, R., Warren, D.. Johnson, N., 2025. Modelling vector host distributions inform potential disease risk: case study West Nile virus United Kingdom. Medical Veterinary Entomology. https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/mve.12825 Rahimi, E. Jung, C., 2025. Exploring Climate-Driven Mismatches Pollinator-Dependent Crops Honeybees Asia. Biology, 14(3), p.234. https://www.mdpi.com/2079-7737/14/3/234 Patron-Rivero, C., Yañez-Arenas, C., Chiappa-Carrara, X., Rojas-Soto, O., Ruane, S. Guevara, L., 2025. Ecological biogeographic drivers speciation neotropical hognose pit vipers, Porthidium (Squamata, Viperidae). Zoologischer Anzeiger. https://www.sciencedirect.com/science/article/pii/S004452312500083X Ramírez‐Arce, D.G., Ochoa‐Ochoa, L.M., Lira‐Noriega, . Martorell, C., 2025. Reptile Diversity Patterns Climate Land Use Change Scenarios Subtropical Montane Landscape Mexico. Journal Biogeography, 52(1), pp.108-121. https://onlinelibrary.wiley.com/doi/abs/10.1111/jbi.15017 Gehman, C.S. Gienger, C.M., 2025. Predicting potential distribution Gila Monster evaluating extent protected natural areas conservation. Journal Nature Conservation, 86, p.126944. https://www.sciencedirect.com/science/article/pii/S1617138125001219 Lin, Y., Liu, Q., Lv, S., Huang, X., Wei, C., Li, J., Guan, Y., Pan, Y., Mi, Y., Cheng, Y. Yang, X., 2025. Assessing Potential Distribution Traditional Chinese Medicinal Plant Spatholobus suberectus China Climate Change: Biomod2 Ensemble Model-Based Study. Biology, 14(8), p.1071. https://www.mdpi.com/2079-7737/14/8/1071 Kougioumoutzis, K., Kokkoris, .P., Trigas, P., Strid, . Dimopoulos, P., 2025. Projected Impacts Climate Land Use Change Endemic Plant Distributions Mediterranean Island Hotspot: Case Evvia (Aegean, Greece). Climate, 13(5), p.100. https://www.mdpi.com/2225-1154/13/5/100 Bro-Jørgensen, J., Ikram, S., Spedding, J.V., Thomas, C.D., Snape, S., Nilsson, M. Lazagabaster, .., 2025. Applying habitat suitability modelling establish species identity ambiguous animal depictions archaeology: new insights wild bovids ancient Egypt. Journal archaeological science, 179, p.106239. https://www.sciencedirect.com/science/article/pii/S0305440325000883 Holcomb, K.M., Foster, E., Maes, S.E., Parise, C.M., Osikowicz, L.M., Hojgaard, . Eisen, R.J., 2025. Estimated density Borrelia burgdorferi sensu stricto-infected Ixodes scapularis nymphs eastern United States. Parasites & Vectors, 18(1), p.350. https://link.springer.com/article/10.1186/s13071-025-06937-2 Alves‐Ferreira, G., Vancine, M.H., Mota, F.M.M., Bello, C., Sobral‐Souza, T., Percequillo, .R., Lacher Jr, T.E., Galetti, M. Bovendorp, R.S., 2025. Hot Cold Spots: Climate Change Projected Modify Diversity Patterns Small Mammals Biodiversity Hotspot. Diversity Distributions, 31(5), p.e70026. https://onlinelibrary.wiley.com/doi/abs/10.1111/ddi.70026 Holcomb, K.M., Foster, E. Eisen, R.J., 2025. Estimating density questing Ixodes scapularis nymphs eastern United States using climate land cover data. Ticks Tick-borne Diseases, 16(2), p.102446. https://www.sciencedirect.com/science/article/pii/S1877959X2500010X Duyar, ., Demir, M.. Kabalak, M., 2025. Prediction current future distributions chalcophora detrita (coleoptera: buprestidae) climate change scenarios. Ecology Evolution, 15(1), p.e70693. https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.70693 Cheng, H., Johansen, K., Jin, B., Xu, S., Zhao, X., Han, L. McCabe, M.F., 2025. Human footprint machine learning identifies risks invasive weed Conyza sumatrensis across land-use types climate change. Global Ecology Conservation, p.e03657. https://www.sciencedirect.com/science/article/pii/S2351989425002586 Stefanidis, ., Kougioumoutzis, K., Zografou, K., Fotiadis, G., Willemse, L., Tzortzakaki, O. Kati, V., 2025. Distribution patterns habitat preferences five globally threatened endemic montane Orthoptera (Parnassiana Oropodisma). Ecologies, 6(1), p.5. https://www.mdpi.com/2673-4133/6/1/5 Backus, G.., Rose, M.B., Velazco, S.J., Franklin, J., Syphard, .D. Regan, H.M., 2025. Population Decline Plants California Floristic Province: Demography Geography Determine Climate Change Vulnerability?. Diversity Distributions, 31(8), p.e70067. https://onlinelibrary.wiley.com/doi/abs/10.1111/ddi.70067 Hubbard, J.., Andrew R. Drake, D. Mandrak, N.E., 2025. ‘Euclimatch’: R package climate matching Euclidean distance metrics. Ecography, 2025(4), p.e07614. https://nsojournals.onlinelibrary.wiley.com/doi/abs/10.1111/ecog.07614 Stefanidis, ., Kougioumoutzis, K., Zografou, K., Fotiadis, G., Tzortzakaki, O., Willemse, L. Kati, V., 2025. Mitigating extinction risk globally threatened endemic mountainous Orthoptera species: Parnassiana parnassica Oropodisma parnassica. Insect Conservation Diversity, 18(1), pp.54-68. https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/icad.12784 Noel, ., Schlaepfer, D.R., Butterfield, B.J., Swan, M.C., Norris, J., Hartwig, K., Duniway, M.C. Bradford, J.B., 2025. Pinyon–Juniper Woodland Species Distributions Projected Shrink Rather Shift Climate Change. Rangeland Ecology & Management, 98, pp.454-466. https://www.sciencedirect.com/science/article/pii/S1550742424001659 de Oliveira Junior, .C. Velazco, S.J.E., 2025. adm: R package constructing abundance‐based species distribution models. Methods Ecology Evolution. https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.70074 Fonteyn, W., Serra‐Diaz, J.M., Muys, B. Van Meerbeek, K., 2025. Incorporating climatic extremes using GEV distribution improves SDM range edge performance. Journal Biogeography, 52(3), pp.780-791. https://onlinelibrary.wiley.com/doi/abs/10.1111/jbi.15067 Harapan, T.S., Ong, L., Agung, .P., Rafia, R., Tjong, D.H., Novarino, W. Campos‐Arceiz, ., 2025. Slow Underappreciated Forest Megafauna: Food Habits, Movements, Multiscale Habitat Preferences Critically Endangered Sundaic Giant Tortoises (Manouria emys emys). Integrative Zoology. https://onlinelibrary.wiley.com/doi/abs/10.1111/1749-4877.12965 Rossi, J.P., Battisti, ., Avtzis, D.N., Burban, C., Rahim, N., Rousselet, J., Kerdelhué, C. ̇pekdal, K., 2025. Warmer brighter winters : Ecological public health challenges expansion pine processionary moth (Thaumetopoea pityocampa). Science Total Environment, 978, p.179470. https://www.sciencedirect.com/science/article/pii/S0048969725011076 Zhang, Z., Kass, J.M., Bede‐Fazekas, Á., Mammola, S., Qu, J., Molinos, J.G., Gu, J., Huang, H., Qu, M., Yue, Y. Qin, G., 2025. Differences predictions marine species distribution models based expert maps opportunistic occurrences. Conservation Biology, p.e70015. https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/cobi.70015 Rey Pullido, K.G. Velazco, S.J.E. protected areas effective area-based conservation measures conserve biodiversity. Exploring contribution Colombian snakes. Perspective Ecology Conservation, 23(2), pp.110-120. https://www.sciencedirect.com/science/article/pii/S2530064425000173?via%3Dihub Aidoo, O.F., Amaro, G.C., Souza, P.G.C., Picanço, M.C., Awuah‐Mensah, K.. Silva, R.S.D., 2025. Climate change impacts worldwide ecological niche invasive potential Sternochetus mangiferae. Pest Management Science, 81(2), pp.667-677. https://scijournals.onlinelibrary.wiley.com/doi/abs/10.1002/ps.8465","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/pkg_citation.html","id":"section-1","dir":"Articles","previous_headings":"","what":"2024","title":"Where flexsdm was cited?","text":"Kougioumoutzis, K., Tsakiri, M., Kokkoris, .P., Trigas, P., Iatrou, G., Lamari, F.N., Tzanoudakis, D., Koumoutsou, E., Dimopoulos, P., Strid, ., Panitsa, M., (2024). Assessing vulnerability medicinal aromatic plants climate land-use changes Mediterranean biodiversity hotspot. Land, 13(2), 133. https://doi.org/10.3390/land13020133 Rodriguez, C.S., Rose, M.B., Velazco, S.J.E., Franklin, J., & Larios, L., (2024). High potential Brassica tournefortii spread North American introduced range, despite highly conserved niche. Biological Invasions, 26(1), 337-351. https://doi.org/10.1007/s10530-023-03176-3 Chartois, M., Fried, G. & Rossi, J.-P. (2024) Climate host plant availability favourable establishment Lycorma delicatula Europe. Agricultural Forest Entomology, 1–13. Available : https://doi.org/10.1111/afe.12665 Syphard, . D., Velazco, S. J. E., Rose, M. B., Franklin, J., & Regan, H. M. (2024). importance geography forecasting future fire patterns climate change. Proceedings National Academy Sciences, 121(32), e2310076121. https://doi.org/10.1073/pnas.2310076121 Rose, M. B., Velazco, S. J. E., Regan, H. M., Flint, . L., Flint, L. E., Thorne, J. H., & Franklin, J. (2024). Uncertainty consensus predictions plant species’ vulnerability climate change. Diversity Distributions, 30(8), e13898. https://doi.org/10.1111/ddi.13898 Aidoo, O.F., Amaro, G.C., Souza, P.G.C., Picanço, M.C., Awuah-Mensah, K.. & Silva, R.S.d. (2024), Climate change impacts worldwide ecological niche invasive potential Sternochetus mangiferae. Pest Management Science, https://doi.org/10.1002/ps.8465 Pires, M. B., Kougioumoutzis, K., Norder, S., Dimopoulos, P., Strid, ., & Panitsa, M. (2024). future plant diversity within Mediterranean endemism centre: Modelling synergistic effects climate land-use change Peloponnese, Greece. Science Total Environment, 947, 174622.https://doi.org/10.1016/j.scitotenv.2024.174622 Noel, ., Schlaepfer, D.R., Butterfield, B.J., Swan, M.C., Norris, J., Hartwig, K., Duniway, M.C. & Bradford, J.B. (2024). Pinyon–Juniper Woodland Species Distributions Projected Shrink Rather Shift Climate Change. Rangeland Ecology & Management, https://doi.org/10.1016/j.rama.2024.09.002 Stefanidis, ., Kougioumoutzis, K., Zografou, K., Fotiadis, G., Tzortzakaki, O., Willemse, L. & Kati, V., (2024) Mitigating extinction risk globally threatened endemic mountainous Orthoptera species: Parnassiana parnassica Oropodisma parnassica. Insect Conservation Diversity, 1–15. Available : https://doi.org/10.1111/icad.12784 Rahimi E, Jung C. (2024) New SDM-Based Approach Assessing Climate Change Effects Plant–Pollinator Networks. Insects, 15(11):842. https://doi.org/10.3390/insects15110842 Rahimi, E., Dong, P. & Ahmadzadeh, F. (2024). Assessing climate niche similarity persian fallow deer (Dama mesopotamica) areas Iran. BMC Ecology Evolution, 24(1), 93. https://doi.org/10.1186/s12862-024-02281-8 Ramírez‐Arce, D. G., Ochoa‐Ochoa, L. M., Lira‐Noriega, ., & Martorell, C. (2024). Reptile Diversity Patterns Climate Land Use Change Scenarios Subtropical Montane Landscape Mexico. Journal Biogeography, https://doi.org/10.1111/jbi.15017 Rahimi, E., & Jung, C. (2024). Global trends climate suitability bees: Ups downs warming world. Insects, 15(2), 127. https://doi.org/10.3390/insects15020127 Lazagabaster, . ., Thomas, C. D., Spedding, J. V., Ikram, S., Solano‐Regadera, ., Snape, S., & Bro‐Jørgensen, J. (2024). Evaluating species distribution model predictions time paleozoological records. Ecology evolution, 14(10), e70288. https://doi.org/10.1002/ece3.70288 Habibi, ., Achour, H., Bounaceur, F., Benaradj, ., & Aulagnier, S. (2024). Predicting future distribution Barbary ground squirrel (Atlantoxerus getulus) climate change using niche overlap analysis species distribution modeling. Environmental Monitoring Assessment, 196(11), 1-18. https://doi.org/10.1007/s10661-024-13350-2 Nelson, D. L., Marneweck, C. J., McShea, W. J., Shamon, H., & Jachowski, D. S. (2024). Predicted future range expansion small carnivore: swift fox North America. Landscape Ecology, 39(9), 164. https://doi.org/10.1007/s10980-024-01962-5 Rahimi, E., & Jung, C. (2024). Global Estimation Potential Climate Change Effects Pollinator-Dependent Crops. Agricultural Research, 1-11. https://doi.org/10.1007/s40003-024-00802-x Rahimi, E., Dong, P., Ahmadzadeh, F., & Jung, C. (2024). Assessing climate change threats biodiversity protected areas Iran. European Journal Wildlife Research, 70(5), 1-11. https://doi.org/10.1007/s10344-024-01842-y , J., Lu, L., , H., Zhang, Z., Hao, M., Zhang, C., Zhao, X. & von Gadow, K. (2024). Estimating dynamics ecosystem functions climate change temperate forest region. Ecological Indicators, 166, 112353. https://doi.org/10.1016/j.ecolind.2024.112353 Nieto‐Lugilde, M., Nieto‐Lugilde, D., Piatkowski, B., Duffy, .M., Robinson, S.C., Aguero, B., Schuette, S., Wilkens, R., Yavitt, J. & Shaw, .J.(2024). Ecological differentiation sympatry cryptic species Sphagnum magellanicum complex (Bryophyta). American Journal Botany, e16401. https://doi.org/10.1002/ajb2.16401 Serra‐Diaz, J.M., Borderieux, J., Maitner, B., Boonman, C.C., Park, D., Guo, W.Y., Callebaut, ., Enquist, B.J., Svenning, J.C. & Merow, C. (2024). occTest: integrated approach quality control species occurrence data. Global Ecology Biogeography, e13847. https://doi.org/10.1111/geb.13847 Bayraktarov, E., Low-Choy, S., Singh, .R., Beaumont, L.J., Williams, K.J., Baumgartner, J., Laffan, S.W., Vasco, D., Cosgrove, R., Wraith, J. & Antunes, J.F. (2024). EcoCommons Australia Virtual Laboratories Cloud Computing: Meeting Diverse User Needs Ecological Modeling Decision-making. Environmental Modelling & Software, 106255. https://doi.org/10.1016/j.envsoft.2024.106255 Lamboley, Q., & Fourcade, Y. (2024). optimal spatial filtering distance mitigating sampling bias ecological niche models. Journal Biogeography, 51, 1783–1794. https://doi.org/10.1111/jbi.14854 Delle Monache, D., Martino, G., Chiocchio, ., Siclari, ., Bisconti, R., Maiorano, L., & Canestrelli, D. (2024). Mapping local climates highly heterogeneous mountain regions: Interpolation meteorological station data vs. downscaling macroclimate grids. Ecological Informatics, 102674. https://doi.org/10.1016/j.ecoinf.2024.102674 Rahimi, E., & Jung, C. (2024). Identifying pollinator‐friendly sites within urban green spaces sustainable urban agriculture. Journal Sustainable Agriculture Environment, 3(3), e12109. https://doi.org/10.1002/sae2.12109 Vélez, D., & Vivallo, F. (2024). Key areas conserving sustainably using oil-collecting bees (Apidae: Centridini, Tapinotaspidini, Tetrapediini) Americas. Journal Insect Conservation, 1-17. https://doi.org/10.1007/s10841-024-00620-0 Ninsin, K.D., Souza, P.G.C., Amaro, G.C., Aidoo, O.F., Barry, E.J.D.V., da Silva, R.S., Osei-Owusu, J., Dofuor, .K., Ablormeti, F.K., Heve, W.K. & Edusei, G., (2024). Risk spread Asian citrus psyllid Diaphorina citri Kuwayama (Hemiptera: Liviidae) Ghana. Bulletin Entomological Research, 1-20. https://doi.org/10.1017/S0007485324000105 Buebos-Esteve, D. E., Redeña-Santos, J. C., & Dagamac, N. H. . (2024). Ensemble modeling identify high conservation value areas endemic elusive large-sized mammals Philippines. Journal Nature Conservation, 126657. https://doi.org/10.1016/j.jnc.2024.126657 Esparza-Orozco, ., & Lira-Noriega, . (2024). Use secondary diversity data improve diversity estimates multiple geographic scales. Biodiversity Conservation, 1-18. https://doi.org/10.1007/s10531-024-02844-7 Gandaho, S. M., Sogbohossou, E. ., & Thompson, L. J. (2024). NIMO: graphical user interface‐based R package species distribution modelling. Ecological Solutions Evidence, 5(3), e12385. https://doi.org/10.1002/2688-8319.12385 Kougioumoutzis, K., Constantinou, ., & Panitsa, M. (2024). Rising Temperatures, Falling Leaves: Predicting Fate Cyprus’s Endemic Oak Climate Land Use Change. Plants, 13(8), 1109. https://doi.org/10.3390/plants13081109 Somerville, R., MacNeil, C., & Lee, F. (2024). Habitat suitability Aotearoa New Zealand recently invaded gold clam (Corbicula fluminea). New Zealand Journal Marine Freshwater Research, 1-18. https://doi.org/10.1080/00288330.2024.2368856 Marom, N., Peretz, . O., Lazagabaster, . ., Meiri, M., & Meiri, S. (2024). Water voles Lake Hula: assessing past, present, future. European Journal Wildlife Research, 70(2), 34. https://doi.org/10.1007/s10344-024-01781-8 Rahimi, E., & Jung, C. (2024). global evaluation urban agriculture potential pollinator‐dependent crops major cities. Urban Agriculture & Regional Food Systems, 9(1), e20058. https://doi.org/10.1002/uar2.20058 Castillo, D. S. C., & Higa, M. (2024). Strengthening ecologically based rodent management Philippines using maximum entropy (MaxEnt) predictions. Journal Tropical Ecology, 40, e19. https://doi.org/10.1017/S0266467424000208 Tytar, V., Kozynenko, ., & Navakatikyan, M. (2024). Modelling distribution proboscis monkey (Nasalis larvatus) Sabah (Borneo) based remotely sensed high-resolution global cloud dynamics. Theriologia Ukrainica, 27, 103-111. http://doi.org/10.53452/TU2711","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/pkg_citation.html","id":"section-2","dir":"Articles","previous_headings":"","what":"2023","title":"Where flexsdm was cited?","text":"Velazco, S. J. E., Brooke, M. R., De Marco Jr., P., Regan, H. M., & Franklin, J. (2023). far can extrapolate species distribution model? Exploring Shape, novel method. Ecography, e06992. https://doi.org/10.1111/ecog.06992 Sillero, N., Campos, J. C., Arenas-Castro, S., & Barbosa, . (2023). curated list R packages ecological niche modelling. Ecological Modelling, 476, 110242. https://doi.org/10.1016/j.ecolmodel.2022.110242 Rose, M. B., Elías Velazco, S. J., Regan, H. M., & Franklin, J. (2023). Rarity, geography, plant exposure global change California Floristic Province. Global Ecology Biogeography, 32(2), 218-232. https://doi.org/10.1111/geb.13618 Franklin, J. (2023). Species distribution modelling supports study past, present future biogeographies. Journal Biogeography, 50(9), 1533-1545. https://doi.org/10.1111/jbi.14617 Amaro, G., Fidelis, E. G., Da Silva, R. S., & Marchioro, C. . (2023). Effect study area extent potential distribution Species: case study models Raoiella indica Hirst (Acari: Tenuipalpidae). Ecological Modelling, 483, 110454. https://doi.org/10.1016/j.ecolmodel.2023.110454 Moura, M. R., Oliveira, G. ., Paglia, . P., Pires, M. M., & Santos, B. . (2023). Climate change drive mammal defaunation tropical dry forests. Global Change Biology, 29(24), 6931-6944. https://doi.org/10.1111/gcb.16979 Da Silva, J. P., Sousa, R., Gonçalves, D. V., Miranda, R., Reis, J., Teixeira, ., Varandas, S., Lopes-Lima, M., & Filipe, . F. (2023). Streams Mediterranean Region mussels: Predicting extinctions range contractions future climate change. Science Total Environment, 883, 163689. https://doi.org/10.1016/j.scitotenv.2023.163689 Du, Y., Jueterbock, ., Firdaus, M., Hurtado, . Q., & Duan, D. (2023). Niche comparison range shifts two Kappaphycus species Indo-Pacific Ocean climate change. Ecological Indicators, 154, 110900. https://doi.org/10.1016/j.ecolind.2023.110900 Mathias, S., Jarvie, S., & Larcombe, M. J. (2023). Range reshuffling: Climate change, invasive species, case Nothofagus forests Aotearoa New Zealand. Diversity Distributions, 29(11), 1402-1419. https://doi.org/10.1111/ddi.13767 Petersen, W. J., & Savini, T. (2023). Lowland forest loss climate-species distribution models exaggerate forest-dependent species’ vulnerability climate change. Ecological Informatics, 78, 102327. https://doi.org/10.1016/j.ecoinf.2023.102327 Kokkoris, . P., Kougioumoutzis, K., Charalampopoulos, ., Apostolidis, E., Apostolidis, ., Strid, ., & Dimopoulos, P. (2023). Conservation Responsibility Priority Habitats Future Climate Conditions: Case Study Juniperus drupacea Forests Greece. Land, 12(11), 1976. https://doi.org/10.3390/land12111976 Wang, X., Xu, Q., & Liu, J. (2023). Determining representative pseudo-absences invasive plant distribution modeling based geographic similarity. Frontiers Ecology Evolution, 11, 1193602. https://doi.org/10.3389/fevo.2023.1193602 Tytar, V., Nekrasova, O., Pupins, M., Skute, ., Kirjušina, M., Gravele, E., Mezaraupe, L., Marushchak, O., Čeirāns, ., Kozynenko, ., & Kulikova, . . (2023). Modeling Distribution Chytrid Fungus Batrachochytrium dendrobatidis Special Reference Ukraine. Journal Fungi, 9(6), 607. https://doi.org/10.3390/jof9060607 Moura, M. R., Paolucci, L. N., Silva, D. P., & Santos, B. . (2023). Pervasive impacts climate change woodiness ecological generalism dry forest plant assemblages. Journal Ecology, 111(8), 1762-1776. https://doi.org/10.1111/1365-2745.14139 Zhang, X., Huang, Q., Liu, P., Sun, C., Papa, R. D., Sanoamuang, L., Dumont, H. J., & Han, B. (2023). Geography, ecology, history synergistically shape across-range genetic variation calanoid copepod endemic north-eastern Oriental. Evolution, 77(2), 422-436. https://doi.org/10.1093/evolut/qpac043","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/pkg_citation.html","id":"section-3","dir":"Articles","previous_headings":"","what":"2022","title":"Where flexsdm was cited?","text":"Wen, C., Cha, J., Xu, L., Xu, H. Spatial Potential Recreational Services Western Hubei Region Light “--One Tourism” Development—Machine Learning Approach Based Ensemble Model. (2022) Landscape Architecture Frontiers, 10(5): 8‒31 https://doi.org/10.15302/J-LAF-1-020073","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"flexsdm: Overview of Pre-modeling functions","text":"Species distribution modeling (SDM) become standard tool many research areas, including ecology, conservation biology, biogeography, paleobiogeography, epidemiology. SDM active area theoretical methodological research. flexsdm package provides users ability manipulate parameterize models variety ways meet unique research needs. flexibility enables users define complete partial modeling procedure specific modeling situation (e.g., number variables, number records, different algorithms ensemble methods, algorithms tuning, etc.). vignette, users learn first set functions flexsdm package fall “pre-modeling” umbrella (see full list). pre-modeling functions calib_area() Delimit calibration area constructing species distribution models correct_colinvar() Collinearity reduction predictors env_outliers() Integration outliers detection methods environmental space part_random() Data partitioning training testing models part_sblock() Spatial block cross-validation part_sband() Spatial band cross-validation part_senv() Environmental cross-validation plot_res() Plot different resolutions used part_sblock get_block() Transform spatial partition layer spatial properties environmental variables sample_background() Sample background points sample_pseudoabs() Sample pseudo-absence sdm_directory() Create directories saving outputs flexsdm sdm_extract() Extract environmental data based x y coordinates occfilt_env() Perform environmental filtering species occurrences occfilt_geo() Perform geographical filtering species occurrences","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"flexsdm: Overview of Pre-modeling functions","text":"First, install flexsdm package. can install released version flexsdm github :","code":"# devtools::install_github('sjevelazco/flexsdm') library(flexsdm) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(terra) #> terra 1.8.60 #>  #> Attaching package: 'terra' #> The following object is masked from 'package:knitr': #>  #>     spin library(ggplot2)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"project-directory-setup","dir":"Articles","previous_headings":"","what":"Project Directory Setup","title":"flexsdm: Overview of Pre-modeling functions","text":"building SDM’s, organizing folders (directories) project save time confusion. project directory main project folder store relevant data results current project. Now, let’s create project directory initial data model results stored. function sdm_directory() can , based types model algorithms want use /types projections like make. First decide computer like store inputs outputs project (main directory) use dir.create() create main directory. Next, specify whether want include folders projections, calibration areas, algorithms, ensembles, thresholds.","code":"my_project <- file.path(file.path(tempdir(), \"flex_sdm_project\")) dir.create(my_project)  project_directory <- sdm_directory(   main_dir = my_project,   projections = NULL,   calibration_area = TRUE,   algorithm = c(\"fit_max\", \"tune_raf\"),   ensemble = c(\"mean\"),   threshold = TRUE,   return_vector = TRUE )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"data-species-occurrence-and-background-data","dir":"Articles","previous_headings":"","what":"Data, species occurrence and background data","title":"flexsdm: Overview of Pre-modeling functions","text":"tutorial, using species occurrences available flexsdm package. “spp” example dataset includes pr_ab column (presence = 1, absence = 0), location columns (x, y). can load “spp” data local R environment using code :","code":"data(\"spp\")  spp #> # A tibble: 1,150 × 4 #>    species        x        y pr_ab #>    <chr>      <dbl>    <dbl> <dbl> #>  1 sp1       -5541. -145138.     0 #>  2 sp1      -51981.   16322.     0 #>  3 sp1     -269871.   69512.     1 #>  4 sp1      -96261.  -32008.     0 #>  5 sp1      269589. -566338.     0 #>  6 sp1       29829. -328468.     0 #>  7 sp1     -152691.  393782.     0 #>  8 sp1     -195081.  253652.     0 #>  9 sp1        -951. -277978.     0 #> 10 sp1      145929. -271498.     0 #> # ℹ 1,140 more rows"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"geographic-region","dir":"Articles","previous_headings":"","what":"Geographic region","title":"flexsdm: Overview of Pre-modeling functions","text":"species occurrences located California Floristic Province (far western USA). “regions” dataset can used visualize study area geographic space. points distributed across study area?","code":"regions <- system.file(\"external/regions.tif\", package = \"flexsdm\") regions <- terra::rast(regions) try(plot(regions), silent = TRUE) points(spp[, 2:3], pch = 19, cex = 0.5, col = as.factor(spp$species))"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"calibration-area","dir":"Articles","previous_headings":"","what":"Calibration area","title":"flexsdm: Overview of Pre-modeling functions","text":"important decision SDM delimit model’s calibration area, geographic space use train model(s). Choice calibration area affects modeling steps, including sampling pseudo-absence background points, performance metrics, geographic patterns habitat suitability. want train SDM using entire extent United States interested geographic distribution environmental controls rare plant species found mountaintops Sierra Nevada, California! Let’s use presence locations one species exercise. calib_area() function offers three methods defining calibration area: buffer, mcp, bmcp, mask. briefly go .","code":"spp1 <-   spp %>%   dplyr::filter(species == \"sp1\") %>%   dplyr::filter(pr_ab == 1) %>%   dplyr::select(-pr_ab)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"buffer","dir":"Articles","previous_headings":"Calibration area","what":"1. Buffer","title":"flexsdm: Overview of Pre-modeling functions","text":"calibration area defined using buffers around presence points. User’s can specify distance around points using “width” argument. buffer width value interpreted m CRS longitude/latitude, map units cases.","code":"crs(regions, proj = TRUE) #> [1] \"+proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs\"  ca_1 <- calib_area(   data = spp1,   x = \"x\",   y = \"y\",   method = c(\"buffer\", width = 40000),   crs = crs(regions) ) plot(regions, main = \"Buffer method\") plot(ca_1, add = TRUE) points(spp1[, 2:3], pch = 19, cex = 0.5)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"minimum-convex-polygon","dir":"Articles","previous_headings":"Calibration area","what":"2. Minimum convex polygon","title":"flexsdm: Overview of Pre-modeling functions","text":"minimum convex polygon (mcp) method produces much simpler shape.","code":"ca_2 <- calib_area(   data = spp1,   x = \"x\",   y = \"y\",   method = c(\"mcp\"),   crs = crs(regions) )  plot(regions, main = \"Minimum convex polygon method\") plot(ca_2, add = TRUE) points(spp1[, 2:3], pch = 19, cex = 0.5)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"buffered-minimum-convex-polygon","dir":"Articles","previous_headings":"Calibration area","what":"3. Buffered minimum convex polygon","title":"flexsdm: Overview of Pre-modeling functions","text":"can also create buffer around minimum convex polygon.","code":"ca_3 <- calib_area(   data = spp1,   x = \"x\",   y = \"y\",   method = c(\"bmcp\", width = 40000),   crs = crs(regions) )  plot(regions, main = \"Buffered minimum convex polygon\") plot(ca_3, add = TRUE) points(spp1[, 2:3], pch = 19, cex = 0.5)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"mask","dir":"Articles","previous_headings":"Calibration area","what":"4. Mask","title":"flexsdm: Overview of Pre-modeling functions","text":"mask method allows polygons selected intersect species locations delineate calibration area. useful expect species distributions associated ecologically significant (mapped) ecoregions, interested distributions within political boundaries. use random set polygons named “clusters” illustrate mask method. original polygons left polygons contain points (“mask” calibration area) right.","code":"clusters <- system.file(\"external/clusters.shp\", package = \"flexsdm\") clusters <- terra::vect(clusters)  ca_4 <- calib_area(   data = spp1,   x = \"x\",   y = \"y\",   method = c(\"mask\", clusters, \"clusters\"),   crs = crs(regions) )  par(mfrow = c(1, 2)) plot(clusters, main = \"Original polygons\") plot(ca_4, main = \"Polygons with points (mask)\") points(spp1[, 2:3], pch = 19, cex = 0.5)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"reducing-collinearity-among-the-predictors","dir":"Articles","previous_headings":"","what":"Reducing collinearity among the predictors","title":"flexsdm: Overview of Pre-modeling functions","text":"Predictor collinearity common issue SDMs, can lead model overfitting inaccurate tests significance predictors (De Marco & Nóbrega, 2018; Dormann et al., 2013).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"environmental-predictors","dir":"Articles","previous_headings":"Reducing collinearity among the predictors","what":"Environmental predictors","title":"flexsdm: Overview of Pre-modeling functions","text":"use four climatic variables available flexsdm package: actual evapotranspiration (CFP_1), climatic water deficit (CFP_2), maximum temperature warmest month (CFP_3), minimum temperature coldest month (CFP_4).  relationship different environmental variables can visualized pairs() function terra package. Several variables highly correlated (.89 predictors tmx tmn).  can correct reduce collinearity? function correct_colinvar() four methods deal collinearity: pearson, vif, pca, fa. method returns 1) raster object (SpatRaster) selected predictors 2) useful outputs relevant method. functions used supplementary tools, predictor selection SDMs complicated ultimately based relationship environment species’ biology. said, functions offer options exploring relationships predictor variables can aid predictor selection process. collinearity analysis based entire cells environmental rasters just using cells species points used construct models (see details based_on_points argument correct_colivar() function). Use based_on_points approach yield different results. Let’s look method:","code":"somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\")  somevar <- terra::rast(somevar)  names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\")  plot(somevar) terra::pairs(somevar)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"pearson-correlation","dir":"Articles","previous_headings":"Reducing collinearity among the predictors","what":"1. Pearson correlation","title":"flexsdm: Overview of Pre-modeling functions","text":"method returns three objects 1) SpatRaster environmental variables correlation given threshold (default 0.7), 2) names variables correlation given threshold “removed” environmental data, 3) correlation matrix environmental variables. However, strongly urge users use information along knowledge specific species-environment relationships select ecologically-relevant predictors SDMs. example, , modeling distribution plant species water-limited Mediterranean-type ecosystem, may want include climatic water deficit (cwd) actual evapotranspiration (aet). Despite highly correlated, variables capture water availability evaporative demand, respectively (Stephenson 1998). Additionally, minimum absolute temperature strongly controls vegetation distributions (Woodward, Lomas, Kelly 2004), select tmn (minimum temperature coldest month) example. references, see:","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"woodward-f--i--m--r--lomas-and-c--k--kelly--2004--global-climate-and-the-distribution-of-plant-biomes--philosophical-transactions-of-the-royal-society-of-london--series-b-biological-sciences-35914651476-","dir":"Articles","previous_headings":"Reducing collinearity among the predictors > 1. Pearson correlation","what":"2. Woodward, F. I., M. R. Lomas, and C. K. Kelly. 2004. Global climate and the distribution of plant biomes. Philosophical transactions of the Royal Society of London. Series B, Biological sciences 359:1465–1476.","title":"flexsdm: Overview of Pre-modeling functions","text":"","code":"pearson_var <- correct_colinvar(somevar, method = c(\"pearson\", th = \"0.7\")) pearson_var$cor_table #>           aet       cwd       tmx       tmn #> aet 0.0000000 0.7689893 0.7924813 0.7845401 #> cwd 0.7689893 0.0000000 0.4168956 0.5881831 #> tmx 0.7924813 0.4168956 0.0000000 0.7323259 #> tmn 0.7845401 0.5881831 0.7323259 0.0000000 pearson_var$cor_variables #> $aet #> [1] \"cwd\" \"tmx\" \"tmn\" #>  #> $cwd #> [1] \"aet\" #>  #> $tmx #> [1] \"aet\" \"tmn\" #>  #> $tmn #> [1] \"aet\" \"tmx\"  chosen_variables <- somevar[[c(\"cwd\", \"aet\", \"tmn\")]]"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"variance-inflation-factor","dir":"Articles","previous_headings":"Reducing collinearity among the predictors","what":"2. Variance inflation factor","title":"flexsdm: Overview of Pre-modeling functions","text":"method removes predictors variance inflation factor higher chosen threshold. , users can specify threshold (default 10). method retains predictors aet, tmx, tmn removes cwd. output method matches produced pearson method: 1) environmental layer retained variables, 2) list removed variables, 3) correlation matrix variables.","code":"vif_var <- correct_colinvar(somevar, method = c(\"vif\", th = \"10\")) vif_var$env_layer #> class       : SpatRaster  #> size        : 558, 394, 4  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source      : somevar.tif  #> names       :      aet,      cwd,       tmx,        tmn  #> min values  :    0.000, -9.39489,  22.44685,  0.2591429  #> max values  : 1357.865, 14.20047, 614.69125, 64.3747588 vif_var$removed_variables #> NULL vif_var$vif_table #> # A tibble: 4 × 2 #>   Variables   VIF #>   <chr>     <dbl> #> 1 aet        7.62 #> 2 cwd        3.29 #> 3 tmx        3.95 #> 4 tmn        2.89"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"principal-component-analysis","dir":"Articles","previous_headings":"Reducing collinearity among the predictors","what":"3. Principal component analysis","title":"flexsdm: Overview of Pre-modeling functions","text":"Finally, “pca” method performs principal components analysis predictors returns axis accounts 95% total variance system. method returns 1) SpatRaster object selected environmental variables, 2) matrix coefficients principal components predictors, 3) tibble cumulative variance explained selected principal components.","code":"pca_var <- correct_colinvar(somevar, method = c(\"pca\")) pca_var$env_layer #> class       : SpatRaster  #> size        : 558, 394, 3  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> names       :       PC1,       PC2,       PC3  #> min values  : -8.453273, -4.260147, -1.525085  #> max values  :  2.827164,  3.337545,  4.342864 pca_var$coefficients #> # A tibble: 4 × 5 #>   variable    PC1     PC2    PC3     PC4 #>   <chr>     <dbl>   <dbl>  <dbl>   <dbl> #> 1 aet       0.550 -0.0722  0.296 -0.778  #> 2 cwd       0.450 -0.777   0.103  0.429  #> 3 tmx      -0.485 -0.594  -0.450 -0.459  #> 4 tmn      -0.511 -0.198   0.836 -0.0241 pca_var$cumulative_variance #> # A tibble: 4 × 2 #>      PC  cvar #>   <int> <dbl> #> 1     1 0.764 #> 2     2 0.915 #> 3     3 0.979 #> 4     4 1"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"factorial-analysis","dir":"Articles","previous_headings":"Reducing collinearity among the predictors","what":"4. Factorial analysis","title":"flexsdm: Overview of Pre-modeling functions","text":"Selecting “fa” method performs factorial analysis reduce dimensionality selects predictor(s) highest correlation axis. outputs method similar produced ‘pca’ method.","code":"fa_var <- correct_colinvar(env_layer = somevar, method = c(\"fa\")) fa_var$env_layer fa_var$number_factors fa_var$removed_variables fa_var$uniqueness fa_var$loadings"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"comments","dir":"Articles","previous_headings":"Reducing collinearity among the predictors","what":"5. Comments","title":"flexsdm: Overview of Pre-modeling functions","text":"flexsdm also possible restrict cell used perform collinearity reduction analysis geographical area smaller full extent environmental variables. See ‘restric_to_region’ ‘restric_pca_proj’ correct_colinvar examples alternative PCA given function help.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"data-filtering","dir":"Articles","previous_headings":"","what":"Data filtering","title":"flexsdm: Overview of Pre-modeling functions","text":"Sample bias species occurrence data common issue ecological studies filtering occurrence data can reduce bias. flexsdm provides two functions different types filtering, based geographical environmental “thinning”, randomly removing points dense (oversampling) geographical environmental space. can improve model performance reduce redundancy data.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"environmental-filtering","dir":"Articles","previous_headings":"Data filtering","what":"Environmental filtering","title":"flexsdm: Overview of Pre-modeling functions","text":"function occfilt_env(), performs environmental filtering species occurrence data. method basically reduces environmental redundancy data based methods outlined Valera et al. (2014). However, function unique flexsdm, able use number environmental dimensions perform PCA filtering. example, use original environmental data (somevar) occurrence data single species (spp1). filtering occurrences, important row species data unique code (example: idd). function also gives user option specifying number classes used split environmental condition. explore results using 5, 8, 12 bins. Increasing number bins increases number occurrence points retained.","code":"spp1$idd <- 1:nrow(spp1)  filt_env5 <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = 5 ) #> Extracting values from raster ... #> 12 records were removed because they have NAs for some variables #> Number of unfiltered records: 238 #> Number of filtered records: 57  filt_env8 <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = 8 ) #> Extracting values from raster ... #> 12 records were removed because they have NAs for some variables #> Number of unfiltered records: 238 #> Number of filtered records: 112  filt_env12 <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = 12 ) #> Extracting values from raster ... #> 12 records were removed because they have NAs for some variables #> Number of unfiltered records: 238 #> Number of filtered records: 173   par(mfrow = c(2, 2)) somevar[[1]] %>% plot(main = \"Original occurrence data\") points(spp1 %>% select(x, y)) somevar[[1]] %>% plot(main = \"Filtering with 5 bins\") points(filt_env5 %>% select(x, y)) somevar[[1]] %>% plot(main = \"Filtering with 8 bins\") points(filt_env8 %>% select(x, y)) somevar[[1]] %>% plot(main = \"Filtering with 12 bins\") points(filt_env12 %>% select(x, y))"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"geographical-filtering","dir":"Articles","previous_headings":"Data filtering","what":"Geographical filtering","title":"flexsdm: Overview of Pre-modeling functions","text":"Next, look occfilt_geo(), three alternatives determine distance threshold pair points: “moran” determines threshold distance points minimizes spatial autocorrelation occurrence data; “cellsize” filters occurrences based resolution predictors (specified coarser resolution); finally, “determined” allows users manually determine distance threshold.  Also, three methods, possible methods use several values, turning easier possibility explore test several filtering values.    tested filtering occurrence different values, can use occfilt_select() function select filtered dataset equilibrate spatial autocorrelation maximum number presences (see occfilt_select() function help)","code":"filt_geo1 <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"moran\"),   prj = crs(somevar) ) #> Extracting values from raster ... #> 16 records were removed because they have NAs for some variables #> Number of unfiltered records: 234 #> Moran's I threshold closest to the supplied value: 0.099 #> Distance threshold (km) : 334.908 #> Number of filtered records: 4  filt_geo2 <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"cellsize\", factor = \"3\"), # coarser resolution than the provided raster   prj = crs(somevar) ) #> Extracting values from raster ... #> 16 records were removed because they have NAs for some variables #> Number of unfiltered records: 234 #> Factor: x3 #> Distance threshold (km): 4.617 #> Number of filtered records: 212  filt_geo3 <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"defined\", d = \"30\"),   prj = crs(somevar) ) #> Extracting values from raster ... #> 16 records were removed because they have NAs for some variables #> Number of unfiltered records: 234 #> Distance threshold (km): 30 #> Number of filtered records: 78  par(mfrow = c(2, 2)) somevar[[1]] %>% plot(main = \"Original occurrence data\") points(spp1 %>% select(x, y)) somevar[[1]] %>% plot(main = \"Filtering with Moran's I\") points(filt_geo1 %>% select(x, y)) somevar[[1]] %>% plot(main = \"Filtering with cell size\") points(filt_geo2 %>% select(x, y)) somevar[[1]] %>% plot(main = \"Filtering with defined distance (30km)\") points(filt_geo3 %>% select(x, y)) filt_geo1 <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"moran\", c(0.1, 0.2, 0.3, 0.5)),   prj = crs(somevar) )  filt_geo2 <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"cellsize\", factor = c(1, 5, 8, 12)), # coarser resolution than the provided raster   prj = crs(somevar) )  filt_geo3 <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"defined\", d = c(5, 10, 15, 30)),   prj = crs(somevar) )  # When several values are used, note the function returns a list with the filtered data filt_geo1 %>% class() #> [1] \"list\" filt_geo1 %>% names() #> [1] \"0.1\" \"0.2\" \"0.3\" \"0.5\"  # Let's plot the results with ggplot2 bind_rows(filt_geo1, .id = \"moran\") %>%   dplyr::mutate(moran = as.numeric(moran)) %>%   ggplot(aes(x, y)) +   geom_point() +   facet_wrap(~moran) bind_rows(filt_geo2, .id = \"cellsize\") %>%   dplyr::mutate(moran = as.numeric(cellsize)) %>%   ggplot(aes(x, y)) +   geom_point() +   facet_wrap(~cellsize) bind_rows(filt_geo2, .id = \"determined\") %>%   dplyr::mutate(moran = as.numeric(determined)) %>%   ggplot(aes(x, y)) +   geom_point() +   facet_wrap(~determined) filt_selected <- occfilt_select(   occ_list = filt_geo2,   x = \"x\", y = \"y\",   env_layer = somevar, filter_prop = TRUE ) #> Dataset with filtered value 8 was selected filt_selected #> $occ #> # A tibble: 156 × 4 #>    species        x        y   idd #>    <chr>      <dbl>    <dbl> <int> #>  1 sp1     -269871.   69512.     1 #>  2 sp1     -149991.  267962.     2 #>  3 sp1       91659. -156748.     4 #>  4 sp1     -210471.  326282.     5 #>  5 sp1     -140541.  284972.     6 #>  6 sp1     -217491.   65732.     7 #>  7 sp1      -92481.  155642.    12 #>  8 sp1     -367611.  266072.    13 #>  9 sp1     -184551.  425372.    15 #> 10 sp1     -260151.   57632.    18 #> # ℹ 146 more rows #>  #> $filter_prop #>   filt_value mean_autocorr n_records       aet       cwd       tmx       tmn #> 1          1     0.3219265       233 0.3534014 0.2017850 0.3352363 0.3972832 #> 2          5     0.2923551       189 0.3276294 0.1400721 0.3170405 0.3846783 #> 3        * 8     0.2602486       156 0.3055744 0.1287050 0.2635844 0.3431307 #> 4         12     0.2291901       118 0.2568785 0.1080880 0.2311247 0.3206691"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"data-partitioning","dir":"Articles","previous_headings":"","what":"Data partitioning","title":"flexsdm: Overview of Pre-modeling functions","text":"Data partitioning, splitting data testing training groups, key step building SDMs. flexsdm offers multiple options data partitioning, including part_random(), part_sband(), part_sblock(), part_senv(). Let’s explore methods.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"conventional-data-partitioning-methods-part_random","dir":"Articles","previous_headings":"Data partitioning","what":"1. Conventional data partitioning methods (part_random)","title":"flexsdm: Overview of Pre-modeling functions","text":"part_random() function provides users ability divide species occurrence data based conventional partition methods including k-folds, repeated k-folds, leave-one-cross-validation, bootstrap partitioning. , use “kfold” method 10 folds divide data. results 10 folds occurrence data 25 observations fold.","code":"spp1$pr_ab <- 1 # Add a column with 1 to denote that this is presences only data sp_part1 <- part_random(   data = spp1,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 10) )  sp_part1$.part %>% table() #> . #>  1  2  3  4  5  6  7  8  9 10  #> 25 25 25 25 25 25 25 25 25 25"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"spatial-band-cross-validation-part_sband","dir":"Articles","previous_headings":"Data partitioning","what":"2. Spatial band cross-validation (part_sband)","title":"flexsdm: Overview of Pre-modeling functions","text":"part_sband() part_sblock() partition data based position geographic space. Geographically structured data partitioning methods especially useful users want evaluate model transferability different regions time periods. function part_sband tests different numbers spatial partitions using latitudinal longitudinal bands selects best number bands given presence, presence-absence, presence-background dataset. procedure based spatial autocorrelation, environmental similarity, number presence/absence records band partition. function’s output includes 1) tibble presence/absence locations assigned partition number, 2) tibble information best partition, 3) SpatRaster showing selected grid.","code":"set.seed(1) sp_part2 <- part_sband(   env_layer = somevar,   data = spp1,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   type = \"lat\", # specify bands across different degrees of longitude 'lon' or latitude 'lat'.   min_bands = 2, # minimum number of spatial bands to be tested   max_bands = 20, # maximum number of spatial bands to be tested   n_part = 2,   prop = 0.5 ) #> 12 rows were excluded from database because NAs were found #> The following number of bands will be tested: #> 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 #> Creating basic raster mask... #> Searching for the optimal number of bands... plot(sp_part2$grid, col = gray.colors(20)) points(sp_part2$part[c(\"x\", \"y\")],   col = rainbow(8)[sp_part2$part$.part],   cex = 0.9,   pch = c(1, 19)[sp_part2$part$pr_ab + 1] )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"spatial-block-cross-validation-part_sblock","dir":"Articles","previous_headings":"Data partitioning","what":"3. Spatial block cross-validation (part_sblock)","title":"flexsdm: Overview of Pre-modeling functions","text":"part_sblock() function similar part_sband() instead bands explores spatial blocks different raster cells sizes returns one best suited input dataset. , can see data divided different “blocks” training testing.  However, notice grid partition produced part_sblock different resolution original environmental variables. want map layer properties (.e. resolution, extent, NAs) original environmental variables, apply get_block() function grid resulting part_sblock(). layer can really useful generating pseudo-absence background sample points, explore next section.","code":"sp_part3 <- part_sblock(   env_layer = somevar,   data = spp1,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_res_mult = 10, # Minimum value used for multiplying raster resolution and define the finest resolution to be tested   max_res_mult = 500, # Maximum value used for multiplying raster resolution and define the coarsest resolution to be tested   num_grids = 30, # Number of grid to be tested between min_res_mult X (raster resolution) and max_res_mult X (raster resolution)   n_part = 2, # Number of partitions   prop = 0.5 # Proportion of points used for testing autocorrelation between groupds (0-1) ) #> 12 rows were excluded from database because NAs were found #> The following grid cell sizes will be tested: #> 18900 | 50834.48 | 82768.97 | 114703.45 | 146637.93 | 178572.41 | 210506.9 | 242441.38 | 274375.86 | 306310.34 | 338244.83 | 370179.31 | 402113.79 | 434048.28 | 465982.76 | 497917.24 | 529851.72 | 561786.21 | 593720.69 | 625655.17 | 657589.66 | 689524.14 | 721458.62 | 753393.1 | 785327.59 | 817262.07 | 849196.55 | 881131.03 | 913065.52 | 945000 #> Creating basic raster mask... #> Searching for the optimal grid size...  plot(sp_part3$grid) points(sp_part3$part[c(\"x\", \"y\")],   col = c(\"blue\", \"red\")[sp_part3$part$.part],   cex = 0.5,   pch = 19 ) terra::res(sp_part3$grid) #> [1] 881131 881131 terra::res(somevar) #> [1] 1890 1890  grid_env <- get_block(env_layer = somevar, best_grid = sp_part3$grid)  plot(grid_env) # this is a block layer with the same layer # properties as environmental variables. points(sp_part3$part[c(\"x\", \"y\")],   col = c(\"blue\", \"red\")[sp_part3$part$.part],   cex = 0.5,   pch = 19 )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"environmental-and-spatial-cross-validation-part_senv","dir":"Articles","previous_headings":"Data partitioning","what":"4. Environmental and spatial cross-validation (part_senv)","title":"flexsdm: Overview of Pre-modeling functions","text":"final partitioning function flexsdm part_senv(), explores different numbers environmental partitions based K-means clustering algorithm returns one best-suited particular dataset, considering spatial autocorrelation, environmental similarity, number presence /absence records partition. map shows partitioning based environmental spatial factors.","code":"sp_part4 <- part_senv(   env_layer = somevar,   data = spp1,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_n_groups = 2, # Minimum number of groups to be tested   max_n_groups = 10, # Maximum number of groups to be tested   prop = 0.5 # Proportion of points used for testing autocorrelation between groups (0-1) ) #> 12 rows were excluded from database because NAs were found #> The following grid cell sizes will be tested: #> 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 #> Searching best partition...  plot(regions, col = gray.colors(9)) points(sp_part4$part[c(\"x\", \"y\")],   col = hcl.colors(length(unique(sp_part4$part)))[sp_part4$part$.part],   cex = 1,   pch = 19 )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"background-and-pseudo-absence-sampling","dir":"Articles","previous_headings":"","what":"Background and pseudo-absence sampling","title":"flexsdm: Overview of Pre-modeling functions","text":"Presence-occurrence data quite common ecology researchers may adequate “absence” data species interest. Sometimes building species distribution models, need able generate background pseudo-absence points modeling goals. flexsdm package allows users using sample_background() sample_pseudoabs().","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"sample-background","dir":"Articles","previous_headings":"Background and pseudo-absence sampling","what":"1. Sample background","title":"flexsdm: Overview of Pre-modeling functions","text":"function sample_background() allows slection background sample points based different geographic restrictions sampling methods. , sample set background points based earlier spatial block partitioning using “random” method. Using lapply() case ensures generate background points spatial blocks (n = 2). also specifying want ten times amount background points original occurrences calibration area buffer area around presence points (see section “Calibration area”).","code":"p_data <-   sp_part3$part # presence data from spatial block partition example  set.seed(10) bg <- lapply(1:2, function(x) {   sample_background(     data = p_data,     x = \"x\",     y = \"y\",     n = sum(p_data == x) * 10,     # number of background points to be sampled     method = \"random\",     rlayer = grid_env,     maskval = x,     calibarea = ca_1 # A SpatVector which delimit the calibration area used for a given species   ) }) %>%   bind_rows() %>%   mutate(pr_ab = 0)  par(mfrow = c(2, 1))  plot(grid_env, main = \"Presence points\") plot(ca_1, add = TRUE) points(p_data, cex = .7, pch = 19)  plot(grid_env, main = \"Background points\") plot(ca_1, add = TRUE) points(bg, cex = .1, pch = 19)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"sample-pseudo-absences","dir":"Articles","previous_headings":"Background and pseudo-absence sampling","what":"2. Sample pseudo-absences","title":"flexsdm: Overview of Pre-modeling functions","text":"Similarly, function sample_pseudoabs allows random pseudo-absence sampling based environmental /geographical constraints. example, specifying method = “env_const” selects pseudo-absences environmentally constrained regions lower suitability values predicted Bioclim model. Additionally, function allows users specify calibration area generate pseudo-absence points. , use buffer area around presence points (ca_1) show might look like. can see, generated pseudo-absence points general vicinity presence points, concentrated areas lower environmental suitability. specific method chosen sampling background /pseudo-absence points vary depending research goals.","code":"set.seed(10) psa <- lapply(1:2, function(x) {   sample_pseudoabs(     data = p_data,     x = \"x\",     y = \"y\",     n = sum(p_data == x),     # number of pseudo-absence points to be sampled     method = c(\"env_const\", env = somevar),     rlayer = grid_env,     maskval = x,     calibarea = ca_1   ) }) %>%   bind_rows() %>%   mutate(pr_ab = 0) #> Extents do not match, raster layers used were croped to minimum extent #> Extents do not match, raster layers used were croped to minimum extent  par(mfrow = c(2, 1))  plot(grid_env, main = \"Presence points\") plot(ca_1, add = TRUE) points(p_data, cex = .7, pch = 19)  plot(grid_env, main = \"Pseudo-absence points\") plot(ca_1, add = TRUE) points(psa, cex = .7, pch = 19)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html","id":"extracting-environmental-values","dir":"Articles","previous_headings":"","what":"Extracting environmental values","title":"flexsdm: Overview of Pre-modeling functions","text":"Finally, modeling species geographic distributions, must extract environmental data presences + absences/pseudo-absences/background point locations. function sdm_extract() extracts environmental data values based x y coordinates returns tibble original data + additional columns extracted environmental variables locations. Let’s original presence points (spp1) background locations (bg). #=========#=========#=========#=========#=========#=========#=========# Vignette still construction changes #=========#=========#=========#=========#=========#=========#=========#","code":"all_points <- bind_rows(spp1 %>% dplyr::select(-idd), bg)  ex_spp <- sdm_extract(   data = all_points,   x = \"x\",   y = \"y\",   env_layer = somevar, # Raster with environmental variables   variables = NULL, # Vector with the variable names of predictor   # variables Usage variables. = c(\"aet\", \"cwd\", \"tmin\"). If no variable is specified, function will return data for all layers.   filter_na = TRUE )  ex_spp"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"flexsdm: Overview of Modeling functions","text":"Species distribution modeling (SDM) become standard tool multiple research areas, including ecology, conservation biology, biogeography, paleobiogeography, epidemiology. SDM area active theoretical methodological research. flexsdm package provides users ability manipulate parameterize models variety ways meet unique research needs. flexibility enables users define complete partial modeling procedure specific modeling situations (e.g., number variables, number records, different algorithms ensemble methods, algorithms tuning, etc.). vignette, users learn second set functions flexsdm package fall “modeling” umbrella. functions designed construct validate different types models can grouped fit_* , tune_* , esm_* family functions. addition function perform ensemble modeling. fit_* functions construct validate models default hyper-parameter values. tune_* functions construct validate models searching best combination hyper-parameter values, esm_ functions can used constructing validating Ensemble Small Models. Finally, fit_ensemble() function fitting validating ensemble models. functions model construction validation: fit_* functions family fit_gam() Fit validate Generalized Additive Models fit_gau() Fit validate Gaussian Process models fit_gbm() Fit validate Generalized Boosted Regression models fit_glm() Fit validate Generalized Linear Models fit_max() Fit validate Maximum Entropy models fit_net() Fit validate Neural Networks models fit_raf() Fit validate Random Forest models fit_svm() Fit validate Support Vector Machine models tune_* functions family tune_gbm() Fit validate Generalized Boosted Regression models exploration hyper-parameters tune_max() Fit validate Maximum Entropy models exploration hyper-parameters tune_net() Fit validate Neural Networks models exploration hyper-parameters tune_raf() Fit validate Random Forest models exploration hyper-parameters tune_svm() Fit validate Support Vector Machine models exploration hyper-parameters model ensemble fit_ensemble() Fit validate ensemble models different ensemble methods esm_* functions family esm_gam() Fit validate Generalized Additive Models Ensemble Small Model approach esm_gau() Fit validate Gaussian Process models Models Ensemble Small Model approach esm_gbm() Fit validate Generalized Boosted Regression models Ensemble Small Model approach esm_glm() Fit validate Generalized Linear Models Ensemble Small Model approach esm_max() Fit validate Maximum Entropy models Ensemble Small Model approach esm_net() Fit validate Neural Networks models Ensemble Small Model approach esm_svm() Fit validate Support Vector Machine models Ensemble Small Model approach","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"flexsdm: Overview of Modeling functions","text":"First, install flexsdm package. can install released version flexsdm github :","code":"# devtools::install_github('sjevelazco/flexsdm') require(flexsdm) #> Loading required package: flexsdm require(terra) #> Loading required package: terra #> terra 1.8.60 #>  #> Attaching package: 'terra' #> The following object is masked from 'package:knitr': #>  #>     spin require(dplyr) #> Loading required package: dplyr #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:terra': #>  #>     intersect, union #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"project-directory-setup","dir":"Articles","previous_headings":"","what":"Project directory setup","title":"flexsdm: Overview of Modeling functions","text":"Decide computer like store inputs outputs project (main directory). Use existing one use dir.create() create main directory. specify whether include folders projections, calibration areas, algorithms, ensembles, thresholds. details see Vignette 01_pre_modeling","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"data-species-occurrence-and-background-data","dir":"Articles","previous_headings":"","what":"Data, species occurrence and background data","title":"flexsdm: Overview of Modeling functions","text":"tutorial, using species occurrences environmental data available flexsdm package. “abies” example dataset includes pr_ab column (presence = 1, absence = 0), location columns (x, y) environmental data. can load “abies” data local R environment using code : (EXAMPLE LOOKS LITTLE STRANGE ALSO USING BACKGROUND DATA, ABIES DATASET CLEARLY ABSENCES…) want replace abies dataset data, make sure dataset contains environmental conditions related presence-absence data. use pre-modeling family function k-fold partition method (used cross-validation). partition method number folds replications must presence-absence background points datasets. Now, abies2 object new column called “.part” 5 k-folds (1, 2, 3, 4, 5), indicating partition record (row) member . Next, apply partition method number folds environmental conditions background points. backg2 object new column called “.part” 5 k-folds (1, 2, 3, 4, 5).","code":"data(\"abies\") data(\"backg\")  dplyr::glimpse(abies) #> Rows: 1,400 #> Columns: 13 #> $ id       <int> 715, 5680, 7907, 1850, 1702, 10036, 12384, 6513, 9884, 8651, … #> $ pr_ab    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ x        <dbl> -95417.134, 98986.536, 121474.257, -39976.221, 111372.261, -2… #> $ y        <dbl> 314240.13, -159415.18, -99463.44, -17456.11, -91404.05, 39222… #> $ aet      <dbl> 323.1133, 447.5567, 182.2833, 372.3867, 209.4567, 308.3000, 5… #> $ cwd      <dbl> 546.1400, 815.4033, 271.1800, 946.2933, 398.5500, 534.9533, 3… #> $ tmin     <dbl> 1.2433, 9.4267, -4.9500, 8.7767, -4.0333, 4.6600, 4.3800, 4.9… #> $ ppt_djf  <dbl> 62.7257, 129.6406, 150.7003, 116.0236, 164.9327, 166.2220, 48… #> $ ppt_jja  <dbl> 17.7941, 6.4317, 11.2294, 2.7020, 9.2686, 16.5310, 41.2494, 8… #> $ pH       <dbl> 5.773341, 5.600000, 0.000000, 6.411796, 0.000000, 5.700000, 5… #> $ awc      <dbl> 0.10837019, 0.16000000, 0.00000000, 0.09719457, 0.00000000, 0… #> $ depth    <dbl> 152.000000, 201.000000, 0.000000, 59.759930, 0.000000, 112.99… #> $ landform <fct> 7, 11, 15, 14, 15, 15, 7, 15, 4, 10, 6, 10, 10, 15, 10, 11, 1… dplyr::glimpse(backg) #> Rows: 5,000 #> Columns: 13 #> $ pr_ab        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #> $ x            <dbl> 160779.16, 36849.16, -240170.84, -152420.84, -193190.84, … #> $ y            <dbl> -449968.33, 24151.67, 90031.67, -143518.33, 24151.67, 223… #> $ aet          <dbl> 280.4567, 259.7800, 400.1767, 367.4833, 397.3667, 385.263… #> $ cwd          <dbl> 1137.2433, 381.5367, 699.6500, 843.4467, 842.3833, 637.35… #> $ tmin         <dbl> 13.5100, -3.1733, 8.6800, 9.0133, 8.9700, 4.9333, 6.2933,… #> $ ppt_djf      <dbl> 71.2741, 171.4537, 285.0893, 72.0309, 125.2467, 226.1534,… #> $ ppt_jja      <dbl> 1.1920, 17.5193, 5.0158, 1.2047, 1.9778, 8.1554, 18.4182,… #> $ pH           <dbl> 0.0000000, 0.2122687, 5.7222223, 7.5350823, 6.1963525, 5.… #> $ awc          <dbl> 0.000000000, 0.003473487, 0.080370426, 0.170000002, 0.131… #> $ depth        <dbl> 0.00000, 201.00000, 50.07409, 154.39426, 122.39575, 56.17… #> $ percent_clay <dbl> 0.0000000, 0.4438345, 18.4111176, 46.9751244, 37.1873169,… #> $ landform     <fct> 13, 10, 6, 6, 10, 14, 8, 14, 6, 7, 11, 14, 14, 10, 6, 6, … abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  dplyr::glimpse(abies2) #> Rows: 1,400 #> Columns: 14 #> $ id       <int> 715, 5680, 7907, 1850, 1702, 10036, 12384, 6513, 9884, 8651, … #> $ pr_ab    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ x        <dbl> -95417.134, 98986.536, 121474.257, -39976.221, 111372.261, -2… #> $ y        <dbl> 314240.13, -159415.18, -99463.44, -17456.11, -91404.05, 39222… #> $ aet      <dbl> 323.1133, 447.5567, 182.2833, 372.3867, 209.4567, 308.3000, 5… #> $ cwd      <dbl> 546.1400, 815.4033, 271.1800, 946.2933, 398.5500, 534.9533, 3… #> $ tmin     <dbl> 1.2433, 9.4267, -4.9500, 8.7767, -4.0333, 4.6600, 4.3800, 4.9… #> $ ppt_djf  <dbl> 62.7257, 129.6406, 150.7003, 116.0236, 164.9327, 166.2220, 48… #> $ ppt_jja  <dbl> 17.7941, 6.4317, 11.2294, 2.7020, 9.2686, 16.5310, 41.2494, 8… #> $ pH       <dbl> 5.773341, 5.600000, 0.000000, 6.411796, 0.000000, 5.700000, 5… #> $ awc      <dbl> 0.10837019, 0.16000000, 0.00000000, 0.09719457, 0.00000000, 0… #> $ depth    <dbl> 152.000000, 201.000000, 0.000000, 59.759930, 0.000000, 112.99… #> $ landform <fct> 7, 11, 15, 14, 15, 15, 7, 15, 4, 10, 6, 10, 10, 15, 10, 11, 1… #> $ .part    <int> 3, 2, 5, 3, 5, 4, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 5, 4, 5, 1, 5… backg2 <- part_random(   data = backg,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  dplyr::glimpse(backg2) #> Rows: 5,000 #> Columns: 14 #> $ pr_ab        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #> $ x            <dbl> 160779.16, 36849.16, -240170.84, -152420.84, -193190.84, … #> $ y            <dbl> -449968.33, 24151.67, 90031.67, -143518.33, 24151.67, 223… #> $ aet          <dbl> 280.4567, 259.7800, 400.1767, 367.4833, 397.3667, 385.263… #> $ cwd          <dbl> 1137.2433, 381.5367, 699.6500, 843.4467, 842.3833, 637.35… #> $ tmin         <dbl> 13.5100, -3.1733, 8.6800, 9.0133, 8.9700, 4.9333, 6.2933,… #> $ ppt_djf      <dbl> 71.2741, 171.4537, 285.0893, 72.0309, 125.2467, 226.1534,… #> $ ppt_jja      <dbl> 1.1920, 17.5193, 5.0158, 1.2047, 1.9778, 8.1554, 18.4182,… #> $ pH           <dbl> 0.0000000, 0.2122687, 5.7222223, 7.5350823, 6.1963525, 5.… #> $ awc          <dbl> 0.000000000, 0.003473487, 0.080370426, 0.170000002, 0.131… #> $ depth        <dbl> 0.00000, 201.00000, 50.07409, 154.39426, 122.39575, 56.17… #> $ percent_clay <dbl> 0.0000000, 0.4438345, 18.4111176, 46.9751244, 37.1873169,… #> $ landform     <fct> 13, 10, 6, 6, 10, 14, 8, 14, 6, 7, 11, 14, 14, 10, 6, 6, … #> $ .part        <int> 4, 4, 1, 5, 5, 2, 5, 3, 2, 5, 4, 1, 4, 1, 5, 1, 1, 5, 4, …"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"fit-and-validate-models","dir":"Articles","previous_headings":"Data, species occurrence and background data","what":"1. Fit and validate models","title":"flexsdm: Overview of Modeling functions","text":"fit validate models: . maximum entropy model default hyper-parameter values (flexsdm::fit_max) II. random forest model exploration hyper-parameters (flexsdm::tune_raf). . Maximum Entropy models default hyper-parameter values. function returns list object following elements: model: “MaxEnt” class object. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: performance metric (see sdm_eval). metrics threshold dependent calculated based threshold specified argument. can see selected threshold values. Predicted suitability test partition (row) based best model. database used fit_ensemble. II- Random forest models exploration hyper-parameters. First, create data.frame provides hyper-parameters values tested. recommended generate data.frame. Hyper-parameter needed tuning ‘mtry’. maximum mtry must equal total number predictors. use data object abies2, k-fold partition method: Let’s see output object contains. function returns list object following elements: model: “randomForest” class object. object can used see formula details, basic summary o fthe model, predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: performance metric (see sdm_eval). metrics threshold dependent calculated based threshold specified argument. can see selected threshold values. Predicted suitability test partition (row) based best model. database used fit_ensemble. model objects can used flexsdm::fit_ensemble().","code":"max_t1 <- fit_max(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   background = backg2,   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   clamp = TRUE,   classes = \"default\",   pred_type = \"cloglog\",   regmult = 1 ) #> Formula used for model fitting: #> ~aet + ppt_jja + pH + awc + depth + I(aet^2) + I(ppt_jja^2) + I(pH^2) + I(awc^2) + I(depth^2) + hinge(aet) + hinge(ppt_jja) + hinge(pH) + hinge(awc) + hinge(depth) + ppt_jja:aet + pH:aet + awc:aet + depth:aet + pH:ppt_jja + awc:ppt_jja + depth:ppt_jja + awc:pH + depth:pH + depth:awc + categorical(landform) - 1 #> Replica number: 1/1 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 names(max_t1) #> [1] \"model\"       \"predictors\"  \"performance\" \"data_ens\" options(max.print = 20) max_t1$model #>  #> Call:  glmnet::glmnet(x = mm, y = as.factor(p), family = \"binomial\",      weights = weights, lambda = 10^(seq(4, 0, length.out = 200)) *          sum(reg)/length(reg) * sum(p)/sum(weights), standardize = F,      penalty.factor = reg)  #>  #>     Df  %Dev  Lambda #> 1    0  0.00 21.3700 #> 2    0  0.00 20.4100 #> 3    0  0.00 19.4800 #> 4    0  0.00 18.6000 #> 5    0  0.00 17.7600 #> 6    0  0.00 16.9600 #>  [ reached getOption(\"max.print\") -- omitted 194 rows ] max_t1$predictors #> # A tibble: 1 × 6 #>   c1    c2      c3    c4    c5    f        #>   <chr> <chr>   <chr> <chr> <chr> <chr>    #> 1 aet   ppt_jja pH    awc   depth landform max_t1$performance #> # A tibble: 3 × 25 #>   model threshold      thr_value n_presences n_absences TPR_mean TPR_sd TNR_mean #>   <chr> <chr>              <dbl>       <int>      <int>    <dbl>  <dbl>    <dbl> #> 1 max   equal_sens_sp…     0.573         700        700    0.674 0.0164    0.674 #> 2 max   max_sens_spec      0.416         700        700    0.909 0.0260    0.52  #> 3 max   max_sorensen       0.335         700        700    0.95  0.0101    0.469 #> # ℹ 17 more variables: TNR_sd <dbl>, SORENSEN_mean <dbl>, SORENSEN_sd <dbl>, #> #   JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, FPB_sd <dbl>, #> #   OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, AUC_mean <dbl>, #> #   AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, IMAE_mean <dbl>, #> #   IMAE_sd <dbl> max_t1$data_ens #> # A tibble: 1,400 × 5 #>    rnames replicates part  pr_ab   pred #>    <chr>  <chr>      <chr> <dbl>  <dbl> #>  1 8      .part      1         0 0.600  #>  2 11     .part      1         0 0.237  #>  3 13     .part      1         0 0.0483 #>  4 20     .part      1         0 0.115  #>  5 32     .part      1         0 0.716  #>  6 33     .part      1         0 0.0430 #>  7 48     .part      1         0 0.143  #>  8 55     .part      1         0 0.726  #>  9 65     .part      1         0 0.850  #> 10 75     .part      1         0 0.308  #> # ℹ 1,390 more rows tune_grid <-   expand.grid(     mtry = seq(1, 7, 1),     ntree = c(300, 500, 700, 900)   ) rf_t <-   tune_raf(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = \"max_sens_spec\",     metric = \"TSS\",   ) #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmin + ppt_djf + ppt_jja + pH + awc + depth + landform #> Tuning model... #> Replica number: 1/1 #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmin + ppt_djf + ppt_jja + pH + awc + depth + landform #> Replica number: 1/1 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 names(rf_t) #> [1] \"model\"             \"predictors\"        \"performance\"       #> [4] \"hyper_performance\" \"data_ens\" rf_t$model #>  #> Call: #>  randomForest(formula = formula1, data = data, mtry = mtry, ntree = 500,      importance = TRUE, )  #>                Type of random forest: classification #>                      Number of trees: 500 #> No. of variables tried at each split: 2 #>  #>         OOB estimate of  error rate: 10.93% #> Confusion matrix: #>     0   1 class.error #> 0 606  94  0.13428571 #> 1  59 641  0.08428571 rf_t$predictors #> # A tibble: 1 × 9 #>   c1    c2    c3    c4      c5      c6    c7    c8    f        #>   <chr> <chr> <chr> <chr>   <chr>   <chr> <chr> <chr> <chr>    #> 1 aet   cwd   tmin  ppt_djf ppt_jja pH    awc   depth landform rf_t$performance #> # A tibble: 1 × 27 #>    mtry ntree model threshold   thr_value n_presences n_absences TPR_mean TPR_sd #>   <dbl> <dbl> <chr> <chr>           <dbl>       <int>      <int>    <dbl>  <dbl> #> 1     2   300 raf   max_sens_s…      0.53         700        700    0.913 0.0383 #> # ℹ 18 more variables: TNR_mean <dbl>, TNR_sd <dbl>, SORENSEN_mean <dbl>, #> #   SORENSEN_sd <dbl>, JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, #> #   FPB_sd <dbl>, OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, #> #   AUC_mean <dbl>, AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, #> #   IMAE_mean <dbl>, IMAE_sd <dbl> rf_t$data_ens #> # A tibble: 1,400 × 5 #>    rnames replicates part  pr_ab  pred #>    <chr>  <chr>      <chr> <fct> <dbl> #>  1 8      .part      1     0     0.156 #>  2 11     .part      1     0     0.152 #>  3 13     .part      1     0     0.01  #>  4 20     .part      1     0     0.476 #>  5 32     .part      1     0     0.126 #>  6 33     .part      1     0     0.078 #>  7 48     .part      1     0     0.01  #>  8 55     .part      1     0     0.148 #>  9 65     .part      1     0     0.444 #> 10 75     .part      1     0     0.086 #> # ℹ 1,390 more rows"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"model-ensemble","dir":"Articles","previous_headings":"Data, species occurrence and background data","what":"2. Model Ensemble","title":"flexsdm: Overview of Modeling functions","text":"example fit validate ensemble model using two model objects just created.","code":"# Fit and validate ensemble model an_ensemble <- fit_ensemble(   models = list(max_t1, rf_t),   ens_method = \"meansup\",   thr = NULL,   thr_model = \"max_sens_spec\",   metric = \"TSS\" ) #>   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% # Outputs names(an_ensemble) #> [1] \"models\"      \"thr_metric\"  \"predictors\"  \"performance\"  an_ensemble$thr_metric #> [1] \"max_sens_spec\" \"TSS_mean\" an_ensemble$predictors #> # A tibble: 2 × 9 #>   c1    c2      c3    c4      c5      f        c6    c7    c8    #>   <chr> <chr>   <chr> <chr>   <chr>   <chr>    <chr> <chr> <chr> #> 1 aet   ppt_jja pH    awc     depth   landform NA    NA    NA    #> 2 aet   cwd     tmin  ppt_djf ppt_jja landform pH    awc   depth an_ensemble$performance #> # A tibble: 7 × 25 #>   model   threshold   thr_value n_presences n_absences TPR_mean  TPR_sd TNR_mean #>   <chr>   <chr>           <dbl>       <int>      <int>    <dbl>   <dbl>    <dbl> #> 1 meansup equal_sens…     0.58          700        700    0.876 0.0251     0.876 #> 2 meansup lpt             0.028         700        700    1     0          0.421 #> 3 meansup max_fpb         0.48          700        700    0.933 0.0310     0.843 #> 4 meansup max_jaccard     0.48          700        700    0.933 0.0310     0.843 #> 5 meansup max_sens_s…     0.48          700        700    0.91  0.0345     0.87  #> 6 meansup max_sorens…     0.48          700        700    0.933 0.0310     0.843 #> 7 meansup sensitivity     0.534         700        700    0.897 0.00391    0.857 #> # ℹ 17 more variables: TNR_sd <dbl>, SORENSEN_mean <dbl>, SORENSEN_sd <dbl>, #> #   JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, FPB_sd <dbl>, #> #   OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, AUC_mean <dbl>, #> #   AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, IMAE_mean <dbl>, #> #   IMAE_sd <dbl>"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v02_modeling.html","id":"fit-and-validate-models-with-ensemble-of-small-model-approach","dir":"Articles","previous_headings":"Data, species occurrence and background data","what":"3. Fit and validate models with Ensemble of Small Model approach","title":"flexsdm: Overview of Modeling functions","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers’ D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic applied species occurrences. detail see Breiner et al. (2015, 2018) can use different methods flexsdm::part_random function according data. See part_random details. function constructs Generalized Additive Models using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018). function returns list object following elements: esm_model: list “GAM” class object bivariate model. object can used predicting using ESM approachwith sdm_predict function. predictors: tibble variables use modeling. performance: Performance metric (see sdm_eval). threshold dependent metrics calculated based threshold specified argument. Now, test rep_kfold partition method. method ‘folds’ refers number partitions data partitioning ‘replicate’ refers number replicates. assume values >=1. use new rep_kfold partition gam model Test random bootstrap partitioning. method ‘replicate’ refers number replicates (assumes value >=1), ‘proportion’ refers proportion occurrences used model fitting (assumes value >0 <=1). method can configure proportion training testing data according species occurrences. example, proportion=‘0.7’ indicates 70% data used model training, 30% used model testing. method, function return .partX columns “train” “test” words entries. Use new rep_kfold partition gam model #=========#=========#=========#=========#=========#=========#=========# Vignette still construction changes #=========#=========#=========#=========#=========#=========#=========#","code":"data(\"abies\") library(dplyr)  # Create a smaller subset of occurrences set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by() # Using k-fold partition method for model cross validation abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 3) ) abies2 #> # A tibble: 20 × 14 #>       id pr_ab        x        y   aet   cwd   tmin ppt_djf ppt_jja    pH    awc #>    <int> <dbl>    <dbl>    <dbl> <dbl> <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl> #>  1 12040     0 -308909.  384248.  573.  332.  4.84     521.   48.8   5.63 0.108  #>  2 10361     0 -254286.  417158.  260.  469.  2.93     151.   15.1   6.20 0.0950 #>  3  9402     0 -286979.  386206.  587.  376.  6.45     333.   15.7   5.5  0.160  #>  4  9815     0 -291849.  445595.  443.  455.  4.39     332.   19.1   6    0.0700 #>  5 10524     0 -256658.  184438.  355.  568.  5.87     303.   10.6   5.20 0.0800 #>  6  8860     0  121343. -164170.  354.  733.  3.97     182.    9.83  0    0      #>  7  6431     0  107903. -122968.  461.  578.  4.87     161.    7.66  5.90 0.0900 #>  8 11730     0 -333903.  431238.  561.  364.  6.73     387.   25.2   5.80 0.130  #>  9   808     0 -150163.  357180.  339.  564.  2.64     220.   15.3   6.40 0.100  #> 10 11054     0 -293663.  340981.  477.  396.  3.89     332.   26.4   4.60 0.0634 #> 11  2960     1  -49273.  181752.  512.  275.  0.920    319.   17.3   5.92 0.0900 #> 12  3065     1  126907. -198892.  322.  544.  0.700    203.   10.6   5.60 0.110  #> 13  5527     1  116751. -181089.  261.  537.  0.363    178.    7.43  0    0      #> 14  4035     1  -31777.  115940.  394.  440.  2.07     298.   11.2   6.01 0.0769 #> 15  4081     1   -5158.   90159.  301.  502.  0.703    203.   14.6   6.11 0.0633 #> 16  3087     1  102151. -143976.  299.  425. -2.08     205.   13.4   3.88 0.110  #> 17  3495     1  -19586.   89803.  438.  419.  2.13     189.   15.2   6.19 0.0959 #> 18  4441     1   49405.  -60502.  362.  582.  2.42     218.    7.84  5.64 0.0786 #> 19   301     1 -132516.  270845.  367.  196. -2.56     422.   26.3   6.70 0.0300 #> 20  3162     1   59905.  -53634.  319.  626.  1.99     212.    4.50  4.51 0.0396 #> # ℹ 3 more variables: depth <dbl>, landform <fct>, .part <int> # We set the model without threshold specification and with the kfold created above esm_gam_t1 <- esm_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL ) #>  #> Model has more coefficients than data used for training it. Try to reduce k names(esm_gam_t1) #> NULL options(max.print = 10) # If you don't want to see printed all the output esm_gam_t1$esm_model #> NULL esm_gam_t1$predictors #> NULL esm_gam_t1$performance #> NULL # Remove the previous k-fold partition abies2 <- abies2 %>% select(-starts_with(\".\"))  # Test with rep_kfold partition using 3 folds and 5 replicates set.seed(10) abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2 #> # A tibble: 20 × 18 #>       id pr_ab        x        y   aet   cwd   tmin ppt_djf ppt_jja    pH    awc #>    <int> <dbl>    <dbl>    <dbl> <dbl> <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl> #>  1 12040     0 -308909.  384248.  573.  332.  4.84     521.   48.8   5.63 0.108  #>  2 10361     0 -254286.  417158.  260.  469.  2.93     151.   15.1   6.20 0.0950 #>  3  9402     0 -286979.  386206.  587.  376.  6.45     333.   15.7   5.5  0.160  #>  4  9815     0 -291849.  445595.  443.  455.  4.39     332.   19.1   6    0.0700 #>  5 10524     0 -256658.  184438.  355.  568.  5.87     303.   10.6   5.20 0.0800 #>  6  8860     0  121343. -164170.  354.  733.  3.97     182.    9.83  0    0      #>  7  6431     0  107903. -122968.  461.  578.  4.87     161.    7.66  5.90 0.0900 #>  8 11730     0 -333903.  431238.  561.  364.  6.73     387.   25.2   5.80 0.130  #>  9   808     0 -150163.  357180.  339.  564.  2.64     220.   15.3   6.40 0.100  #> 10 11054     0 -293663.  340981.  477.  396.  3.89     332.   26.4   4.60 0.0634 #> 11  2960     1  -49273.  181752.  512.  275.  0.920    319.   17.3   5.92 0.0900 #> 12  3065     1  126907. -198892.  322.  544.  0.700    203.   10.6   5.60 0.110  #> 13  5527     1  116751. -181089.  261.  537.  0.363    178.    7.43  0    0      #> 14  4035     1  -31777.  115940.  394.  440.  2.07     298.   11.2   6.01 0.0769 #> 15  4081     1   -5158.   90159.  301.  502.  0.703    203.   14.6   6.11 0.0633 #> 16  3087     1  102151. -143976.  299.  425. -2.08     205.   13.4   3.88 0.110  #> 17  3495     1  -19586.   89803.  438.  419.  2.13     189.   15.2   6.19 0.0959 #> 18  4441     1   49405.  -60502.  362.  582.  2.42     218.    7.84  5.64 0.0786 #> 19   301     1 -132516.  270845.  367.  196. -2.56     422.   26.3   6.70 0.0300 #> 20  3162     1   59905.  -53634.  319.  626.  1.99     212.    4.50  4.51 0.0396 #> # ℹ 7 more variables: depth <dbl>, landform <fct>, .part1 <int>, .part2 <int>, #> #   .part3 <int>, .part4 <int>, .part5 <int> esm_gam_t2 <- esm_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL ) #>  #> Model has more coefficients than data used for training it. Try to reduce k # Remove the previous k-fold partition abies2 <- abies2 %>% select(-starts_with(\".\"))  # Test with bootstrap partition using 10 replicates set.seed(10) abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 10, proportion = 0.7) ) abies2 #> # A tibble: 20 × 23 #>       id pr_ab        x        y   aet   cwd   tmin ppt_djf ppt_jja    pH    awc #>    <int> <dbl>    <dbl>    <dbl> <dbl> <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl> #>  1 12040     0 -308909.  384248.  573.  332.  4.84     521.   48.8   5.63 0.108  #>  2 10361     0 -254286.  417158.  260.  469.  2.93     151.   15.1   6.20 0.0950 #>  3  9402     0 -286979.  386206.  587.  376.  6.45     333.   15.7   5.5  0.160  #>  4  9815     0 -291849.  445595.  443.  455.  4.39     332.   19.1   6    0.0700 #>  5 10524     0 -256658.  184438.  355.  568.  5.87     303.   10.6   5.20 0.0800 #>  6  8860     0  121343. -164170.  354.  733.  3.97     182.    9.83  0    0      #>  7  6431     0  107903. -122968.  461.  578.  4.87     161.    7.66  5.90 0.0900 #>  8 11730     0 -333903.  431238.  561.  364.  6.73     387.   25.2   5.80 0.130  #>  9   808     0 -150163.  357180.  339.  564.  2.64     220.   15.3   6.40 0.100  #> 10 11054     0 -293663.  340981.  477.  396.  3.89     332.   26.4   4.60 0.0634 #> 11  2960     1  -49273.  181752.  512.  275.  0.920    319.   17.3   5.92 0.0900 #> 12  3065     1  126907. -198892.  322.  544.  0.700    203.   10.6   5.60 0.110  #> 13  5527     1  116751. -181089.  261.  537.  0.363    178.    7.43  0    0      #> 14  4035     1  -31777.  115940.  394.  440.  2.07     298.   11.2   6.01 0.0769 #> 15  4081     1   -5158.   90159.  301.  502.  0.703    203.   14.6   6.11 0.0633 #> 16  3087     1  102151. -143976.  299.  425. -2.08     205.   13.4   3.88 0.110  #> 17  3495     1  -19586.   89803.  438.  419.  2.13     189.   15.2   6.19 0.0959 #> 18  4441     1   49405.  -60502.  362.  582.  2.42     218.    7.84  5.64 0.0786 #> 19   301     1 -132516.  270845.  367.  196. -2.56     422.   26.3   6.70 0.0300 #> 20  3162     1   59905.  -53634.  319.  626.  1.99     212.    4.50  4.51 0.0396 #> # ℹ 12 more variables: depth <dbl>, landform <fct>, .part1 <chr>, .part2 <chr>, #> #   .part3 <chr>, .part4 <chr>, .part5 <chr>, .part6 <chr>, .part7 <chr>, #> #   .part8 <chr>, .part9 <chr>, .part10 <chr> esm_gam_t3 <- esm_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL ) #>  #> Model has more coefficients than data used for training it. Try to reduce k"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"flexsdm: Overview of Post-modeling functions","text":"Species distribution modeling (SDM) become standard tool multiple research areas, including ecology, conservation biology, biogeography, paleobiogeography, epidemiology. SDM area active theoretical methodological research flexsdm package provides users ability manipulate parameterize models variety ways meet unique research needs. flexibility enables users define complete partial modeling procedure specific modeling situations (e.g., number variables, number records, different algorithms ensemble methods, algorithms tuning, etc.). vignette, users learn post-modeling set functions flexsdm package. functions designed aim assisting flexsdm user predicting, evaluating, correcting SDMs. functions created model prediction, evaluation correction: Post-modeling functions sdm_predict() Spatial predictions individual ensemble models sdm_summarize() Merge model performance tables interp() Raster interpolation SDM predictions two time periods extra_eval() Measure model extrapolation extra_correct() Constraint suitability values given extrapolation value msdm_priori() Create spatial predictor variables reduce overprediction species distribution models msdm_posteriori() Methods correct overprediction species distribution models based occurrences suitability patterns","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"flexsdm: Overview of Post-modeling functions","text":"Install flexsdm package. can install released version flexsdm github :","code":"# devtools::install_github('sjevelazco/flexsdm') library(flexsdm) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(terra) #> terra 1.8.60 #>  #> Attaching package: 'terra' #> The following object is masked from 'package:knitr': #>  #>     spin"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"project-directory-setup","dir":"Articles","previous_headings":"","what":"Project directory setup","title":"flexsdm: Overview of Post-modeling functions","text":"Decide computer like store inputs outputs project (main directory). Use existing one use dir.create() create main directory. specify whether include folders projections, calibration areas, algorithms, ensembles, thresholds. details see Vignette 01_pre_modeling","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"species-occurrence-presenceabsense-and-environmental-data","dir":"Articles","previous_headings":"","what":"Species occurrence, presence/absense and environmental data","title":"flexsdm: Overview of Post-modeling functions","text":"tutorial, using “spp” example dataset includes pr_ab (presence = 1, absence = 0), location (x, y) data 3 plant species found California raster environmental data. can load data local R environment using code : want replace spp dataset data, make sure contains coordinates, species presence = 1 / absence = 0 raster environmental data. First, prepare occurrences, environmental conditions partitions Next, fit different models","code":"data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # Select only one species some_sp <- spp %>%   filter(species == \"sp3\")  # Extract the environmental condition from the rsater for sp3 some_sp <-   sdm_extract(     data = some_sp,     x = \"x\",     y = \"y\",     env_layer = somevar   ) #> 4 rows were excluded from database because NAs were found  # Make a partition defining the method, folds and replicates some_sp <- part_random(   data = some_sp,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) # Fit and validate a [generalized linear model](https://sjevelazco.github.io/flexsdm/reference/fit_glm.html) mglm <- fit_glm(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\",   poly = 2 ) #> Formula used for model fitting: #> pr_ab ~ CFP_1 + CFP_2 + CFP_3 + CFP_4 + I(CFP_1^2) + I(CFP_2^2) + I(CFP_3^2) + I(CFP_4^2) #> Replica number: 1/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 2/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 3/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 4/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 5/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3  # Fit and validate a [random forest model](https://sjevelazco.github.io/flexsdm/reference/fit_raf.html) mraf <- fit_raf(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\", ) #> Formula used for model fitting: #> pr_ab ~ CFP_1 + CFP_2 + CFP_3 + CFP_4 #> Replica number: 1/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 2/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 3/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 4/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 5/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3  # Fit and validate a [general boosted regression model](https://sjevelazco.github.io/flexsdm/reference/fit_gbm.html) mgbm <- fit_gbm(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\" ) #> Formula used for model fitting: #> pr_ab ~ CFP_1 + CFP_2 + CFP_3 + CFP_4 #> Replica number: 1/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 2/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 3/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 4/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3 #> Replica number: 5/5 #> Partition number: 1/3 #> Partition number: 2/3 #> Partition number: 3/3"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"fit-and-ensemble-the-models-above","dir":"Articles","previous_headings":"Species occurrence, presence/absense and environmental data","what":"1. Fit and ensemble the models above","title":"flexsdm: Overview of Post-modeling functions","text":"can also fit model using Ensembles Small Models approach. example, fit without threshold specification k-fold cross-validation. Finally, can predict different kinds models data (some_sp). sdm_predict can used predicting one models fitted fit_ tune_ functions. output list SpatRaster continuous /binary predictions.","code":"# Fit and ensemble the models. To choose the arguments that best fit your own data, see all options available in [fit_ensemble](https://sjevelazco.github.io/flexsdm/reference/fit_ensemble.html) mensemble <- fit_ensemble(   models = list(mglm, mraf, mgbm),   ens_method = \"meansup\",   thr = NULL,   thr_model = \"max_sens_spec\",   metric = \"TSS\" ) #>   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% msmall <- esm_gam(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\",   thr = NULL ) #>   |                                                                              |                                                                      |   0%  |                                                                              |============                                                          |  17%  |                                                                              |=======================                                               |  33%  |                                                                              |===================================                                   |  50%  |                                                                              |===============================================                       |  67%  |                                                                              |==========================================================            |  83%  |                                                                              |======================================================================| 100% # Predict using a single model, which is an mglm model in this example, # and a threshold type for binary predictions ind_p <- sdm_predict(   models = mglm,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL ) #> Predicting individual models  # Inspect the object. It's a SpatRaster with 2 layers: glm, max_fpb # These are the continuous and binary prediction from the model ind_p #> $glm #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : somevar  #>               somevar  #> names       :          glm, max_fpb  #> min values  : 2.220446e-16,    TRUE  #> max values  : 1.000000e+00,    TRUE  # Plot to see this layers ind_p_rst <- terra::rast(ind_p) plot(ind_p_rst) # Predict a list of more than one model, specifying a threshold type list_p <- sdm_predict(   models = list(mglm, mraf, mgbm),   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL ) #> Predicting list of individual models  # Inspect the object. It's a list with 3 SpatRaster, one for each model, # each of which contains 2 layers, for the continuous and thresholded binary predictions. list_p #> $glm #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : somevar  #>               somevar  #> names       :          glm, max_fpb  #> min values  : 2.220446e-16,    TRUE  #> max values  : 1.000000e+00,    TRUE  #>  #> $raf #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : somevar  #>               somevar  #> names       : raf, max_fpb  #> min values  :   0,   FALSE  #> max values  :   1,    TRUE  #>  #> $gbm #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : somevar  #>               somevar  #> names       :          gbm, max_fpb  #> min values  : 0.0002949323,   FALSE  #> max values  : 0.9986537352,    TRUE  # Plot to see this layers list_p_rst <- terra::rast(list_p) plot(list_p_rst) # Predict an ensemble model. This is only possible using one fit_ensemble object. It's not possible to include e.g., list(fit_ensemble1, fit_ensemble2) in the model argument. ensemble_p <- sdm_predict(   models = mensemble,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL ) #> Predicting ensembles  # Inspect the object. It's a SpatRaster with 2 layers, mensemble and max_fpb # These are the continuous and binary prediction from the ensemble model ensemble_p #> $meansup #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : somevar  #>               somevar  #> names       : meansup, max_fpb  #> min values  :       0,   FALSE  #> max values  :       1,    TRUE  # Plot to see this layers ensemble_p_rst <- terra::rast(ensemble_p) plot(ensemble_p_rst) # Predict an ensembles of small models. small_p <- sdm_predict(   models = msmall,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL ) #> Predicting ensemble of small models  # Inspect the object It's a SpatRaster with 2 layers, msmall and max_fpb # These are the continuous and binary prediction from the ESM model small_p #> $esm_gam #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> names       :      esm_gam, max_fpb  #> min values  : 2.476531e-05,   FALSE  #> max values  : 1.000000e+00,    TRUE  # Plot to see this layers small_p_rst <- terra::rast(small_p) plot(small_p_rst)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"merge-model-performance-tables","dir":"Articles","previous_headings":"Species occurrence, presence/absense and environmental data","what":"2. Merge model performance tables","title":"flexsdm: Overview of Post-modeling functions","text":"function combines model performance tables input models. function requires list one models fitted fit_ tune_ functions, fit_ensemble output, esm_ family function output. Build models use performance table merge Finally, merge three sdm performance tables.","code":"# Load abies data data(abies) abies #> # A tibble: 1,400 × 13 #>       id pr_ab        x        y   aet   cwd  tmin ppt_djf ppt_jja    pH    awc #>    <int> <dbl>    <dbl>    <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> #>  1   715     0  -95417.  314240.  323.  546.  1.24    62.7   17.8   5.77 0.108  #>  2  5680     0   98987. -159415.  448.  815.  9.43   130.     6.43  5.60 0.160  #>  3  7907     0  121474.  -99463.  182.  271. -4.95   151.    11.2   0    0      #>  4  1850     0  -39976.  -17456.  372.  946.  8.78   116.     2.70  6.41 0.0972 #>  5  1702     0  111372.  -91404.  209.  399. -4.03   165.     9.27  0    0      #>  6 10036     0 -255715.  392229.  308.  535.  4.66   166.    16.5   5.70 0.0777 #>  7 12384     0 -311765.  380213.  568.  352.  4.38   480.    41.2   5.80 0.110  #>  8  6513     0  111360. -120229.  327.  633.  4.93   163.     8.91  1.18 0.0116 #>  9  9884     0 -284326.  442136.  377.  446.  3.99   296.    16.8   5.96 0.0900 #> 10  8651     0  137640. -110538.  215.  265. -4.62   180.     9.57  0    0      #> # ℹ 1,390 more rows #> # ℹ 2 more variables: depth <dbl>, landform <fct>  # We will partition the data with the k-fold method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) ) # Build a generalized additive model, and a generalized linear model using fit_ family functions gam_t1 <- fit_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") ) #> Formula used for model fitting: #> pr_ab ~ s(aet, k = -1) + s(ppt_jja, k = -1) + s(pH, k = -1) + s(awc, k = -1) + s(depth, k = -1) + landform #> Replica number: 1/1 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5   glm_t1 <- fit_glm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   poly = 0,   inter_order = 0 ) #> Formula used for model fitting: #> pr_ab ~ aet + ppt_jja + pH + awc + depth + landform #> Replica number: 1/1 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5  # Build a tuned model using tune_ family functions  # Prepare the grid object to use in grid argument tune_grid <-   expand.grid(     mtry = seq(1, 7, 1),     ntree = seq(300, 1500, 200)   )  # Build a tuned random forest model rf_t1 <-   tune_raf(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),     metric = \"TSS\",   ) #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmin + ppt_djf + ppt_jja + pH + awc + depth + landform #> Tuning model... #> Replica number: 1/1 #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmin + ppt_djf + ppt_jja + pH + awc + depth + landform #> Replica number: 1/1 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5  rf_t1$performance #> # A tibble: 1 × 27 #>    mtry ntree model threshold   thr_value n_presences n_absences TPR_mean TPR_sd #>   <dbl> <dbl> <chr> <chr>           <dbl>       <int>      <int>    <dbl>  <dbl> #> 1     3   300 raf   max_sens_s…     0.606         700        700    0.924 0.0356 #> # ℹ 18 more variables: TNR_mean <dbl>, TNR_sd <dbl>, SORENSEN_mean <dbl>, #> #   SORENSEN_sd <dbl>, JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, #> #   FPB_sd <dbl>, OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, #> #   AUC_mean <dbl>, AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, #> #   IMAE_mean <dbl>, IMAE_sd <dbl> # Note in rf_t1$performance the best model was the one with mtry = 3 and threshold = 'max_sens_spec' merge_df <- sdm_summarize(models = list(gam_t1, glm_t1, rf_t1))  merge_df #> # A tibble: 7 × 28 #>   model_ID model threshold      thr_value n_presences n_absences TPR_mean TPR_sd #>      <int> <chr> <chr>              <dbl>       <int>      <int>    <dbl>  <dbl> #> 1        1 gam   equal_sens_sp…     0.540         700        700    0.737 0.0366 #> 2        1 gam   max_sens_spec      0.530         700        700    0.751 0.0461 #> 3        1 gam   max_sorensen       0.359         700        700    0.864 0.0580 #> 4        2 glm   equal_sens_sp…     0.523         700        700    0.663 0.0583 #> 5        2 glm   max_sens_spec      0.463         700        700    0.803 0.111  #> 6        2 glm   max_sorensen       0.356         700        700    0.876 0.0436 #> 7        3 raf   max_sens_spec      0.606         700        700    0.924 0.0356 #> # ℹ 20 more variables: TNR_mean <dbl>, TNR_sd <dbl>, SORENSEN_mean <dbl>, #> #   SORENSEN_sd <dbl>, JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, #> #   FPB_sd <dbl>, OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, #> #   AUC_mean <dbl>, AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, #> #   IMAE_mean <dbl>, IMAE_sd <dbl>, mtry <dbl>, ntree <dbl>"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"raster-interpolation-between-two-time-periods","dir":"Articles","previous_headings":"Species occurrence, presence/absense and environmental data","what":"3. Raster interpolation between two time periods","title":"flexsdm: Overview of Post-modeling functions","text":"function useful calculating projected suitability values two time periods simple interpolation using two raster objects suitability values. useful , example, SDM projected future past time period (using maps predictor variables, climate variables, different time periods), user requires estimate suitability intermediate time periods. example may needed input types models risk analysis. function returns SpatRaster dir_save used NULL. However, user specifies dir_save, function save interpolated raster files given directory.  function create object interpolated values n annual layers ranging initial final year. resolution dimensions result object remain initial final maps. example, nine annual (2011-2019) interpolated maps generated initial (2010) final (2020) prediction maps. cell starting value 1 ending value 0 changed increments (1-0)/((2020-2010)-1), given interpolated values 0.9, 0.8, 0.7…0.1","code":"library(terra) library(dplyr)  f <- system.file(\"external/suit_time_step.tif\", package = \"flexsdm\") abma <- terra::rast(f) plot(abma) int <- interp(   r1 = abma[[1]], # set the raster of initial year   r2 = abma[[2]], # set the raster of final year   y1 = 2010, # set the numeric initial year   y2 = 2020, # set the numeric final year   rastername = \"Abies\",   dir_save = NULL )  # Layers in the abma SpatRaster names(abma) #> [1] \"current\" \"future\" # plot(abma)  # Layers in the int SpatRaster int #> class       : SpatRaster  #> size        : 558, 394, 11  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : suit_time_step  #>               suit_time_step  #>               suit_time_step  #>               ... #> names       : Abies_2010, Abies_2011, Abies_2012, Abies_2013, Abies_2014, Abies_2015, ...  #> min values  :  0.0000000,  0.0000000,  0.0000000,  0.0000000,  0.0000000,  0.0000000, ...  #> max values  :  0.9756107,  0.9606077,  0.9504615,  0.9440073,  0.9442941,  0.9463548, ... plot(int)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"measure-model-extrapolation","dir":"Articles","previous_headings":"Species occurrence, presence/absense and environmental data","what":"4. Measure model extrapolation","title":"flexsdm: Overview of Post-modeling functions","text":"function measures extent model extrapolation comparing data used modeling calibration area model projection using approach proposed Velazco et al., prep.  accessible area defines calibration area used extract environmental conditions","code":"library(dplyr) library(terra)  data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Inspect the unique values for species spp$species %>% unique() #> [1] \"sp1\" \"sp2\" \"sp3\"  # Subset spp data into a tibble only with coordinates for sp3 and pr_ab == 1 sp <- spp %>%   dplyr::filter(species == \"sp3\", pr_ab == 1) %>%   dplyr::select(x, y)  # Define accessible area for sp3 based on a buffer with around each point that is related to dispersal ability or some other ecological criterion ca <-   calib_area(     sp,     x = \"x\",     y = \"y\",     method = c(\"buffer\", width = 30000),     crs = crs(somevar)   )  # Plot the SpatRaster, occurrences and accessible area plot(somevar$CFP_1) points(sp) plot(ca, add = T) somevar_ca <- somevar %>%   crop(., ca) %>%   mask(., ca)  # Plot environmental conditions of the calibration area plot(somevar_ca) xp <-   extra_eval(     training_data = somevar_ca,     projection_data = somevar,     n_cores = 1,     aggreg_factor = 3   )  # Plot the SpatRaster object with the extrapolation values measured in percentage plot(xp)"},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"create-spatial-predictor-variables-to-reduce-overprediction-of-species-distribution-models","dir":"Articles","previous_headings":"Species occurrence, presence/absense and environmental data","what":"6. Create spatial predictor variables to reduce overprediction of species distribution models","title":"flexsdm: Overview of Post-modeling functions","text":"function creates geographical predictor variables , together environmental variables, can used construct constrained species distribution models. function returns SpatRaster object, used together environmental variables construct species distribution models. ‘xy’ approach creates single pair raster layers can used species share study region. Otherwise, ‘cml’, ‘min’, ‘ker’ create species-specific raster layer.  Next, use different methods according data.","code":"library(dplyr) library(terra)  data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Select the presences of one species (sp3) occ <- spp %>%   dplyr::filter(species == \"sp3\", pr_ab == 1)  # Select a raster layer to be used as a basic raster a_variable <- somevar[[1]] plot(a_variable) points(occ %>% dplyr::select(x, y)) # Use xy method m_xy <- msdm_priori(   data = occ,   x = \"x\",   y = \"y\",   method = \"xy\",   env_layer = a_variable )  plot(m_xy) # Explore the object. This method assumes that spatial structure can partially explain species distribution (Bahn & Mcgill, 2007). Therefore, the result are two raster layers containing the latitude and longitude of pixels, respectively. This method could be used for all species set that share the same study area region. m_xy #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varnames    : somevar  #>               somevar  #> names       :  msdm_lon,  msdm_lat  #> min values  : -370850.8, -601978.3  #> max values  :  368139.2,  448861.7 m_cml <- msdm_priori(   data = occ,   x = \"x\",   y = \"y\",   method = \"cml\",   env_layer = a_variable )  plot(m_cml) # Explore the object. This method assumes that pixels closer to presences are likely included in species distributions. The results is a raster layer containing the sum of euclidean geographic distances from each pixel to all occurrences of a species. m_cml #> class       : SpatRaster  #> size        : 558, 394, 1  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> varname     : somevar  #> name        : msdm_cml  #> min value   :        0  #> max value   :        1"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v03_post_modeling.html","id":"methods-to-correct-overprediction-of-species-distribution-models-based-on-occurrences-and-suitability-patterns","dir":"Articles","previous_headings":"Species occurrence, presence/absense and environmental data","what":"7. Methods to correct overprediction of species distribution models based on occurrences and suitability patterns","title":"flexsdm: Overview of Post-modeling functions","text":"methods designed reduce overprediction species distribution models based posteriori method (see Mendes et al 2020), .e., combination patterns species occurrences predicted suitability. First, prepare data Next, fit predict model Next, let’s predict model plot map  Finally, perform correction avoid models overpredictions.      #=========#=========#=========#=========#=========#=========#=========# Vignette still construction changes #=========#=========#=========#=========#=========#=========#=========#","code":"library(dplyr) library(terra)  data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Prepare data for modeling a species set.seed(10) occ <- spp %>%   dplyr::filter(species == \"sp2\") %>% # filter using only sp2   sdm_extract(     data = ., x = \"x\", y = \"y\",     env_layer = somevar, filter_na = TRUE   ) %>% # extract variables values from the raster layer   part_random(.,     pr_ab = \"pr_ab\",     method = c(method = \"kfold\", folds = 10)   ) # add columns with partition #> 6 rows were excluded from database because NAs were found m_glm <- fit_glm(   data = occ,   response = \"pr_ab\",   predictors = names(somevar),   partition = \".part\",   thr = \"equal_sens_spec\", ) #> Formula used for model fitting: #> pr_ab ~ CFP_1 + CFP_2 + CFP_3 + CFP_4 + I(CFP_1^2) + I(CFP_2^2) + I(CFP_3^2) + I(CFP_4^2) #> Replica number: 1/1 #> Partition number: 1/10 #> Partition number: 2/10 #> Partition number: 3/10 #> Partition number: 4/10 #> Partition number: 5/10 #> Partition number: 6/10 #> Partition number: 7/10 #> Partition number: 8/10 #> Partition number: 9/10 #> Partition number: 10/10 # Predict this model m_pred <- sdm_predict(models = m_glm, pred = somevar, thr = NULL, con_thr = FALSE) #> Predicting individual models  # Predicting individual models plot(m_pred[[1]]) # Using mcp method. The Minimum Convex Polygon (mcp) method excludes from SDMs climate suitable pixels that do not intercept a minimum convex polygon, with interior angles smaller than 180, enclosing all occurrences of a species. m_mcp <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"mcp\",   cont_suit = m_pred[[1]],   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_mcp) # Using bmcp method. The Buffered Minimum Convex Polygon (bmcp) method is similar to the 'mcp' except by the inclusion of a buffer zone surrounding minimum convex polygons. m_bmcp <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"bmcp\",   cont_suit = m_pred[[1]],   thr = \"equal_sens_spec\",   buffer = 30000,   crs = crs(m_pred[[1]]) )  plot(m_bmcp) # Using obr method. The Occurrences Based Restriction (obr) method assumes that suitable patches intercepting species occurrences are more likely a part of species distributions than suitable patches that do not intercept any occurrence. m_obr <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"obr\",   cont_suit = m_pred[[1]],   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_obr) # Using pres method. The only occurrences based restriction (pres) method only retains those pixels in suitability patches intercepting occurrences. m_pres <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"pres\",   cont_suit = m_pred[[1]],   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_pres) # Using lq method. The Lower Quantile (lq) method works whenever a suitable pixel is within a k patch, i.e., not within this lower quartile, the suitability of the pixel is reduced to zero. This means that 75% of k patches were withdrawn from the model. m_lq <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"lq\",   cont_suit = m_pred[[1]],   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_lq)"},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"study-species-overview-of-methods","dir":"Articles","previous_headings":"Example of full modeling process","what":"Study species & overview of methods","title":"flexsdm: Red Fir example","text":", used flexsdm package model current distribution California red fir (Abies magnifica). Red fir high-elevation conifer species ’s geographic range extends Sierra Nevada California, USA, southern portion Cascade Range Oregon. species, used presence data compiled several public datasets curated natural resources agencies. built distribution models using four hydro-climatic variables: actual evapotranspiration, climatic water deficit, maximum temperature warmest month, minimum temperature coldest month. variables resampled (aggregated) 1890 m spatial resolution improve processing time.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"delimit-of-a-calibration-area","dir":"Articles","previous_headings":"Example of full modeling process","what":"Delimit of a calibration area","title":"flexsdm: Red Fir example","text":"Delimiting calibration area (aka accessible area) essential step SDMs methodological theoretical terms. calibration area affect several characteristics SDM like range environmental variables, number absences, distribution background points pseudo-absences, unfortunately, performance metrics like AUC TSS. several ways delimit calibration area. calib_area(). used method calibration area delimited 100-km buffer around presences (shown figure ).","code":"# devtools::install_github('sjevelazco/flexsdm') library(flexsdm) library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies) abies_p <- abies %>%   select(x, y, pr_ab) %>%   filter(pr_ab == 1) # filter only for presence locations  ca <-   calib_area(     data = abies_p,     x = \"x\",     y = \"y\",     method = c(\"buffer\", width = 100000),     crs = crs(somevar)   ) # create a calibration area with 100 km buffer around occurrence points  # visualize the species occurrences layer1 <- somevar[[1]] layer1[!is.na(layer1)] <- 1  plot(layer1, col = \"gray80\", legend = FALSE, axes = FALSE) plot(crop(ca, layer1), add = TRUE) points(abies_p[, c(\"x\", \"y\")], col = \"#00000480\")"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"occurrence-filtering","dir":"Articles","previous_headings":"Example of full modeling process","what":"Occurrence filtering","title":"flexsdm: Red Fir example","text":"Sample bias species occurrence data long recognized issue SDM. However, environmental filtering observation data can improve model predictions reducing redundancy environmental (e.g. climatic) hyper-space (Varela et al. 2014). use function occfilt_env() thin red fir occurrences based environmental space. function unique flexsdm, contrast packages able use number environmental dimensions perform PCA filtering. Next apply environmental occurrence filtering using 8 bins display resulting filtered occurrence data","code":"abies_p$id <- 1:nrow(abies_p) # adding unique id to each row abies_pf <- abies_p %>%   occfilt_env(     data = .,     x = \"x\",     y = \"y\",     id = \"id\",     nbins = 8,     env_layer = somevar   ) %>%   left_join(abies_p, by = c(\"id\", \"x\", \"y\")) #> Extracting values from raster ... #> 27 records were removed because they have NAs for some variables #> Number of unfiltered records: 673 #> Number of filtered records: 216  plot(layer1, col = \"gray80\", legend = FALSE, axes = FALSE) plot(crop(ca, layer1), add = TRUE) points(abies_p[, c(\"x\", \"y\")], col = \"#00000480\") points(abies_pf[, c(\"x\", \"y\")], col = \"#5DC86180\")"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"block-partition-with-4-folds","dir":"Articles","previous_headings":"Example of full modeling process","what":"Block partition with 4 folds","title":"flexsdm: Red Fir example","text":"Data partitioning, splitting data testing training groups, key step building SDMs. flexsdm offers multiple options data partitioning use spatial block method. Geographically structured data partitioning methods especially useful users want evaluate model transferability different regions time periods. part_sblock() function explores spatial blocks different raster cells sizes returns one best suited input datset based spatial autocorrelation, environmental similarity, number presence/absence records block partition. function’s output provides users 1) tibble presence/absence locations assigned partition number, 2) tibble information best partition, 3) SpatRaster showing selected grid. want divide data 4 different partitions using spatial block method.","code":"set.seed(10) occ_part <- abies_pf %>%   part_sblock(     data = .,     env_layer = somevar,     pr_ab = \"pr_ab\",     x = \"x\",     y = \"y\",     n_part = 4,     min_res_mult = 3,     max_res_mult = 200,     num_grids = 30,     prop = 1   ) #> The following grid cell sizes will be tested: #> 5670 | 18508.97 | 31347.93 | 44186.9 | 57025.86 | 69864.83 | 82703.79 | 95542.76 | 108381.72 | 121220.69 | 134059.66 | 146898.62 | 159737.59 | 172576.55 | 185415.52 | 198254.48 | 211093.45 | 223932.41 | 236771.38 | 249610.34 | 262449.31 | 275288.28 | 288127.24 | 300966.21 | 313805.17 | 326644.14 | 339483.1 | 352322.07 | 365161.03 | 378000 #> Creating basic raster mask... #> Searching for the optimal grid size... abies_pf <- occ_part$part  # Transform best block partition to a raster layer with same resolution and extent than # predictor variables block_layer <- get_block(env_layer = somevar, best_grid = occ_part$grid)  cl <- c(\"#64146D\", \"#9E2962\", \"#F47C15\", \"#FCFFA4\") plot(block_layer, col = cl, legend = FALSE, axes = FALSE) points(abies_pf[, c(\"x\", \"y\")]) # Number of presences per block abies_pf %>%   dplyr::group_by(.part) %>%   dplyr::count() #> # A tibble: 4 × 2 #> # Groups:   .part [4] #>   .part     n #>   <int> <int> #> 1     1    38 #> 2     2    59 #> 3     3    33 #> 4     4    86 # Additional information of the best block occ_part$best_part_info #> # A tibble: 1 × 5 #>   n_grid cell_size spa_auto env_sim  sd_p #>    <int>     <dbl>    <dbl>   <dbl> <dbl> #> 1     14   172577.      0.5    173.  24.1"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"pseudo-absencebackground-points-using-partition-previously-created-as-a-mask","dir":"Articles","previous_headings":"Example of full modeling process","what":"Pseudo-absence/background points (using partition previously created as a mask)","title":"flexsdm: Red Fir example","text":"example, species presence data. However, SDM methods require either pseudo-absence background data. , use spatial block partition just created generate pseudo-absence background points.  Extract environmental data presence-absence background data . View distributions present points, pseudo-absence points, background points using blocks reference map.","code":"# Spatial blocks where species occurs # Sample background points throughout study area with random method, allocating 10X the number of presences a background set.seed(10) bg <- lapply(1:4, function(x) {   sample_background(     data = abies_pf,     x = \"x\",     y = \"y\",     n = sum(abies_pf$.part == x) * 10,     method = \"random\",     rlayer = block_layer,     maskval = x,     calibarea = ca   ) }) %>%   bind_rows() bg <- sdm_extract(data = bg, x = \"x\", y = \"y\", env_layer = block_layer)  # Sample a number of pseudo-absences equal to the presence in each partition set.seed(10) psa <- lapply(1:4, function(x) {   sample_pseudoabs(     data = abies_pf,     x = \"x\",     y = \"y\",     n = sum(abies_pf$.part == x),     method = \"random\",     rlayer = block_layer,     maskval = x,     calibarea = ca   ) }) %>%   bind_rows() psa <- sdm_extract(data = psa, x = \"x\", y = \"y\", env_layer = block_layer)  cl <- c(\"#280B50\", \"#9E2962\", \"#F47C15\", \"#FCFFA4\") plot(block_layer, col = \"gray80\", legend = FALSE, axes = FALSE) points(bg[, c(\"x\", \"y\")], col = cl[bg$.part], cex = 0.8) # Background points points(psa[, c(\"x\", \"y\")], bg = cl[psa$.part], cex = 0.8, pch = 21) # Pseudo-absences # Bind a presences and pseudo-absences abies_pa <- bind_rows(abies_pf, psa) abies_pa # Presence-Pseudo-absence database #> # A tibble: 432 × 4 #>          x        y pr_ab .part #>      <dbl>    <dbl> <dbl> <dbl> #>  1 -12558.   68530.     1     2 #>  2 115217. -145937.     1     4 #>  3   3634.   22501.     1     2 #>  4  44972.  -60781.     1     2 #>  5 -34463.  160313.     1     3 #>  6  83108.  -27300.     1     2 #>  7 124877. -176319.     1     4 #>  8 118707. -179991.     1     4 #>  9 126141. -176302.     1     4 #> 10 -49722.  141124.     1     3 #> # ℹ 422 more rows bg # Background points #> # A tibble: 2,160 × 4 #>           x       y pr_ab .part #>       <dbl>   <dbl> <dbl> <dbl> #>  1 -153501. 392162.     0     1 #>  2  -89241. 263642.     0     1 #>  3  -89241.  27392.     0     1 #>  4 -130821. 331682.     0     1 #>  5 -132711. 339242.     0     1 #>  6  -51441. -63328.     0     1 #>  7  -59001.  67082.     0     1 #>  8  -32541. -51988.     0     1 #>  9  -96801.    932.     0     1 #> 10  -47661. -31198.     0     1 #> # ℹ 2,150 more rows abies_pa <- abies_pa %>%   sdm_extract(     data = .,     x = \"x\",     y = \"y\",     env_layer = somevar,     filter_na = TRUE   ) bg <- bg %>%   sdm_extract(     data = .,     x = \"x\",     y = \"y\",     env_layer = somevar,     filter_na = TRUE   )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"fit-models-with-tune_max-fit_gau-and-fit_glm","dir":"Articles","previous_headings":"Example of full modeling process","what":"Fit models with tune_max, fit_gau, and fit_glm","title":"flexsdm: Red Fir example","text":"Now, fit models. flexsdm package offers wide range modeling options, traditional statistical methods like GLMs GAMs, machine learning methods like random forests support vector machines. modeling method, flexsdm provides fit_ tune_ functions, allow users use default settings adjust hyperparameters depending research goals. , test tune_max() (tuned Maximum Entropy model), fit_gau() (fit Guassian Process model), fit_glm (fit Generalized Linear Model). model, selected three threshold values generate binary suitability predictions: threshold maximizes TSS (max_sens_spec), threshold sensitivity specificity equal (equal_sens_spec), threshold Sorenson index highest (max_sorenson). example, selected TSS performance metric used selecting best combination hyper-parameter values tuned Maximum Entropy model.","code":"t_max <- tune_max(   data = abies_pa,   response = \"pr_ab\",   predictors = names(somevar),   background = bg,   partition = \".part\",   grid = expand.grid(     regmult = seq(0.1, 3, 0.5),     classes = c(\"l\", \"lq\", \"lqhpt\")   ),   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   metric = \"TSS\",   clamp = TRUE,   pred_type = \"cloglog\" ) #> Tuning model... #> Replica number: 1/1 #> Partition number: 1/4 #> Partition number: 2/4 #> Partition number: 3/4 #> Partition number: 4/4 #> Fitting best model #> Formula used for model fitting: #> ~aet + cwd + tmx + tmn + I(aet^2) + I(cwd^2) + I(tmx^2) + I(tmn^2) + hinge(aet) + hinge(cwd) + hinge(tmx) + hinge(tmn) + thresholds(aet) + thresholds(cwd) + thresholds(tmx) + thresholds(tmn) + cwd:aet + tmx:aet + tmn:aet + tmx:cwd + tmn:cwd + tmn:tmx - 1 #> Replica number: 1/1 #> Partition number: 1/4 #> Partition number: 2/4 #> Partition number: 3/4 #> Partition number: 4/4 f_gau <- fit_gau(   data = abies_pa,   response = \"pr_ab\",   predictors = names(somevar),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") ) #> Replica number: 1/1 #> Partition number: 1/4 #> Partition number: 2/4 #> Partition number: 3/4 #> Partition number: 4/4 f_glm <- fit_glm(   data = abies_pa,   response = \"pr_ab\",   predictors = names(somevar),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   poly = 2 ) #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmx + tmn + I(aet^2) + I(cwd^2) + I(tmx^2) + I(tmn^2) #> Replica number: 1/1 #> Partition number: 1/4 #> Partition number: 2/4 #> Partition number: 3/4 #> Partition number: 4/4"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"fit-an-ensemble-model","dir":"Articles","previous_headings":"Example of full modeling process","what":"Fit an ensemble model","title":"flexsdm: Red Fir example","text":"Spatial predictions different SDM algorithms can vary substantially, ensemble modeling become increasingly popular. fit_ensemble() function, users can easily produce ensemble SDM based individual fit_ tune_ models included package. example, fit ensemble model red fir based weighted average three individual models. used threshold values performance metric implemented individual models. output flexsdm model objects allows easily compare metrics across models, AUC TSS. example, can use sdm_summarize() function merge model performance tables.","code":"ens_m <- fit_ensemble(   models = list(t_max, f_gau, f_glm),   ens_method = \"meanw\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   thr_model = \"max_sens_spec\",   metric = \"TSS\" ) #>   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% ens_m$performance #> # A tibble: 3 × 25 #>   model threshold      thr_value n_presences n_absences TPR_mean TPR_sd TNR_mean #>   <chr> <chr>              <dbl>       <int>      <int>    <dbl>  <dbl>    <dbl> #> 1 meanw equal_sens_sp…     0.582         216        216    0.787 0.0795    0.808 #> 2 meanw max_sens_spec      0.470         216        216    0.949 0.0162    0.752 #> 3 meanw max_sorensen       0.449         216        216    0.963 0.0143    0.738 #> # ℹ 17 more variables: TNR_sd <dbl>, SORENSEN_mean <dbl>, SORENSEN_sd <dbl>, #> #   JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, FPB_sd <dbl>, #> #   OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, AUC_mean <dbl>, #> #   AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, IMAE_mean <dbl>, #> #   IMAE_sd <dbl> model_perf <- sdm_summarize(list(t_max, f_gau, f_glm, ens_m)) model_perf #> # A tibble: 10 × 28 #>    model_ID model threshold     thr_value n_presences n_absences TPR_mean TPR_sd #>       <int> <chr> <chr>             <dbl>       <int>      <int>    <dbl>  <dbl> #>  1        1 max   max_sens_spec     0.364         216        216    0.954 0.0316 #>  2        2 gau   equal_sens_s…     0.643         216        216    0.784 0.0890 #>  3        2 gau   max_sens_spec     0.471         216        216    0.952 0.0122 #>  4        2 gau   max_sorensen      0.471         216        216    0.964 0.0108 #>  5        3 glm   equal_sens_s…     0.649         216        216    0.800 0.0851 #>  6        3 glm   max_sens_spec     0.554         216        216    0.954 0.0493 #>  7        3 glm   max_sorensen      0.423         216        216    0.977 0.0379 #>  8        4 meanw equal_sens_s…     0.582         216        216    0.787 0.0795 #>  9        4 meanw max_sens_spec     0.470         216        216    0.949 0.0162 #> 10        4 meanw max_sorensen      0.449         216        216    0.963 0.0143 #> # ℹ 20 more variables: TNR_mean <dbl>, TNR_sd <dbl>, SORENSEN_mean <dbl>, #> #   SORENSEN_sd <dbl>, JACCARD_mean <dbl>, JACCARD_sd <dbl>, FPB_mean <dbl>, #> #   FPB_sd <dbl>, OR_mean <dbl>, OR_sd <dbl>, TSS_mean <dbl>, TSS_sd <dbl>, #> #   AUC_mean <dbl>, AUC_sd <dbl>, BOYCE_mean <dbl>, BOYCE_sd <dbl>, #> #   IMAE_mean <dbl>, IMAE_sd <dbl>, regmult <dbl>, classes <fct>"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"project-the-ensemble-model","dir":"Articles","previous_headings":"Example of full modeling process","what":"Project the ensemble model","title":"flexsdm: Red Fir example","text":"Next project ensemble model space across entire extent environmental layer, California Floristic Province, using sdm_predict() function. function can use predict species suitability across area species’ current future suitability. example, project ensemble model one threshold, though users option project multiple models multiple threshold values. , also specify want function return SpatRast continuous suitability values threshold (con_thr = TRUE).","code":"pr_1 <- sdm_predict(   models = ens_m,   pred = somevar,   thr = \"max_sens_spec\",   con_thr = TRUE,   predict_area = NULL ) #> Predicting ensembles  unconstrained <- pr_1$meanw[[1]] names(unconstrained) <- \"unconstrained\"  cl <- c(\"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\", \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\") plot(unconstrained, col = cl, legend = FALSE, axes = FALSE)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v04_Red_fir_example.html","id":"constrain-the-model-with-msdm_posterior","dir":"Articles","previous_headings":"Example of full modeling process","what":"Constrain the model with msdm_posterior","title":"flexsdm: Red Fir example","text":"Finally, flexsdm offers users function help correct overprediction SDM based occurrence records suitability patterns. example constrained ensemble model using method “occurrence based restriction”, assumes suitable patches intercept species occurrences likely part species distributions suitable patches intercept occurrences. methods msdm_posteriori() function work presences important always use original database (.e., presences spatially environmentally filtered). methods available msdm_posteriori() function based Mendes et al. (2020). #=========#=========#=========#=========#=========#=========#=========# Vignette still construction changes #=========#=========#=========#=========#=========#=========#=========#","code":"thr_val <- ens_m$performance %>%   dplyr::filter(threshold == \"max_sens_spec\") %>%   pull(thr_value) m_pres <- msdm_posteriori(   records = abies_p,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   cont_suit = pr_1$meanw[[1]],   method = c(\"obr\"),   thr = c(\"sensitivity\", sens = thr_val),   buffer = NULL )  constrained <- m_pres$meanw[[1]] names(constrained) <- \"constrained\"  cl <- c(\"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\", \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\") plot(constrained, col = cl, legend = FALSE, axes = FALSE)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"intro","dir":"Articles","previous_headings":"","what":"Intro","title":"flexsdm: Modeling a rare species","text":"Creating SDMs rare poorly known species can difficult task. Occurrence data often limited observation, can lead model overfitting, especially using many predictor variables build models. However, researchers often interested building SDMs rare species, often threatened need conservation action. address issues associated modeling spatial distributions rare species, Lomba et al. (2010) Breiner et al. (2015) proposed method “ensemble small models” ESM. ESM, many bivariate models pairwise combinations predictor variable, ensemble performed. flexsdm, ensemble created using average suitability across “small models”, weighted Somers’ D (D = 2 * (AUC-.5)). important note method allow use categorical variables (soil type). practical applications ESMs include identifying areas reintroduction rare species areas establishing new populations, especially face climate change. example, Dubos et al. (2021) used variation ESM identify areas may remain suitable climate change two rare species Madagascar: golden mantella frog (Mantella aurantiaca) Manapany day gecko (Phelsuma inexpectata). example, walk process comparing ESM traditional modeling approaches Hesperocyparis stephensonii (Cuyamaca cypress), conifer tree species endemic southern California. species listed Critically Endangered IUCN found headwaters King Creek San Diego County. Cedar Fire 2003 left 30-40 surviving trees. hypothetical example, searching suitable areas might possible establish new populations species, hopes decreasing species’ future extinction risk.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"data","dir":"Articles","previous_headings":"Intro","what":"Data","title":"flexsdm: Modeling a rare species","text":"models, use four environmental variables influence plant distributions California: available evapotranspiration (aet), climatic water deficit (cwd), maximum temperature warmest month (tmx), minimum temperature coldest month (tmn). occurrence data include 21 geo-referenced observations downloaded online database Calflora.","code":"# devtools::install_github('sjevelazco/flexsdm') library(flexsdm) library(terra) library(dplyr)  # environmental data somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\")  # species occurence data (presence-only) data(hespero) hespero <- hespero %>% dplyr::select(-id)  # California ecoregions regions <- system.file(\"external/regions.tif\", package = \"flexsdm\") regions <- terra::rast(regions) regions <- as.polygons(regions) sp_region <- terra::subset(regions, regions$category == \"SCR\") # ecoregion where *Hesperocyparis stephensonii* is found  # visualize the species occurrences plot(   sp_region,   col = \"gray80\",   legend = FALSE,   axes = FALSE,   main = \"Hesperocyparis stephensonii occurrences\" ) points(hespero[, c(\"x\", \"y\")], col = \"black\", pch = 16) cols <- rep(\"gray80\", 8) cols[regions$category == \"SCR\"] <- \"yellow\" terra::inset(   regions,   loc = \"bottomleft\",   scale = .3,   col = cols )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"delimit-calibration-area","dir":"Articles","previous_headings":"Intro","what":"Delimit calibration area","title":"flexsdm: Modeling a rare species","text":"First, must define model’s calibration area. flexsdm package offers several methods defining model calibration area. , use 25-km buffer areas around presence points select pseudo-absence locations.","code":"ca <- calib_area(   data = hespero,   x = \"x\",   y = \"y\",   method = c(\"buffer\", width = 25000),   crs = crs(somevar) )  # visualize the species occurrences & calibration area plot(   sp_region,   col = \"gray80\",   legend = FALSE,   axes = FALSE,   main = \"Calibration area and occurrences\" ) plot(ca, add = TRUE) points(hespero[, c(\"x\", \"y\")], col = \"black\", pch = 16)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"create-pseudo-absence-data","dir":"Articles","previous_headings":"Intro","what":"Create pseudo-absence data","title":"flexsdm: Modeling a rare species","text":"often case rare species, species presence data. However, SDM methods require either pseudo-absence background data. , use calibration area produce pseudo-absence data can used SDMs.","code":"# Sample the same number of species presences set.seed(10) psa <- sample_pseudoabs(   data = hespero,   x = \"x\",   y = \"y\",   n = sum(hespero$pr_ab), # selecting number of pseudo-absence points that is equal to number of presences   method = \"random\",   rlayer = somevar,   calibarea = ca )  # Visualize species presences and pseudo-absences plot(   sp_region,   col = \"gray80\",   legend = FALSE,   axes = FALSE,   xlim = c(289347, 353284),   ylim = c(-598052, -520709),   main = \"Presence = yellow, Pseudo-absence = black\" ) plot(ca, add = TRUE) points(psa[, c(\"x\", \"y\")], cex = 0.8, pch = 16, col = \"black\") # Pseudo-absences points(hespero[, c(\"x\", \"y\")], col = \"yellow\", pch = 16, cex = 1.5) # Presences # Bind a presences and pseudo-absences hespero_pa <- bind_rows(hespero, psa) hespero_pa # Presence-Pseudo-absence database #> # A tibble: 42 × 3 #>          x        y pr_ab #>      <dbl>    <dbl> <dbl> #>  1 316923. -557843.     1 #>  2 317155. -559234.     1 #>  3 316960. -558186.     1 #>  4 314347. -559648.     1 #>  5 317348. -557349.     1 #>  6 316753. -559679.     1 #>  7 316777. -558644.     1 #>  8 317050. -559043.     1 #>  9 316655. -559928.     1 #> 10 316418. -567439.     1 #> # ℹ 32 more rows"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"partition-data-for-evaluating-models","dir":"Articles","previous_headings":"Intro","what":"Partition data for evaluating models","title":"flexsdm: Modeling a rare species","text":"evaluate model performance, need specify data testing training. flexsdm offers range random spatial random data partition methods evaluating SDMs. use repeated K-fold cross-validation, suitable partition approach performing ESM.","code":"set.seed(10)  # Repeated K-fold method hespero_pa2 <- part_random(   data = hespero_pa,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 5, replicates = 10) )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"extracting-environmental-values","dir":"Articles","previous_headings":"Intro","what":"Extracting environmental values","title":"flexsdm: Modeling a rare species","text":"Next, extract values four environmental predictors presence pseudo-absence locations.","code":"hespero_pa3 <-   sdm_extract(     data = hespero_pa2,     x = \"x\",     y = \"y\",     env_layer = somevar,     variables = c(\"aet\", \"cwd\", \"tmx\", \"tmn\")   )"},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"standard-models","dir":"Articles","previous_headings":"Intro > Modeling","what":"Standard models","title":"flexsdm: Modeling a rare species","text":"First, let’s use three standard algorithms model distribution Hesperocyparis stephensonii: GLM, GBM, SVM. case, use calibration area making predictions.","code":"mglm <-   fit_glm(     data = hespero_pa3,     response = \"pr_ab\",     predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),     partition = \".part\",     thr = \"max_sens_spec\"   ) #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmx + tmn + I(aet^2) + I(cwd^2) + I(tmx^2) + I(tmn^2) #> Replica number: 1/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 2/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 3/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 4/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 5/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 6/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 7/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 8/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 9/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 10/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5  mgbm <- fit_gbm(   data = hespero_pa3,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = \"max_sens_spec\" ) #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmx + tmn #> Replica number: 1/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 2/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 3/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 4/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 5/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 6/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 7/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 8/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 9/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 10/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5  msvm <- fit_svm(   data = hespero_pa3,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = \"max_sens_spec\" ) #> Formula used for model fitting: #> pr_ab ~ aet + cwd + tmx + tmn #> Replica number: 1/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 2/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 3/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 4/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 5/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 6/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 7/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 8/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 9/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5 #> Replica number: 10/10 #> Partition number: 1/5 #> Partition number: 2/5 #> Partition number: 3/5 #> Partition number: 4/5 #> Partition number: 5/5   mpred <- sdm_predict(   models = list(mglm, mgbm, msvm),   pred = somevar,   con_thr = TRUE,   predict_area = ca ) #> Predicting list of individual models"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"ensemble-of-small-models","dir":"Articles","previous_headings":"Intro > Modeling","what":"Ensemble of small models","title":"flexsdm: Modeling a rare species","text":"Now let’s try algorithms ESM approach. Note predicting ESM, possible process one time.","code":"eglm <-   esm_glm(     data = hespero_pa3,     response = \"pr_ab\",     predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),     partition = \".part\",     thr = \"max_sens_spec\"   ) #>   |                                                                              |                                                                      |   0%  |                                                                              |============                                                          |  17%  |                                                                              |=======================                                               |  33%  |                                                                              |===================================                                   |  50%  |                                                                              |===============================================                       |  67%  |                                                                              |==========================================================            |  83%  |                                                                              |======================================================================| 100%  egbm <- esm_gbm(   data = hespero_pa3,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = \"max_sens_spec\" ) #>   |                                                                              |                                                                      |   0%  |                                                                              |============                                                          |  17%  |                                                                              |=======================                                               |  33%  |                                                                              |===================================                                   |  50%  |                                                                              |===============================================                       |  67%  |                                                                              |==========================================================            |  83%  |                                                                              |======================================================================| 100%  esvm <- esm_svm(   data = hespero_pa3,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = \"max_sens_spec\" ) #>   |                                                                              |                                                                      |   0%  |                                                                              |============                                                          |  17%  |                                                                              |=======================                                               |  33%  |                                                                              |===================================                                   |  50%  |                                                                              |===============================================                       |  67%  |                                                                              |==========================================================            |  83%  |                                                                              |======================================================================| 100%   eglm_pred <- sdm_predict(   models = eglm,   pred = somevar,   con_thr = TRUE,   predict_area = ca ) #> Predicting ensemble of small models  egbm_pred <- sdm_predict(   models = egbm,   pred = somevar,   con_thr = TRUE,   predict_area = ca ) #> Predicting ensemble of small models  esvm_pred <- sdm_predict(   models = esvm,   pred = somevar,   con_thr = TRUE,   predict_area = ca ) #> Predicting ensemble of small models"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"comparing-our-models","dir":"Articles","previous_headings":"Intro","what":"Comparing our models","title":"flexsdm: Modeling a rare species","text":"First, let’s take look spatial predictions models. spatial outputs suggest standard models tend predict broader areas high suitability values ESMs.  Next, look performance metrics models, based repeated k-folds cross-validation partition method. can easily done using “sdm_summarize()” function flexsdm. , can see AUC, TSS, Jaccard index higher ESMs corresponding standard model. However, Boyce index Inverse Mean Absolute Error slightly higher standard models.","code":"par(mfrow = c(3, 2)) plot(mpred$glm, main = \"Standard GLM\") # points(hespero$x, hespero$y, pch = 19) plot(eglm_pred[[1]], main = \"ESM GLM\") # points(hespero$x, hespero$y, pch = 19) plot(mpred$gbm, main = \"Standard GBM\") # points(hespero$x, hespero$y, pch = 19) plot(egbm_pred[[1]], main = \"ESM GBM\") # points(hespero$x, hespero$y, pch = 19) plot(mpred$svm, main = \"Standard SVM\") # points(hespero$x, hespero$y, pch = 19) plot(esvm_pred[[1]], main = \"ESM SVM\") # points(hespero$x, hespero$y, pch = 19) merge_df <- sdm_summarize(models = list(mglm, mgbm, msvm, eglm, egbm, esvm))  knitr::kable(   merge_df %>% dplyr::select(     model,     AUC = AUC_mean,     TSS = TSS_mean,     JACCARD = JACCARD_mean,     BOYCE = BOYCE_mean,     IMAE = IMAE_mean   ) )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"conclusions","dir":"Articles","previous_headings":"Intro","what":"Conclusions","title":"flexsdm: Modeling a rare species","text":"Modeling decisions context-dependent must made case--case basis. However, ESM useful approach practitioners interested modeling rare species want avoid common model overfitting issues. always producing SDMs “real-world” applications, important consider spatial prediction patterns along multiple model performance metrics.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v05_Rare_species_example.html","id":"references","dir":"Articles","previous_headings":"Intro","what":"References","title":"flexsdm: Modeling a rare species","text":"Lomba, ., L. Pellissier, C. Randin, J. Vicente, F. Moreira, J. Honrado, . Guisan. 2010. Overcoming rare species modelling paradox: novel hierarchical framework applied Iberian endemic plant. Biological conservation 143:2647–2657. https://doi.org/10.1016/j.biocon.2010.07.007 Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210–1218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802–808. https://doi.org/10.1111/2041-210X.12957 Dubos, N., Montfort, F., Grinand, C., Nourtier, M., Deso, G., Probst, J.-M., Razafimanahaka, J. H., Andriantsimanarilafy, R. R., Rakotondrasoa, E. F., Razafindraibe, P., Jenkins, R., & Crottini, . (2021). narrow-ranging species doomed extinction? Projected dramatic decline future climate suitability two highly threatened species. Perspectives Ecology Conservation, S2530064421000894. https://doi.org/10.1016/j.pecon.2021.10.002","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"Many SDM applications require model extrapolation, e.g., predictions beyond range data set used fit model. example, models often must extrapolate predicting habitat suitability novel environmental conditions induced climate change predicting spread invasive species outside native range based species-environment relationship observed native range. flexsdm, offer new approach (known Shape) evaluating extrapolation truncating spatial predictions based degree extrapolation measured. Shape model-agnostic approach calculating degree extrapolation given projection data point multivariate distance nearest training data point – capturing often complex shape data within environmental space. distances relativized factor reflects dispersion training data environmental space. implemented flexsdm, Shape approach also incorporates adjustable threshold allow binary discrimination acceptable unacceptable degrees extrapolation, based user’s needs applications. information Shape metric, recommend reading article Velazco et al., 2023. vignette, walk evaluate model extrapolation Hesperocyparis stephensonii (Cuyamaca cypress), conifer tree species endemic southern California. species listed Critically Endangered IUCN extremely restricted distribution, found headwaters King Creek San Diego County. Note: tutorial follows generally workflow vignette modeling distribution rare species using ensemble small models (ESM). However, instead constructing ESMs, evaluate model extrapolation predict models extent California Floristic Province (CFP).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"models, use four environmental variables influence plant distributions California: available evapotranspiration (aet), climatic water deficit (cwd), maximum temperature warmest month (tmx), minimum temperature coldest month (tmn). occurrence data include 21 geo-referenced observations downloaded online database Calflora.","code":"library(flexsdm) library(terra) library(dplyr) library(patchwork)  # environmental data somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) names(somevar) <- c(\"cwd\", \"tmn\", \"aet\", \"ppt_jja\")  # species occurence data (presence-only) data(hespero) hespero <- hespero %>% dplyr::select(-id)  # California ecoregions regions <- system.file(\"external/regions.tif\", package = \"flexsdm\") regions <- terra::rast(regions) regions <- terra::as.polygons(regions) sp_region <- terra::subset(regions, regions$category == \"SCR\") # ecoregion where *Hesperocyparis stephensonii* is found  # visualize the species occurrences plot(   sp_region,   col = \"gray80\",   legend = FALSE,   axes = FALSE,   main = \"Hesperocyparis stephensonii occurrences\" ) points(hespero[, c(\"x\", \"y\")], col = \"black\", pch = 16) cols <- rep(\"gray80\", 8) cols[regions$category == \"SCR\"] <- \"yellow\" terra::inset(   regions,   loc = \"bottomleft\",   scale = .3,   col = cols )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"delimit-calibration-area","dir":"Articles","previous_headings":"","what":"Delimit calibration area","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"First, must define model’s calibration area. flexsdm package offers several methods defining model calibration area. , use 25-km buffer areas around presence points select pseudo-absence locations.","code":"ca <- calib_area(   data = hespero,   x = \"x\",   y = \"y\",   method = c(\"buffer\", width = 25000),   crs = crs(somevar) )  # visualize the species occurrences & calibration area plot(   sp_region,   col = \"gray80\",   legend = FALSE,   axes = FALSE,   main = \"Calibration area and occurrences\" ) plot(ca, add = TRUE) points(hespero[, c(\"x\", \"y\")], col = \"black\", pch = 16)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"create-pseudo-absence-data","dir":"Articles","previous_headings":"","what":"Create pseudo-absence data","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"often case rare species, species presence data. However, SDM methods require either pseudo-absence background point data. , use calibration area produce pseudo-absence data can used SDMs.","code":"# Sample the same number of species presences set.seed(10) psa <- sample_pseudoabs(   data = hespero,   x = \"x\",   y = \"y\",   n = sum(hespero$pr_ab), # number of pseudo-absence points equal to number of presences   method = \"random\",   rlayer = somevar,   calibarea = ca )  # Visualize species presences and pseudo-absences plot(   sp_region,   col = \"gray80\",   legend = FALSE,   axes = FALSE,   xlim = c(289347, 353284),   ylim = c(-598052, -520709),   main = \"Presence = yellow, Pseudo-absence = black\" ) plot(ca, add = TRUE) points(psa[, c(\"x\", \"y\")], cex = 0.8, pch = 16, col = \"black\") # Pseudo-absences points(hespero[, c(\"x\", \"y\")], col = \"yellow\", pch = 16, cex = 1.5) # Presences # Bind a presences and pseudo-absences hespero_pa <- bind_rows(hespero, psa) hespero_pa # Presence-Pseudo-absence database #> # A tibble: 42 × 3 #>          x        y pr_ab #>      <dbl>    <dbl> <dbl> #>  1 316923. -557843.     1 #>  2 317155. -559234.     1 #>  3 316960. -558186.     1 #>  4 314347. -559648.     1 #>  5 317348. -557349.     1 #>  6 316753. -559679.     1 #>  7 316777. -558644.     1 #>  8 317050. -559043.     1 #>  9 316655. -559928.     1 #> 10 316418. -567439.     1 #> # ℹ 32 more rows"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"partition-data-for-evaluating-models","dir":"Articles","previous_headings":"","what":"Partition data for evaluating models","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"evaluate model performance, need specify data testing training. flexsdm offers range random spatial random data partition methods evaluating SDMs. use repeated K-fold cross-validation, suitable partition approach validating SDM data.","code":"set.seed(10)  # Repeated K-fold method hespero_pa2 <- part_random(   data = hespero_pa,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 5, replicates = 10) )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"extracting-environmental-values","dir":"Articles","previous_headings":"","what":"Extracting environmental values","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"Next, extract values four environmental predictors presence pseudo-absence locations.","code":"hespero_pa3 <-   sdm_extract(     data = hespero_pa2,     x = \"x\",     y = \"y\",     env_layer = somevar,     variables = c(\"cwd\", \"tmn\", \"aet\", \"ppt_jja\")   )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"modeling","dir":"Articles","previous_headings":"","what":"Modeling","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"Let’s use three standard algorithms model distribution Hesperocyparis stephensonii: GLM, GBM, SVM. case, use extent CFP prediction area can evaluate model extrapolation across broad geographic area.","code":"mglm <-   fit_glm(     data = hespero_pa3,     response = \"pr_ab\",     predictors = c(\"cwd\", \"tmn\", \"aet\", \"ppt_jja\"),     partition = \".part\",     thr = \"max_sens_spec\"   )  mgbm <- fit_gbm(   data = hespero_pa3,   response = \"pr_ab\",   predictors = c(\"cwd\", \"tmn\", \"aet\", \"ppt_jja\"),   partition = \".part\",   thr = \"max_sens_spec\" )  msvm <- fit_svm(   data = hespero_pa3,   response = \"pr_ab\",   predictors = c(\"cwd\", \"tmn\", \"aet\", \"ppt_jja\"),   partition = \".part\",   thr = \"max_sens_spec\" )   mpred <- sdm_predict(   models = list(mglm, mgbm, msvm),   pred = somevar,   con_thr = TRUE,   predict_area = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"comparing-our-models","dir":"Articles","previous_headings":"","what":"Comparing our models","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"First, let’s take look spatial predictions models. GLM GBM predict lot suitable habitat far species found!","code":"par(mfrow = c(1, 3)) plot(mpred$glm, main = \"GLM\") # points(hespero$x, hespero$y, pch = 19) plot(mpred$gbm, main = \"GBM\") # points(hespero$x, hespero$y, pch = 19) plot(mpred$svm, main = \"SVM\") # points(hespero$x, hespero$y, pch = 19)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"partial-dependence-plots-to-explore-the-impact-of-predictor-conditions-on-suitability","dir":"Articles","previous_headings":"","what":"Partial dependence plots to explore the impact of predictor conditions on suitability","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"Extrapolation reflects issue model handles novel data. , see three algorithms explored tutorial predict pretty different geographic patterns habitat suitability based occurrence/pseudo-absence data environmental predictors. Let’s take look partial dependence plots see marginal effect environmental predictors suitability looks like test models. function allows visualize model may extrapolate outside environmental conditions used training, visualizing “projection” data different color. case, environmental predictors cover extent CFP. flexsdm allows users plot univariate partial dependence plots (p_pdp) bivariate partial dependence plots (p_bpdp); shown model. Note: p_bpdp function allows users option show boundaries training data using either rectangle convex hull approach. use convex hull approach. Uni bivariate partial dependence plots GLM:   Uni bivariate partial dependence plots GBM:   Uni bivariate partial dependence plots SVM:   plots show really interesting story! notably, GLM GBM show consistently high habitat suitability areas much higher actual evapotranspiration narrow range values used train model. However, SVM seems best job estimating high habitat suitability environmental values outside training data. Importantly, models can behave differently depending modeling situation context.","code":"p_pdp(model = mglm$model, training_data = hespero_pa3, projection_data = somevar) p_bpdp(model = mglm$model, training_data = hespero_pa3, training_boundaries = \"convexh\") p_pdp(model = mgbm$model, training_data = hespero_pa3, projection_data = somevar) p_bpdp(model = mgbm$model, training_data = hespero_pa3, training_boundaries = \"convexh\", resolution = 100) p_pdp(model = msvm$model, training_data = hespero_pa3, projection_data = somevar) p_bpdp(model = msvm$model, training_data = hespero_pa3, training_boundaries = \"convexh\")"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"extrapolation-evaluation","dir":"Articles","previous_headings":"","what":"Extrapolation evaluation","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"Remember species highly restricted southern California! However, two models (GLM GBM) predict high habitat suitability throughout parts CFP, SVM provides conservative predictions. see GLM GBM tend predict high habitat suitability areas environmentally different training conditions. models extrapolating environmental space? Let’s find using “extra_eval” function SDM. function requires input model training data, column specifying presence vs. absence locations, projection data (can SpatRaster tibble containing data used model projection – can reflect larger region, separate region, different time period used model training), metric calculating degree extrapolation (default Mahalanobis distance, though euclidean also option- explore ), number cores parallel processing, aggregation factor, case want measure extrapolation large data set. First look degree extrapolation geographic space using Shape method based Mahalanobis distance. Also distinguish univariate combinatorial extrapolation. Using Mahalanobis distance: output extra_eval function SpatRaster, showing degree extrapolation across projection area, estimated Shape method.  can also explore extrapolation suitability patterns environmental geographic space, using just one function. , use p_extra function. function plots ggplot object. Let’s start extrapolation evaluation. plots show areas high extrapolation (dark blue) far training data (shown black) environmental geographic space. higher extrapolation values extrapolation area northwestern portion CFP.  Let’s explore univariate combinatorial extrapolation. former defined projecting data outside range training conditions, combinatorial extrapolation area projecting data within range training conditions.","code":"xp_m <-   extra_eval(     training_data = hespero_pa3,     pr_ab = \"pr_ab\",     projection_data = somevar,     metric = \"mahalanobis\",     univar_comb = TRUE,     n_cores = 1,     aggreg_factor = 1   ) xp_m #> class       : SpatRaster  #> size        : 558, 394, 2  (nrow, ncol, nlyr) #> resolution  : 1890, 1890  (x, y) #> extent      : -373685.8, 370974.2, -604813.3, 449806.7  (xmin, xmax, ymin, ymax) #> coord. ref. : +proj=aea +lat_0=0 +lon_0=-120 +lat_1=34 +lat_2=40.5 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +no_defs  #> source(s)   : memory #> names       : extrapolation, uni_comb  #> min values  :         0.000,        1  #> max values  :      3730.677,        2 cl <- c(\"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\", \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\")  par(mfrow = c(1, 2)) plot(xp_m$extrapolation, main = \"Shape metric\", col = cl) plot(xp_m$uni_comb, main = \"Univariate (1) and \\n combinatorial (2) extrapolation\", col = cl) p_extra(   training_data = hespero_pa3,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   color_p = \"black\",   extra_suit_data = xp_m,   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05 ) #> Number of cell used to plot 3642 (5%) p_extra(   training_data = hespero_pa3,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   color_p = \"black\",   extra_suit_data = xp_m$uni_comb,   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05,   color_gradient = c(\"#B3DC2B\", \"#30678D\"),   alpha_p = 0.2 ) #> Number of cell used to plot 3642 (5%)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v06_Extrapolation_example.html","id":"truncating-sdms-predictions-based-on-extrapolation-thresholds","dir":"Articles","previous_headings":"","what":"Truncating SDMs predictions based on extrapolation thresholds","title":"flexsdm: Tools to explore extrapolation in SDMs","text":"Depending user’s end goal, may want exclude suitability values environmentally “” far modeling training data. Shape method allows select extrapolation threshold exclude suitability values. truncating models can use p_extra function explore binary extrapolation patter environmental geographical space. test values 50, 100, 500, comparison.    Values 1 (yellow one) depict environmental geographical regions constraint models suitability (truncate). Note lower threshold, restrictive environmental geographic regions used constrain model. Now use function extra_truncate truncate suitability predictions made GLM, GBM, SVM based extrapolation thresholds explored previously. note, threshold selection user-dependent, function allows select multiple thresholds one time compare outputs. Users can also select “trunc_value” within extra_truncate function, specifies value assigned cells exceed extrapolation threshold (also specified function). default 0 users also choose another value reduce suitability.  Based maps, can see lower extrapolation threshold, restricted habitat suitability patterns, higher values retain greater amount suitable habitat. Selecting best threshold depend modeling goals objectives, . Want learn Shape extrapolation metrics? Read article “Velazco, S. J. E., Brooke, M. R., De Marco Jr., P., Regan, H. M., & Franklin, J. (2023). far can extrapolate species distribution model? Exploring Shape, novel method. Ecography, 11, e06992. https://doi.org/10.1111/ecog.06992”","code":"p_extra(   training_data = hespero_pa3,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   color_p = \"black\",   extra_suit_data = as.numeric(xp_m$extrapolation < 50),   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05,   color_gradient = c(\"gray\", \"#FDE725\"),   alpha_p = 0.5 ) + plot_annotation(subtitle = \"Binary extrapolation pattern with using a threshold of 50\") #> Number of cell used to plot 3642 (5%) p_extra(   training_data = hespero_pa3,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   color_p = \"black\",   extra_suit_data = as.numeric(xp_m$extrapolation < 100),   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05,   color_gradient = c(\"gray\", \"#FDE725\"),   alpha_p = 0.5 ) + plot_annotation(subtitle = \"Binary extrapolation pattern with using a threshold of 100\") #> Number of cell used to plot 3642 (5%) p_extra(   training_data = hespero_pa3,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   color_p = \"black\",   extra_suit_data = as.numeric(xp_m$extrapolation < 500),   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05,   color_gradient = c(\"gray\", \"#FDE725\"),   alpha_p = 0.5 ) + plot_annotation(subtitle = \"Binary extrapolation pattern with using a threshold of 500\") #> Number of cell used to plot 3642 (5%) glm_trunc <- extra_truncate(   suit = mpred$glm,   extra = xp_m,   threshold = c(50, 100, 500),   trunc_value = 0 )  gbm_trunc <- extra_truncate(   suit = mpred$gbm,   extra = xp_m,   threshold = c(50, 100, 500),   trunc_value = 0 )  svm_trunc <- extra_truncate(   suit = mpred$svm,   extra = xp_m,   threshold = c(50, 100, 500),   trunc_value = 0 ) par(mfrow = c(3, 3)) plot(glm_trunc$`50`, main = \"GLM; extra threshold = 50\", col = cl) plot(glm_trunc$`100`, main = \"GLM; extra threshold = 100\", col = cl) plot(glm_trunc$`500`, main = \"GLM; extra threshold = 500\", col = cl) plot(gbm_trunc$`50`, main = \"GBM; extra threshold = 50\", col = cl) plot(gbm_trunc$`100`, main = \"GBM; extra threshold = 100\", col = cl) plot(gbm_trunc$`500`, main = \"GBM; extra threshold = 500\", col = cl) plot(svm_trunc$`50`, main = \"SVM; extra threshold = 50\", col = cl) plot(svm_trunc$`100`, main = \"SVM; extra threshold = 100\", col = cl) plot(svm_trunc$`500`, main = \"SVM; extra threshold = 500\", col = cl)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Species distribution modeling for several species and climate change scenarios","text":"tutorial presents complete workflow species distribution modeling (SDM) using flexsdm R package. ’ll analyzing distribution palm species South Brazil based occurrence data environmental variables different time periods. workflow demonstrates data preparation, model construction, evaluation, prediction, including assessment extrapolation risk, output saving.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"required-packages","dir":"Articles","previous_headings":"Introduction","what":"Required packages","title":"Species distribution modeling for several species and climate change scenarios","text":"First, let’s install load required packages:","code":"# Install and load required packages if (!require(flexsdm)) remotes::install_github(\"flexsdm\") if (!require(terra)) install.packages(\"terra\") if (!require(geodata)) install.packages(\"geodata\") if (!require(tidyterra)) install.packages(\"tidyterra\") if (!require(ggspatial)) install.packages(\"ggspatial\") if (!require(ggplot2)) install.packages(\"ggplot2\") if (!require(dplyr)) install.packages(\"dplyr\") if (!require(tidyr)) install.packages(\"tidyr\") if (!require(readr)) install.packages(\"readr\") if (!require(sf)) install.packages(\"sf\") if (!require(reshape2)) install.packages(\"reshape2\") if (!require(stringr)) install.packages(\"stringr\") if (!require(purrr)) install.packages(\"purrr\")  sapply(   c(     \"flexsdm\", \"terra\", \"geodata\", \"tidyterra\", \"ggplot2\", \"dplyr\", \"tidyr\",     \"readr\", \"sf\", \"ggspatial\", \"reshape2\", \"stringr\", \"purrr\"   ),    require,   character.only = TRUE )  # Set seed for reproducibility set.seed(123)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"directory-setup","dir":"Articles","previous_headings":"","what":"1. Directory Setup","title":"Species distribution modeling for several species and climate change scenarios","text":"First, let’s setup directory project. create structured directory storing data, models, results. can adjust main_dir preferred location. can also adjust parameters needs, defaults work well cases. projections parameter set NULL use default projections, specifying projection scenarios use later. change scenarios evaluate, sure change part file structure compatible project. ensure folders climate change scenarios 1_Inputs/2_Predictors/2_Projection 2_Outputs/2_Projection folders. algorithm ensemble parameters specify algorithms ensemble methods used modeling process. threshold parameter set FALSE, meaning create separate folders continuous thresholded map outputs – though option.","code":"# Future scenarios (we will use the function geodata::cmip6_world() to download future climate data but this will be highly dependent on the source of your future data  # Define scenario components ssps <- c(\"370\", \"585\") # two Shared Socioeconomic Pathway scenarios time <- c(\"2041-2060\") # just one time frame but you can have multiple models <- c(\"CNRM-CM6-1\", \"MIROC6\") # two climate models  # Expand into all combinations scenarios <- expand.grid(model = models, ssp = ssps, time = time,                           stringsAsFactors = FALSE)  # Create identifiers for each scenario combination scenarios$filename <- apply(scenarios, 1, function(x) {   paste0(     tolower(gsub(\"-\", \"\", x[\"model\"])), \"_\",      x[\"ssp\"], \"_\",      gsub(\"-\", \"_\", x[\"time\"])   ) })   # Let's create a directory to create a directory system to store models inputs and outputs temp_dir <- tempdir() # This directory is temporary. We advise using a non-temporary directory to keep outputs saved when you test or adapt these codes.  proj_dir <- file.path(temp_dir, \"1_SDM\") dir.create(proj_dir)  proj_dir <- flexsdm::sdm_directory(   main_dir = proj_dir,   projections = scenarios$filename,   algorithm = c(\"gam\", \"gau\", \"glm\", \"gbm\", \"max\", \"net\", \"raf\", \"svm\", \"mean\", \"median\"),   threshold = FALSE,   return_vector = TRUE )  # You can now use the proj_dir object as a shortcut for saving outputs  # It will be helpful to create a folder for saving figures # Figure directory dir_fig <- file.path(proj_dir[1], \"2_Outputs\", \"3_Figures\") dir.create(dir_fig)  # Path to save data based on points (i.e. presences, pseudo-absences, and background points) points_dir <- proj_dir[grep(   paste0(\"1_Inputs/1_Occurrences\"),   proj_dir )] points_dir"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"load-species-occurrence-data","dir":"Articles","previous_headings":"","what":"2. Load Species Occurrence Data","title":"Species distribution modeling for several species and climate change scenarios","text":"use occurrence data palm species South Brazil (Calambás-Trochez et al., 2021). data available flexsdm internal data. load database save “./1_Inputs/1_Occurrences”. begin loading palm species occurrence data examining structure:","code":"# Load palms occurrence data data(palms) palms  # Save the data to a file ./1_SDM/1_Inputs/1_Occurrence points_dir readr::write_tsv(palms, file.path(points_dir, \"0_south_br_palms.txt\")) # Load species data species_data <- readr::read_tsv(file.path(points_dir, \"0_south_br_palms.txt\"))  # Check the number of occurrences available for each species species_counts <- table(species_data$species) %>% sort() species_counts  # Let's remove species with fewer than 15 occurrences species_data <- species_data %>%   dplyr::group_by(species) %>%   dplyr::filter(n() >= 15) %>%   dplyr::ungroup()  # Plot occurrence points to visualize the data ggplot(data = species_data, aes(x, y)) +   geom_point(aes(color = species)) +   theme_minimal() +   labs(title = \"Palm species occurrences in Southern Brazil\") +    facet_grid(.~species)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"environmental-data","dir":"Articles","previous_headings":"","what":"3. Environmental Data","title":"Species distribution modeling for several species and climate change scenarios","text":"’ll download WorldClim bioclimatic variables environmental predictors (1970-2000). bounding box can adjusted based study extent. Now let’s download variables future scenarios using geodata::cmip6","code":"# Define area of interest (bounding box for South Brazil) bbox <- c(-70, -30, -36, -5) # xmin, xmax, ymin, ymax <- define this based on your study extent of all your species  # If you have a polygon for your study extent, you can define like bbox <- st_bbox(study_extent)  # Download WorldClim bioclimatic variables at 10 arc-minutes resolution (you can adjust the spatial resolution with the res argument) env_data <- geodata::worldclim_global(var = \"bio\", res = 10, path = temp_dir) # tempdir()  # Crop to our area of interest -- retain all variables for now -- we will correct for multicollinearity later env_data <- terra::crop(env_data, terra::ext(bbox))  # Clean variables names names(env_data) <- names(env_data) %>%   gsub(\"wc2.1_10m_\", \"\", .)  # Plot a raster layers and points plot(env_data[[1]]) points(species_data %>% dplyr::select(x, y))  # Save raster for current conditions env_path <- proj_dir[grep(   paste0(\"1_Inputs/2_Predictors/1_Current\"),   proj_dir )] terra::writeRaster(env_data, file.path(env_path, \"bio_var.tif\"), overwrite = TRUE) # Plot the environmental variables # ---- Temperature Variables (1–11) ---- plot(   env_data[[1:11]],   main = c(     \"Annual Mean Temperature\",     \"Mean Diurnal Range\",     \"Isothermality\",     \"Temperature Seasonality\",     \"Max Temperature of Warmest Month\",     \"Min Temperature of Coldest Month\",     \"Temperature Annual Range\",     \"Mean Temperature of Wettest Quarter\",     \"Mean Temperature of Driest Quarter\",     \"Mean Temperature of Warmest Quarter\",     \"Mean Temperature of Coldest Quarter\"   ) )   # ---- Precipitation Variables (12–19) ---- plot(   env_data[[12:19]],   main = c(     \"Annual Precipitation\",     \"Precipitation of Wettest Month\",     \"Precipitation of Driest Month\",     \"Precipitation Seasonality\",     \"Precipitation of Wettest Quarter\",     \"Precipitation of Driest Quarter\",     \"Precipitation of Warmest Quarter\",     \"Precipitation of Coldest Quarter\"   ) ) # Download future climate change projecitons of the bioclim variables fut_env <- list()  for(i in 1:nrow(scenarios)) {   print(scenarios$filename[i])      fut <- geodata::cmip6_world(     model = scenarios$model[i],     ssp   = scenarios$ssp[i],     time  = scenarios$time[i],     var   = \"bioc\",     res   = 10,     path = tempdir()   )      fut_env[[i]] <- terra::crop(fut, terra::ext(bbox)) # if you want your future data cropped to the extent we defined earlier      names(fut_env[[i]] ) <- paste0('bio_', 1:nlyr(fut_env[[i]]))      path <- file.path(temp_dir, \"1_SDM/1_Inputs/2_Predictors/2_Projection\", scenarios$filename[i])      # Save raster for future scenario   terra::writeRaster(fut_env[[i]], file.path(path, paste0(scenarios$filename[i], \"_bio_var.tif\")), overwrite = TRUE) }  names(fut_env) <- scenarios$filename  # Compare bio1 across the four scenarios # Get global min/max for bio_1 across all scenarios bio1_range <- range(unlist(lapply(fut_env, function(r) minmax(r[[\"bio_1\"]]))))  # Set up plotting window (2x2 for 4 scenarios) par(mfrow = c(2, 2))  # Plot with consistent zlim for(i in seq_along(fut_env)){   plot(fut_env[[i]][[\"bio_1\"]],        main = scenarios$filename[i],        zlim = bio1_range) }"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"define-species-training-area","dir":"Articles","previous_headings":"","what":"4. Define species training area","title":"Species distribution modeling for several species and climate change scenarios","text":"define training area (.k.. calibration area accessible area) species based occurrence data. area used extract environmental values create pseudo-absences later.","code":"# A vector with species names that will be modeled sp_names <- unique(species_data$species) %>% sort()  # Directory to save training areas to shapefiles calib_dir <- proj_dir[grep(   paste0(\"1_Inputs/3_Calibration_area\"), proj_dir)]  calib_dir   # Create training areas for each species for (i in 1:length(sp_names)) {   message(\"Creating training area for species: \", sp_names[i])     # Define training area for the i-th species   ca <- calib_area(     data = species_data %>% dplyr::filter(species == sp_names[i]),     x = \"x\",     y = \"y\",     method = c(\"buffer\", width = 300000), # 300 km around presences     crs = crs(env_data)   )    # Save shapefile with tranning area   terra::writeVector(     ca,     filename = file.path(calib_dir, paste0(sp_names[i], \".gpkg\")),     overwrite = TRUE   ) }  # Check the training areas in the directory list.files(calib_dir, full.names = TRUE)"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"evaluate-species-specific-multicollinearity","dir":"Articles","previous_headings":"","what":"5. Evaluate Species-Specific Multicollinearity","title":"Species distribution modeling for several species and climate change scenarios","text":"","code":"# Extract environmental values at species occurrence points species_env <- flexsdm::sdm_extract(   data = species_data,   x = \"x\",   y = \"y\",   env_layer = env_data,   filter_na = TRUE )  sp_names # Vector with species to be modeled  # List of species data frames species_data_list <- species_env %>%   dplyr::mutate(pr_ab = 1) %>%   dplyr::group_by(species) %>%   dplyr::group_split()  names(species_data_list) <- sp_names  head(species_data_list) # Vector with variable names var_names <- names(env_data)  # First let's visualize predictor collinearity at species' occurrences for each species for (i in 1:length(sp_names)) {   cor_data <- species_env %>%     dplyr::filter(species == sp_names[i]) %>%     dplyr::select(all_of(var_names)) %>%     cor(use = \"pairwise.complete.obs\", method = \"pearson\") %>%     reshape2::melt()    cor_data <- cor_data[as.numeric(cor_data$Var1) > as.numeric(cor_data$Var2), ]    ggplot(cor_data, aes(x = Var1, y = Var2, fill = value)) +     geom_tile() +     scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", midpoint = 0) +     geom_text(aes(label = sprintf(\"%.2f\", value)), size = 4) +     theme_bw() +     labs(       title = paste(\"Correlation: \", sp_names[i]),       fill = \"Correlation\"     ) +     theme(       axis.text.x = element_text(angle = 45, hjust = 1),       axis.title = element_blank()     )    # save each heatmap (adjust file path as needed)   ggsave(     filename = file.path(dir_fig, paste0(sp_names[i], \"_correlation_heatmap.png\")),     width = 8, height = 6   ) }"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"correct-multicollinearity","dir":"Articles","previous_headings":"","what":"6. Correct Multicollinearity","title":"Species distribution modeling for several species and climate change scenarios","text":"step, use correct_colinvar function flexsdm. several methods correcting multicollinarity among environmental predictors, including setting maximum correlation threshold (0.7 common choice), variance inflation factor (VIF), factorial analysis, principal component analysis (PCA) (checkout correct_colinvar function). method select strongly depends ultimate goals SDM. want better understand compare influence different environmental drivers species distributions, retaining original environmental factors can beneficial. prediction primary goal, PCA can good option reduces dimensionality retaining variance data. use PCA performed species training area. method generate environmental layer principal components used model species. function also allow project principal components PCA future environmental conditions, desired. Note multicollinearity approaches can based entire environmental layers, given training area, based species points (presences+absences pseudo-absences).","code":"# (Optional) Access the help page for the function to learn more about its parameters: # ?correct_colinvar  # Generate a list of file paths to each species' training area. # Each training area is stored as a .gpkg (GeoPackage) file in calib_dir. calib_a <- list.files(calib_dir, full.names = TRUE, pattern = \".gpkg\")  # Assign species names as the names of the elements in calib_a for easy reference. # This extracts the file name without the \".gpkg\" extension and sets it as the list name. names(calib_a) <- basename(calib_a) %>% gsub(\".gpkg\", \"\", .)  # Print the named vector to verify the paths and their associated species names. calib_a  # --- Demonstrate the process for all species ----   # ----------------------------------------------------------- # Example: Running PCA-based collinearity correction #          for multiple species across multiple scenarios # -----------------------------------------------------------  # List training area polygons (.gpkg files) calib_a <- list.files(calib_dir, full.names = TRUE, pattern = \".gpkg\")  # Assign species names to each element for reference names(calib_a) <- basename(calib_a) %>% gsub(\".gpkg\", \"\", .)  # Inspect what we have calib_a  # --- Demonstrate the process for a single species (the first one) ---  # Load the vector (polygon) corresponding to the first species’ training area. # This will be used to restrict PCA to the relevant region. v <- terra::vect(calib_a[sp_names[1]])  # Plot the training area polygon to visually confirm it's correct. plot(v)  # Run the correct_colinvar function to reduce multicollinearity among predictors for this species. # - env_layer: the stack of environmental predictor rasters. # - restric_to_region: restricts the analysis to the training area polygon. # - restric_pca_proj: ensures PCA is projected only within the training area. # - method: use \"pca\" (Principal Component Analysis) for dimensionality reduction. # - based_on_points: FALSE means PCA is based on the entire environmental layer within the region, not just the occurrence points. pca_out <- flexsdm::correct_colinvar(   env_layer = env_data,   restric_to_region = v,      # Restrict to the training area polygon   restric_pca_proj = TRUE,    # Apply PCA projection only to the training area   method = c(\"pca\"),          # Use Principal Component Analysis   based_on_points = FALSE     # Base PCA on environmental data, not just points )  # Print the results of the PCA correction to examine the structure of the output object. pca_out  # Plot the resulting raster of principal components. # This raster will be used as the new, uncorrelated set of predictors for SDM for this species. plot(pca_out$env_layer)  # Display the cumulative variance explained by each principal component. # This helps determine how many components are needed to capture most of the environmental variation. pca_out$cumulative_variance  # Show the PCA loadings (coefficients) for each original variable. # These indicate the contribution of each environmental variable to each principal component. pca_out$coefficients"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"process-environmental-pca-for-all-species","dir":"Articles","previous_headings":"","what":"7. Process environmental PCA for all species","title":"Species distribution modeling for several species and climate change scenarios","text":"principal components used uncorrelated predictors SDMs. interpret ecological meaning PC, explore loading coefficients—e.g., PC heavily influenced bio1, bio5, bio6 may represent temperature gradient.","code":"# Lets create a new folder to store variables of each species save_dir <- file.path(proj_dir[2], \"4_Predictors_by_sp\") dir.create(save_dir) save_dir  # path with future scenarios scenario_path <- proj_dir[grep(   paste0(\"1_Inputs/2_Predictors/2_Projection\"), proj_dir)][1]  # Separate directories for current and future folders <- c('1_Current', '2_Projection')  # Create subfolders inside the base folder folder_paths <- sapply(folders, function(f) {   dir_path <- file.path(save_dir, f)   if (!dir.exists(dir_path))     dir.create(dir_path, recursive = TRUE)   dir_path  # return the created path }, USE.NAMES = TRUE)  env_new <- list()  # Perform PCA for each species and save the outputs for (i in 1:length(sp_names)) {   message(\"Processing species: \", sp_names[i])      v <- calib_a[i] %>% terra::vect()      # species-specific predictor projection folders      fut_folder <- file.path(folder_paths[2], sp_names[i])   dir.create(fut_folder)         # Run PCA collinearity correction   env_new[[i]] <- flexsdm::correct_colinvar(     env_layer = env_data,     proj = scenario_path,     save_proj =  fut_folder,     restric_to_region = v,     restric_pca_proj = TRUE,     method = \"pca\",     based_on_points = FALSE   )      # Save tables      env_new[[i]]$cumulative_variance %>% readr::write_tsv(file.path(folder_paths[1], paste0(sp_names[i], \"-cum_var.txt\")))      env_new[[i]]$coefficients %>% readr::write_tsv(file.path(folder_paths[1], paste0(sp_names[i], \"-coefficients.txt\")))      # Saver raster for current conditions   terra::writeRaster(env_new[[i]]$env_layer, file.path(folder_paths[1], paste0(sp_names[i], \".tif\")), overwrite = TRUE) }"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"occurrence-sample-bias-correction","dir":"Articles","previous_headings":"","what":"8. Occurrence Sample Bias Correction","title":"Species distribution modeling for several species and climate change scenarios","text":"improve SDM robustness reduce influence spatial environmental sampling bias, can filter species occurrence records environmental space using PCA-reduced environmental variables. process implemented three main steps species. First, prepare inputs using species-specific occurrences (species_data_list) PCA-reduced environmental layers (pca_env_selected), cropped training areas (ca). Next, use occfilt_env() filter occurrences across range environmental bin sizes (e.g., 8–30). Finally, select optimal bin size using occfilt_select(), based reducing spatial autocorrelation maximizing number occurrences retained. approach implemented described detail Velazco et al. (2020). plot illustrates mean spatial autocorrelation changes number environmental bins used filtering occurrence data. line represents different species. number bins increases, spatial filtering becomes finer, increasing number occurrences included well spatial clustering occurrences. plot highlights number environmental bins number occurrence records (denoted *) selected. Lower values y-axis indicate greater spatial independence among records, typically preferred model training.","code":"# 'species_data' holds all occurrence records for all species to be modeled. species_data # Data frame: species names, coordinates, etc.  # 'sp_names' contains the names of the species to be included in the analysis. sp_names # Character vector: species to process  # 'save_dir' is the directory where each species' PCA-reduced environmental predictor files are saved. save_dir # Path to directory with species-specific predictors  # 'folders' are the directories where the PCA-reduced environmental predictors are split between Current and Projections file.path(save_dir, folders)  # List all .tif files in folders (one per species, each containing PCA environmental layers for the baseline time). sp_pc <- list.files(file.path(save_dir, folders[1]), full.names = TRUE, pattern = \".tif\")  # Assign species names to each file in 'sp_pc' by removing the '.tif' extension from the filename. names(sp_pc) <- basename(sp_pc) %>% gsub(\".tif\", \"\", .) # Now names(sp_pc) matches sp_names  # Print the named vector to verify that the PCA files are matched to the correct species. sp_pc # Named vector: path to each species' PCA raster  # Initialize empty lists to store filtered occurrences and bin selection results for each species. filtered_occurrences <- list() bins_results <- list()  # Loop over each species to perform occurrence thinning in environmental space. for (s in 1:length(sp_names)) {   message(\"Filtering occurrences for species: \", s)    # Extract occurrence data for the current species.   occ_data <- species_data %>%     dplyr::filter(species == sp_names[s])      # Add a unique identifier to each occurrence record (required for filtering).   occ_data$idd <- seq_len(nrow(occ_data))    # Load the PCA-reduced environmental raster for this species.   env_data <- sp_pc[sp_names[s]] %>% terra::rast()    # Filter occurrences in environmental space using a range of bin numbers.   # This step thins points so that only one point is retained per environmental bin, reducing sampling bias.   filtered_dif_bins <- flexsdm::occfilt_env(     data = occ_data,     x = \"x\",     y = \"y\",     id = \"idd\",     env_layer = env_data,     nbins = c(8, 10, 12, 14, 18, 20, 24, 26, 30) # Try different numbers of bins   )    # Select the optimal bin size (trade-off between spatial independence and number of retained records).   # The function returns the filtered occurrences and summary statistics for each bin size.   occ_selected <- flexsdm::occfilt_select(     occ_list = filtered_dif_bins,     x = \"x\",     y = \"y\",     env_layer = env_data,     filter_prop = TRUE # Optimize for spatial independence and number of points retained   )    # Save the filtered occurrences and bin selection results for this species.   filtered_occurrences[[s]] <- occ_selected$occ   bins_results[[s]] <- occ_selected$filter_prop    # Clean up memory (especially useful in large loops).   gc() }  # Assign species names as list names for easier downstream handling. names(filtered_occurrences) <- sp_names names(bins_results) <- sp_names  # Combine filtered occurrences from all species into a single data frame with a 'species' column. filtered_occurrences <- dplyr::bind_rows(filtered_occurrences, .id = \"species\") filtered_occurrences  # Combine bin selection summaries for all species into a single data frame. bins_results <- dplyr::bind_rows(bins_results, .id = \"species\") bins_results  # Save bin selection results and filtered occurrences to tab-separated files for reproducibility and downstream use. readr::write_tsv(bins_results, file.path(points_dir, \"0_filt_prop_selected.txt\")) readr::write_tsv(filtered_occurrences, file.path(points_dir, \"0_occurrences_filtered.txt\"))  # Compare the number of original (unfiltered) and filtered occurrence records per species. # This helps assess how much data was removed by the filtering process. left_join(   species_data %>% group_by(species) %>% summarise(unfiltered = n()),   filtered_occurrences %>% group_by(species) %>% summarise(filtered = n()),   by = \"species\" )"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"sample-pseudo-absences-background-points","dir":"Articles","previous_headings":"","what":"9. Sample Pseudo-Absences & Background points","title":"Species distribution modeling for several species and climate change scenarios","text":"SDM, often need generate pseudo-absence points able use algorithm (e.g., SVM, RAF). , create pseudo-absence points species based training area defined earlier. also generate background points Maxent.","code":"# Load the filtered occurrence data from file. # This table contains the bias-corrected presence records for all species. filtered_occurrences <- readr::read_tsv(file.path(proj_dir[2], \"1_Occurrences/0_occurrences_filtered.txt\"))  # Add a column indicating presences (pr_ab = 1), as all records here are presences. filtered_occurrences$pr_ab <- 1  # Prepare to load environmental PCA predictors for each species. # Find all .tif files in the '4_Predictors_by_sp' directory (one per species). sp_pc <- file.path(proj_dir[2], \"4_Predictors_by_sp/1_Current/\") %>%    list.files(., full.names = TRUE, pattern = \".tif\")  # Set the names of the vector to the species names (by stripping \".tif\" extension from the file names). names(sp_pc) <- basename(sp_pc) %>% gsub(\".tif$\", \"\", .)  # Print out the named vector to confirm the mapping of species to file paths. sp_pc  # Initialize empty lists to store results for all species: #   - pres_pabsences: for data with presences and pseudo-absences #   - background: for background points (for Maxent models) pres_pabsences <- list() background <- list()  # Loop over each species to generate pseudo-absences and background points. for (i in 1:length(sp_names)) {   message(\"species \", i)      # Extract filtered occurrence records for the current species.   coord <- dplyr::filter(filtered_occurrences, species == sp_names[i])      # Load the PCA-reduced environmental raster for the current species.   pred <- terra::rast(sp_pc[sp_names[i]])      set.seed(15) # Set random seed for reproducibility.    # Generate pseudo-absence points for the current species.   # n = twice the number of presences (a common SDM practice).   # Points are sampled randomly within the valid region of the predictor raster.   pres_pabsences[[i]] <-     flexsdm::sample_pseudoabs(       data = coord,       x = \"x\",       y = \"y\",       n = nrow(coord) * 2, # 2x number of presences       method = \"random\",    # Random selection       rlayer = pred         # Within the species-specific training area     ) %>%     dplyr::mutate(       species = sp_names[i] # Label with species name     ) %>%     dplyr::bind_rows(coord, .) # Combine presences and pseudo-absences    set.seed(15) # Reset seed for reproducibility.    # Generate 10,000 random background points for the current species (for Maxent).   background[[i]] <- flexsdm::sample_background(     data = coord,     x = \"x\",     y = \"y\",     n = 10000,     method = \"random\",     rlayer = pred   ) %>%     dplyr::mutate(       species = sp_names[i]     ) } # Assign species names to each list element for easy reference later. names(background) <- sp_names  # Combine the lists of data frames into single data frames for all species. pres_pabsences <- dplyr::bind_rows(pres_pabsences) background <- dplyr::bind_rows(background)  # Save the combined presence + pseudo-absence data and background data to disk as .txt files. readr::write_tsv(pres_pabsences, file.path(points_dir, \"0_occurrences_psabsences.txt\")) readr::write_tsv(background, file.path(points_dir, \"0_background.txt\")) # This section generates maps visualizing the spatial distribution of: #   1) species presence locations, #   2) pseudo-absence points, and #   3) background points for each species. # The resulting maps will help to visually assess the sampling design and spatial coverage of your data.  dir_fig # Directory where figure files will be saved  # List all training area shapefiles (.gpkg) for each species. # These polygons define the modeling extent (calibration area) for each species. calib_a <- list.files(calib_dir, full.names = TRUE, pattern = \".gpkg\")  # Assign species names to each element of the calib_a vector,  # by extracting the filename and removing the \".gpkg\" extension. names(calib_a) <- basename(calib_a) %>% gsub(\".gpkg\", \"\", .)  # Loop through species and generate maps for (i in 1:length(sp_names)) {   # Isolate species data   pa_data <- pres_pabsences %>% dplyr::filter(species == sp_names[i])   bg_data <- background %>% dplyr::filter(species == sp_names[i])   ca <- terra::vect(calib_a[sp_names[i]])    # Plot   p <- ggplot() +   geom_spatvector(data = ca, fill = NA, color = \"black\", linetype = \"dashed\") +   geom_point(data = bg_data, aes(x = x, y = y), color = \"gray60\", size = 0.7, alpha = 0.5) +   geom_point(data = pa_data, aes(x = x, y = y, color = as.factor(pr_ab))) +   scale_color_manual(          values = c(\"1\" = \"blue\", \"0\" = \"red\"),        ) +   coord_sf() +   theme_bw() +   labs(     title = paste(\"Species:\", sp_names),     subtitle = \"Blue = Presence | Red = Pseudo-Absence | Gray = Background\",     x = \"Longitude\", y = \"Latitude\"   ) +   annotation_scale(location = \"br\", width_hint = 0.3) +   annotation_north_arrow(     location = \"bl\",     style = north_arrow_fancy_orienteering,     height = unit(1.5, \"cm\"),     width = unit(1.5, \"cm\")   ) +    labs(color = element_blank())     # Print the plot to the console   p      # Save   ggsave(     filename = file.path(dir_fig, paste0(sp_names[i], \"_pr-ab-bg_map.png\")),     plot = p,     width = 8, height = 6, dpi = 300   ) }"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"data-partitioning","dir":"Articles","previous_headings":"","what":"10. Data Partitioning","title":"Species distribution modeling for several species and climate change scenarios","text":"properly evaluate models, ’ll partition data training testing sets using spatial block band partitioning. Often blocks work larger occurrence datasets, bands can useful smaller datasets. try spatial blocks move bands case fails.","code":"# Initialize lists to store partitioned data for each species. # - partitioned_psa: will hold partitioned presence and pseudo-absence records. # - partitioned_bg: will hold partitioned background points. partitioned_psa <- list() partitioned_bg <- list()  # Loop through each species to perform spatial partitioning for cross-validation. for (i in seq_along(sp_names)) {   message(\"Processing spatial partitioning for: \", i)      # Select presence + pseudo-absence data for the current species.   psa_select <- pres_pabsences %>% dplyr::filter(species == sp_names[i])      # Select background points for the current species.   bg_select <- background %>% dplyr::filter(species == sp_names[i])      # Load PCA-reduced environmental raster for the species (used for spatial partitioning).   env_subset <- terra::rast(sp_pc[sp_names[i]])      # Attempt spatial partitioning using spatial blocks (grids).   # This method divides the study area into blocks, assigning data in each block to the same fold.   part <-     flexsdm::part_sblock(       env_layer = env_subset,       data = psa_select,       x = \"x\",       y = \"y\",       pr_ab = \"pr_ab\",       n_part = 4,         # Number of partitions/folds       min_res_mult = 4,   # Controls minimum block size (relative to raster resolution)       max_res_mult = 300, # Controls maximum block size       num_grids = 60,     # Number of candidate grids to test       min_occ = 5,        # Minimum number of occurrences per fold       prop = 0.9          # Proportion of data to be included in the partition (for exclusion of sparse blocks)     )      # If block partitioning fails (e.g., too few records per block), try latitudinal bands.   if (length(part) < 3) {     part <-       flexsdm::part_sband(         env_layer = env_subset,         data = psa_select,         x = \"x\",         y = \"y\",         pr_ab = \"pr_ab\",         type = \"lat\",      # Split into horizontal (latitudinal) bands         n_part = 4,         min_bands = 2,         max_bands = 60,         min_occ = 5,         prop = 0.9       )   }   # If latitudinal bands also fail, try longitudinal bands.   if (length(part) < 3) {     part <-       flexsdm::part_sband(         env_layer = env_subset,         data = psa_select,         x = \"x\",         y = \"y\",         pr_ab = \"pr_ab\",         type = \"lon\",      # Split into vertical (longitudinal) bands         n_part = 4,         min_bands = 2,         max_bands = 60,         min_occ = 5,         prop = 0.9       )   }   # If all spatial partitioning methods fail, revert to standard random k-fold partitioning.   if (length(part) < 3) {     # Randomly assign presences/pseudo-absences to 5 folds.     partitioned_psa[[i]] <- flexsdm::part_random(       data = psa_select,       pr_ab = \"pr_ab\",       method = c(method = \"kfold\", folds = 5)     )          # Randomly assign background points to 5 folds.     partitioned_bg[[i]] <- flexsdm::part_random(       data = bg_select,       pr_ab = \"pr_ab\",       method = c(method = \"kfold\", folds = 5)     )   }      # If spatial partitioning was successful (contains \"best_part_info\"), store results and save partition details.   if (any(\"best_part_info\" == names(part))) {     # Store partitioned presence/pseudo-absence data, adding the species name.     partitioned_psa[[i]] <- part$part %>% dplyr::mutate(species = sp_names[i])          # Save the spatial partition grid (as a raster) for reference or plotting later.     terra::writeRaster(       part$grid,       file.path(points_dir, paste0(sp_names[i], \"_best_part.tif\")),       overwrite = TRUE     )          # Save partitioning summary (e.g., number of records per fold, SD, etc.).     readr::write_tsv(       part$best_part_info,       file.path(points_dir, paste0(sp_names[i], \"_best_part.txt\"))     )          # Assign each background point to a partition/fold according to the spatial partitioning.     partitioned_bg[[i]] <-       flexsdm::sdm_extract(         data = bg_select,         x = \"x\",         y = \"y\",         env_layer = part$grid       )   }      # Run garbage collection to free memory before next iteration (useful in large species datasets).   gc() }  # Combine all species' partitioned presence/pseudo-absence data into a single data frame. partitioned_psa <- dplyr::bind_rows(partitioned_psa)  # Combine all species' partitioned background data into a single data frame. partitioned_bg <- dplyr::bind_rows(partitioned_bg)  # Save the final partitioned datasets to disk for model training and evaluation. readr::write_tsv(partitioned_psa, file.path(points_dir, \"0_partitioned_occurrences_psabsences.txt\")) readr::write_tsv(partitioned_bg, file.path(points_dir, \"0_partitioned_background.txt\"))"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"configuration-of-output-directories-and-data-used-during-model-fitting","dir":"Articles","previous_headings":"","what":"11. Configuration of output directories and data used during model fitting","title":"Species distribution modeling for several species and climate change scenarios","text":"","code":"# Define the directory where model evaluation metrics and performance summaries will be saved. dir_perf <- file.path(temp_dir, \"1_SDM/2_Outputs/0_Model_performance\")  # Define the directory where model predictions for current environmental conditions will be saved. # This folder will store the prediction rasters for each algorithm. dir_current <- file.path(temp_dir, \"1_SDM/2_Outputs/1_Current/Algorithm\")  # 'dir_fig' is assumed to be previously defined, and will be used for saving figures such as plots and maps. dir_fig  # List all environmental raster files (principal component layers) for each species. # These are the PCA-reduced predictor rasters stored in the specified directory. sp_pc <- list.files(   file.path(temp_dir, \"1_SDM/1_Inputs/4_Predictors_by_sp/1_Current\"),   full.names = TRUE,   pattern = \".tif\" )  # List all future environmental raster files (principal component layers) for each species. # These are the PCA-reduced predictor rasters stored in the specified directory. dir_futur_pca <- file.path(proj_dir[2], \"4_Predictors_by_sp/2_Projection/\")   # Get all species folders (exclude the base folder itself) species_dirs <- list.dirs(dir_futur_pca, recursive = FALSE)  # Initialize nested list fut_sp_pc_list <- list()  for (sp_dir in species_dirs) {   sp_name <- basename(sp_dir)   # Get all scenario folders for this species   scenario_dirs <- list.dirs(sp_dir, recursive = FALSE)   # Initialize list for species   fut_sp_pc_list[[sp_name]] <- list()   for (sc_dir in scenario_dirs) {     sc_name <- basename(sc_dir)     # List all .tif rasters in this scenario folder     tif_files <- list.files(sc_dir, pattern = \"\\\\.tif$\", full.names = TRUE)     # Load all rasters as a raster stack     if (length(tif_files) > 0) {       fut_sp_pc_list[[sp_name]][[sc_name]] <- rast(tif_files)     } else {       fut_sp_pc_list[[sp_name]][[sc_name]] <- NULL     }   } }  # Check structure str(fut_sp_pc_list, max.level = 3)  # Assign species names to each raster file in 'sp_pc' by stripping the '.tif' extension from the file name. # This makes it easy to match species names to their respective PCA raster paths. names(sp_pc) <- basename(sp_pc) %>% gsub(\".tif\", \"\", .)  # Load the partitioned presence and pseudo-absence dataset from file. # Each row corresponds to an occurrence or pseudo-absence, along with partition/fold assignments for cross-validation. psa <- readr::read_tsv(file.path(proj_dir[1], \"1_Inputs/1_Occurrences/0_partitioned_occurrences_psabsences.txt\"))  # Load the partitioned background points dataset from file. # Background points are used in algorithms like Maxent and should also have partition assignments. bkgrnd <- readr::read_tsv(file.path(proj_dir[1], \"1_Inputs/1_Occurrences/0_partitioned_background.txt\")"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"main-loop-by-species-for-model-fitting-evaluation-and-prediction","dir":"Articles","previous_headings":"","what":"12. Main loop by species for model fitting, evaluation and prediction","title":"Species distribution modeling for several species and climate change scenarios","text":"","code":"# Get a unique list of species names to iterate through and process each one. sp_names <- unique(psa$species)  # Loop through each species name in the 'sp_names' vector. for (i in 1:length(sp_names)) {   # Get the current species name for this iteration.   s_name <- sp_names[i]   # Print a message to the console to track progress.   message(paste0(\"\\n===== Processing species: \", s_name, \" =====\"))    ##%######################################################%##   ####      1. Prepare Data for the Current Species       ####   ##%######################################################%##    # Load the environmental raster data specific to the species.   env_r <- terra::rast(sp_pc[s_name])   # Get the names of the environmental variables (predictors).   var_names <- names(env_r)    # Filter the presence-absence data for the current species.   sp_pa <- psa %>% dplyr::filter(species == s_name)   # Filter the background data for the current species.   sp_bg <- bkgrnd %>% dplyr::filter(species == s_name)    # Extract environmental data for presence-absence points, removing any points with NA values.   sp_pa <- sdm_extract(sp_pa, x = \"x\", y = \"y\", env_layer = env_r, filter_na = TRUE)   # Extract environmental data for background points.   sp_bg <- sdm_extract(sp_bg, x = \"x\", y = \"y\", env_layer = env_r, filter_na = TRUE)     ## %######################################################%##   ####                   2. Fit Models                     ####   ## %######################################################%##   message(\"  > Fitting models...\")    # ---- Random Forest (tune_raf) ----   # Tune hyperparameters for a Random Forest model.   m_raf <- tune_raf(     data = sp_pa, # Presence-absence data     response = \"pr_ab\", # The column with presence/absence (1/0)     predictors = var_names, # Names of environmental variables     partition = \".part\", # Column for data partitioning (training/testing)     grid = expand.grid( # Define the grid of hyperparameters to test       mtry = seq(1, length(var_names), 1), # Number of variables to sample at each split       ntree = c(400, 600, 800, 1000) # Number of trees to grow     ),     thr = \"max_sorensen\", # Threshold to convert continuous prediction to binary     metric = \"SORENSEN\", # Metric to evaluate the model performance     n_cores = 4 # Number of CPU cores for parallel processing   )    # ---- Maxent (tune_max) ----   # Tune hyperparameters for a Maxent model.   m_max <- tune_max(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     background = sp_bg, # Background data is required for Maxent     partition = \".part\",     grid = expand.grid( # Define the grid of hyperparameters to test       regmult = seq(0.1, 2, 0.5), # Regularization multiplier to prevent overfitting       classes = c(\"lq\", \"lqh\", \"lqhp\", \"lqhpt\") # Feature classes (l=linear, q=quadratic, etc.)     ),     thr = \"max_sorensen\",     metric = \"SORENSEN\",     n_cores = 4   )    # ---- Boosted Regression Tree (tune_gbm) ----   # Tune hyperparameters for a Boosted Regression Tree model.   m_gbm <- tune_gbm(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     partition = \".part\",     grid = expand.grid( # Define the grid of hyperparameters to test       n.trees = seq(150, 200, 10), # Number of trees       shrinkage = seq(1, 1.5, 0.2), # Learning rate       n.minobsinnode = seq(1, 15, 2) # Minimum number of observations in a terminal node     ),     thr = \"max_sorensen\",     metric = \"SORENSEN\",     n_cores = 4   )    # ---- Generalized Additive Model (fit_gam) ----   # Determine the number of training samples.   n_t <- flexsdm:::n_training(data = sp_pa, partition = \".part\")   # Set a starting number for basis functions (k).   candidate_k <- 20   # Reduce 'k' until it's smaller than the number of training samples to avoid errors.   while (any(n_t < flexsdm:::n_coefficients(     data = sp_pa,     predictors = var_names,     k = candidate_k   ))) {     candidate_k <- candidate_k - 3   }   # Fit a GAM model with the adjusted 'k'.   m_gam <- fit_gam(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     partition = \".part\",     thr = \"max_sorensen\",     k = candidate_k # Basis functions parameter   )    # ---- Generalized Linear Model (fit_glm) ----   # Fit a GLM with a second-degree polynomial term.   m_glm <- fit_glm(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     partition = \".part\",     thr = \"max_sorensen\",     poly = 2 # Degree of polynomial functions   )    # ---- Gaussian Process (fit_gau) ----   # Fit a Gaussian Process model.   m_gau <- fit_gau(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     partition = \".part\",     thr = \"max_sorensen\"   )    # ---- Neural Network (tune_net) ----   # Tune hyperparameters for a Neural Network model.   m_net <- tune_net(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     partition = \".part\",     grid = expand.grid( # Define the grid of hyperparameters to test       size = 2:length(var_names), # Number of units in the hidden layer       decay = c(seq(0.01, 1, 0.05), 1, 3, 4, 5, 6) # Weight decay for regularization     ),     thr = \"max_sorensen\",     metric = \"SORENSEN\",     n_cores = 4   )    # ---- Support Vector Machine (tune_svm) ----   # Tune hyperparameters for a Support Vector Machine model.   m_svm <- tune_svm(     data = sp_pa,     response = \"pr_ab\",     predictors = var_names,     partition = \".part\",     grid = expand.grid(       C = seq(2, 60, 5), # Cost parameter for regularization       sigma = c(seq(0.001, 0.3, 0.01)) # Kernel parameter     ),     thr = \"max_sorensen\",     metric = \"SORENSEN\",     n_cores = 4   )    # Gather all fitted model objects (those starting with \"m_\") into a single named list.   model_obj_list <- mget(grep(\"^m_\", ls(), value = TRUE))   # Clean up the names in the list (e.g., \"m_raf\" becomes \"raf\").   names(model_obj_list) <- gsub(\"m_\", \"\", names(model_obj_list))     ## %######################################################%##   ####    3. Partial Dependence & Variable Importance     ####   ## %######################################################%##   message(\"  > Calculating PDP and Variable Importance...\")    # Initialize an empty list to store variable importance results for each model.   varimp <- list()    # Loop through each fitted model to generate plots and calculate importance.   for (i in 1:length(model_obj_list)) {     mod_name <- names(model_obj_list)[i]     model_obj <- model_obj_list[[i]]      # Generate Partial Dependence Plots (PDP) to visualize variable effects.     # The 'p_pdp' function extracts the core model (e.g., randomForest) from the flexsdm object.     p <- p_pdp(model = model_obj$model, training_data = sp_pa) +       ggtitle(paste(s_name, \"-\", mod_name)) # Add a title to the plot      # If the plot was created successfully, save it as a PNG file.     if (!is.null(p)) {       ggsave(         plot = p,         filename = file.path(dir_fig, paste0(s_name, \"_\", mod_name, \"_pdp.png\")),         width = 8,         height = 6,         dpi = 300       )     }      # Calculate variable importance using a permutation-based method.     varimp[[i]] <- flexsdm::sdm_varimp(       model = model_obj,       data = sp_pa,       response = \"pr_ab\",       predictors = var_names,       n_sim = 30, # Number of permutations to run       n_cores = 2,       thr = \"max_sorensen\",       clamp = TRUE,       pred_type = \"cloglog\" # Use cloglog output for predictions     )   }    # Combine the variable importance results from all models into a single data frame.   varimp <- dplyr::bind_rows(varimp)   # Save the combined variable importance table to a text file.   readr::write_tsv(varimp, file.path(dir_perf, paste0(s_name, \"_varimp.txt\")))    # Create a bar plot to visualize variable importance across models.   varimp2 <- varimp %>% tidyr::pivot_longer(     cols = TPR:IMAE,     names_to = \"metric\",     values_to = \"value\"   ) %>%     filter(metric %in% c(\"AUC\", \"TSS\", \"SORENSEN\")) # Filter for specific metrics      p_vi <-  ggplot(varimp2, aes(x = predictors, y = value, fill = model)) +     scale_fill_brewer(palette = \"Set1\") +     geom_bar(stat = \"identity\", position = position_dodge()) +     facet_grid(model~metric, scales = \"free\") +     coord_flip() +     labs(       x = \"Predictor variables\",       y = \"Variable importance\"     ) +     theme_bw()      print(p_vi)   ggsave(     filename = file.path(dir_fig, paste0(s_name, \"_varImp.png\")),     plot = p_vi,     width = 12, height = 14, dpi = 300, unit=\"cm\", scale=1.5   )      # Summarize performance metrics (e.g., SORENSEN, TSS) for all individual models.   model_perf <- flexsdm::sdm_summarize(model_obj_list)   # Save the performance summary to a text file.   readr::write_tsv(model_perf, file.path(dir_perf, paste0(s_name, \"_models_performance.txt\")))     ##%######################################################%##   ####        4. Filter Models for Ensemble              ####   ##%######################################################%##   message(\"  > Filtering models to perform ensemble...\")    # Filter models based on performance criteria to select the \"best\" ones for the ensemble.   # Here, we select models with a mean Sorensen score >= 0.7.   # We also exclude models with thresholds of 0 or 1, as they might indicate overfitting.   good_models_names <- model_perf$model[     model_perf$SORENSEN_mean >= 0.7 &       model_perf$thr_value > 0 &       model_perf$thr_value < 1   ]    # Create a new list containing only the selected \"good\" models.   good_models <- model_obj_list[good_models_names]     ## %######################################################%##   ####                   5. Ensemble Modeling              ####   ## %######################################################%##   # Initialize an empty list to store ensemble models.   ensemble_list <- list()    # Only proceed if there is more than one \"good\" model to create an ensemble.   if (length(good_models) > 1) {     message(\"  > Fitting model ensemble...\")     # Create an ensemble by averaging the predictions of the good models.     m_mean <- flexsdm::fit_ensemble(       good_models,       ens_method = \"mean\", # Ensemble method: mean, weighted_mean, median, etc.       thr_model = \"max_sorensen\", # Thresholding method for individual models       thr = \"max_sorensen\", # Thresholding method for the final ensemble       metric = \"SORENSEN\"     )      # Create an ensemble using the median of the predictions.     m_median <-       flexsdm::fit_ensemble(         good_models,         ens_method = \"median\",         thr_model = \"max_sorensen\",         thr = \"max_sorensen\",         metric = \"SORENSEN\"       )      # Combine the ensemble models into a list.     ensemble_list <- list(mean = m_mean, median = m_median)     # Summarize the performance of the ensemble models.     ens_perf <- flexsdm::sdm_summarize(ensemble_list)      # Combine the performance tables of individual models and ensemble models.     model_perf_with_ens <- dplyr::bind_rows(model_perf, ens_perf)     # Overwrite the previous performance file to include the ensemble results.     readr::write_tsv(model_perf_with_ens,       file.path(dir_perf, paste0(s_name, \"_models_performance.txt\"))     )   }     ## %######################################################%##   ####                  6. Spatial Predictions             ####   ## %######################################################%##   message(\"  > Predicting models ...\")    names(good_models) <- NULL      # Predict habitat suitability for each of the \"good\" individual models.   if (length(good_models) > 0) {     prd_list <- flexsdm::sdm_predict(       models = good_models, # List of good models       pred = env_r, # Environmental raster layers to predict onto       thr = \"max_sorensen\",       clamp = TRUE, # Restrict predictions to the range of training data       con_thr = TRUE, # Produce continuous and binary (thresholded) predictions       pred_type = \"cloglog\"     )      # Loop through the list of predictions and save each one as a GeoTIFF raster file.     for (alg in names(prd_list)) {       terra::writeRaster(         prd_list[[alg]],         filename = file.path(dir_current, alg, paste0(s_name, \".tif\")),         overwrite = TRUE,         filetype = \"GTiff\"       )     }   }    # Predict habitat suitability for the ensemble models.      if (length(ensemble_list) > 0) {     for(i in seq_along(ensemble_list)){       ens_prd <- sdm_predict(       models = ensemble_list[[i]],       pred = env_r,       thr = \"max_sorensen\",       con_thr = TRUE,       clamp = TRUE,       pred_type = \"cloglog\"     )              # Save prediction as a GeoTIFF.       writeRaster(         ens_prd[[1]],         filename = file.path(dir_current, names(ensemble_list[i]), paste0(s_name, \".tif\")),         overwrite = TRUE,         filetype = \"GTiff\"       )     }   }      ##%######################################################%##   ####               7. Future projections                ####   ##%######################################################%##      message(\"  > Predicting models for future projections ...\")      fut_env <- fut_sp_pc_list[[s_name]]      # Loop over each scenario raster stack (fut_sp_pc_list already has species->scenario->raster)   for (sc_name in names(fut_env)) {     env_r <- fut_env[[sc_name]]  # raster stack for this scenario          # Create output folder if it doesn't exist     dir_future <- proj_dir[grep(paste0(\"2_Outputs/2_Projection\"), proj_dir)][1]          # --- Predict individual models ---     if (length(good_models) > 0) {       prd_list <- flexsdm::sdm_predict(         models = good_models,         pred = env_r,         thr = \"max_sorensen\",         clamp = TRUE,         con_thr = TRUE,         pred_type = \"cloglog\"       )              # Save individual model predictions       for (alg in names(prd_list)) {         terra::writeRaster(           prd_list[[alg]],           file.path(dir_future, sc_name, paste0('Algorithm'), alg, paste0(s_name, \".tif\")),           overwrite = TRUE,           filetype = \"GTiff\"         )       }     }          # --- Predict ensemble models ---     if (length(ensemble_list) > 0) {       for (i in seq_along(ensemble_list)) {         ens_prd <- flexsdm::sdm_predict(           models = ensemble_list[[i]],           pred = env_r,           thr = \"max_sorensen\",           clamp = TRUE,           con_thr = TRUE,           pred_type = \"cloglog\"         )                  # Save ensemble prediction         writeRaster(           ens_prd[[1]],           filename = file.path(             dir_future,             sc_name,             paste0('Algorithm'),             paste0(names(ensemble_list[i])),             paste0(s_name, \".tif\")           ),           overwrite = TRUE,           filetype = \"GTiff\"         )       }     }   }         ## %######################################################%##   ####                 8. Clean Up for Next Iteration      ####   ## %######################################################%##   # Remove all model objects (starting with \"m_\") to free up memory.   rm(list = grep(\"^m_\", ls(), value = TRUE))   # Remove another temporary object if it exists.   if (exists(\"alg_prd_cont\")) rm(alg_prd_cont)   # Trigger garbage collection to release memory explicitly.   gc()  } # End of the main species loop."},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"visualization-of-spatial-predictions","dir":"Articles","previous_headings":"","what":"13. Visualization of spatial predictions","title":"Species distribution modeling for several species and climate change scenarios","text":"Iterate species process maps isolation. memory efficient loading everything .","code":"for (s_name in sp_names) {   message(paste(\"  - Processing maps for:\", s_name))      # 1. Search recursively for all prediction raster files (.tif) for the current species.   #    Each file represents a prediction from a different model or ensemble.   #    The pattern ensures only files ending with the species name and .tif extension are matched.   species_files <- list.files(     path = dir_current,     pattern = paste0(s_name, \".tif$\"), # '$' anchors the match to the end of the filename     recursive = TRUE,     full.names = TRUE   )      # If no prediction files are found for this species, output a message and skip to the next species.   if (length(species_files) == 0) {     message(paste(\"    - No prediction files were found for\", s_name, \". Skipping.\"))     next   }      # 2. Load all prediction raster files and convert them to a format suitable for plotting with ggplot2.   r_cont <- list() # list to store continuous models    r_semibin <- list() # list to store semi-binary models  for(i in 1:length(species_files)){   r_cont[[i]] <- terra::rast(species_files[i])[[1]]     r_semibin[[i]] <- terra::rast(species_files[i])[[2]]   } r_cont <- do.call(\"c\", r_cont)   r_semibin <- do.call(\"c\", r_semibin)   names(r_semibin) <- names(r_cont)  # 3. Plot the continuous habitat suitability maps for this species, with one facet per model. p_map_cont <- ggplot() +   tidyterra::geom_spatraster(data = r_cont) +   facet_wrap( ~ lyr) +    scale_fill_princess_c(palette = \"america\") +    theme_bw()  # 4. Plot the semibinary habitat suitability maps for this species, with one facet per model. p_map_semibin <- ggplot() +   tidyterra::geom_spatraster(data = r_semibin) +   facet_wrap( ~ lyr) +    scale_fill_princess_c(palette = \"america\") +    theme_bw()   # 5. Save the generated map as a PNG file in the figures directory, one file per species. ggsave(   filename = file.path(dir_fig, paste0(s_name, \"_cont_map\", \".png\")),   plot = p_map_cont,   width = 12, height = 10, dpi = 300 ) ggsave(   filename = file.path(dir_fig, paste0(s_name, \"_semibin_map\", \".png\")),   plot = p_map_semibin,   width = 12, height = 10, dpi = 300 ) message(paste(\" - Map saved for:\", s_name)) }  message(\"\\nCheck figures output in 'dir_fig' path\") message(\"\\nScript successfully completed!\")"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"visualize-future-projections","dir":"Articles","previous_headings":"","what":"14. Visualize future projections","title":"Species distribution modeling for several species and climate change scenarios","text":"","code":"# Base folder with future projections dir_future <- proj_dir[grep(paste0(\"2_Outputs/2_Projection\"), proj_dir)][1]  # List of scenarios (folders) scenario_folders <- list.dirs(dir_future, recursive = FALSE, full.names = TRUE)  for(s_name in sp_names){   message(\"Processing species: \", s_name)      for(sc_folder in scenario_folders){     sc_name <- basename(sc_folder)          # List algorithm folders     alg_folders <- list.dirs(file.path(sc_folder, \"Algorithm\"), recursive = FALSE, full.names = TRUE)          r_cont_list <- list()     r_semibin_list <- list()     alg_names <- character()          for(alg_folder in alg_folders){       alg_name <- basename(alg_folder)       r_file <- list.files(alg_folder, pattern = paste0(s_name, \".tif$\"), full.names = TRUE)       if(length(r_file) == 0) next              r_stack <- terra::rast(r_file)       r_cont_list[[alg_name]] <- r_stack[[1]]       r_semibin_list[[alg_name]] <- r_stack[[2]]       alg_names <- c(alg_names, alg_name)     }          # Skip if no raster files found     if(length(r_cont_list) == 0){       message(\"  - No raster files found for species \", s_name, \" in scenario \", sc_name, \". Skipping.\")       next     }          # Combine rasters into a single SpatRaster for ggplot faceting     r_cont <- r_cont_list[[1]]     for (i in 2:length(r_cont_list)) {       r_cont <- c(r_cont, r_cont_list[[i]])     }          r_semibin <- r_semibin_list[[1]]     for (i in 2:length(r_semibin_list)) {       r_semibin <- c(r_semibin, r_semibin_list[[i]])     }          names(r_semibin) <- names(r_cont)          # Continuous map     p_cont <- ggplot() +       tidyterra::geom_spatraster(data = r_cont) +       facet_wrap(~ lyr) +       scale_fill_princess_c(palette = \"america\") +       theme_bw() +       ggtitle(paste(s_name, sc_name, \"Continuous\"))          ggsave(file.path(dir_fig, paste0(s_name, \"_\", sc_name, \"_cont.png\")),            plot = p_cont, width = 12, height = 10, dpi = 300)          # Semibinary map     p_semibin <- ggplot() +       tidyterra::geom_spatraster(data = r_semibin) +       facet_wrap(~ lyr) +       scale_fill_princess_c(palette = \"america\") +       theme_bw() +       ggtitle(paste(s_name, sc_name, \"Semibinary\"))          ggsave(file.path(dir_fig, paste0(s_name, \"_\", sc_name, \"_semibin.png\")),            plot = p_semibin, width = 12, height = 10, dpi = 300)          message(\"  - Faceted maps saved for scenario \", sc_name)   } }"},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"15. Conclusion","title":"Species distribution modeling for several species and climate change scenarios","text":"workflow, demonstrated complex, complete species distribution modeling pipeline using flexsdm package. step--step breakdown process:","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"initial-setup","dir":"Articles","previous_headings":"15. Conclusion","what":"1. Initial Setup","title":"Species distribution modeling for several species and climate change scenarios","text":"Installation loading required packages Directory setup Basic R Markdown parameter configuration Setting seed reproducibility","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"data-preparation","dir":"Articles","previous_headings":"15. Conclusion","what":"2. Data Preparation","title":"Species distribution modeling for several species and climate change scenarios","text":"Loading palm species occurrence data Transformation coordinates spatial objects Initial visualization occurrence points (static interactive)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"environmental-data-1","dir":"Articles","previous_headings":"15. Conclusion","what":"3. Environmental Data","title":"Species distribution modeling for several species and climate change scenarios","text":"Download WorldClim bioclimatic variables (current future) Cropping area interest (South Brazil)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"deine-model-calibration-area","dir":"Articles","previous_headings":"15. Conclusion","what":"4. Deine model calibration area","title":"Species distribution modeling for several species and climate change scenarios","text":"Defined species-specific model calibration areas","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"correct-predictor-collinearity","dir":"Articles","previous_headings":"15. Conclusion","what":"6. Correct predictor collinearity","title":"Species distribution modeling for several species and climate change scenarios","text":"Applied species-specific PCA approach reduce multicollinearity","code":""},{"path":[]},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"pseudo-absence-generation","dir":"Articles","previous_headings":"15. Conclusion","what":"9. Pseudo-absence Generation","title":"Species distribution modeling for several species and climate change scenarios","text":"Creation training areas species Generation pseudo-absence points Combination presences pseudo-absences Visualization presence pseudo-absence points","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"data-partitioning-1","dir":"Articles","previous_headings":"15. Conclusion","what":"10. Data Partitioning","title":"Species distribution modeling for several species and climate change scenarios","text":"Division data training testing sets Use cross-validation (k-fold) Extraction environmental values points","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"modeling","dir":"Articles","previous_headings":"15. Conclusion","what":"12. Modeling","title":"Species distribution modeling for several species and climate change scenarios","text":"Fitting multiple algorithms: GLM (Generalized Linear Models) SVM (Support Vector Machines) Maxent (Maximum Entropy) Implementation two approaches: Standard models Ensemble models Generation prediction maps model Comparative visualization results Overlay presence points predictions Variable importance Apply models baseline future climate projections","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"visualize-spatial-predictions","dir":"Articles","previous_headings":"15. Conclusion","what":"13. Visualize spatial predictions","title":"Species distribution modeling for several species and climate change scenarios","text":"Visualize spatial predictions across different algorithms workflow represents complete SDM analysis, data preparation final model evaluation, using flexsdm package main tool. process designed reproducible allows robust comparison different modeling techniques. flexibility flexsdm makes excellent choice SDM analyses, allowing researchers implement best practices species distribution modeling within unified framework.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/articles/v07_Complete_workflow.html","id":"other-examples-of-an-entire-modeling-workflow-with-flexsdm-","dir":"Articles","previous_headings":"","what":"16. Other examples of an entire modeling workflow with flexsdm.","title":"Species distribution modeling for several species and climate change scenarios","text":"interested learning constructing SDM different species, types, amounts occurrence, also recommend exploring codes following papers: 1- Rey Pullido, K.G., & Velazco, S.J.E. (2025). protected areas effective area-based conservation measures conserve biodiversity. Exploring contribution Colombian snakes. Perspective Ecology Conservation, 23(2), pp.110-120. Occurrences record datasets available Codes used create species distribution models, perform spatial conservation prioritization, perform analyses available . 2- Rose, M. B., Elías Velazco, S. J., Regan, H. M., & Franklin, J. (2023). Rarity, geography, plant exposure global change California Floristic Province. Global Ecology Biogeography, 32(2), 218-232. datasets R script used analyses relating exposure species traits included manuscript Supporting Information. Additional scripts used build species distribution models, assess impact land use change, calculate exposure available GitHub repository.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Santiago J.E. Velazco. Author, maintainer. Brooke Rose. Author. André F.. Andrade. Author. Ignacio Minoli. Author. Janet Franklin. Author.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Velazco, S.J.E., Rose, M.B., Andrade, .F.., Minoli, ., Franklin, J. (2022).  flexsdm: R package supporting comprehensive flexible species distribution modelling workflow.  Methods Ecology Evolution, 13(8) 1661-1669. https://doi.org/10.1111/2041-210X.13874","code":"@Article{,   title = {flexsdm: An R package for supporting a comprehensive and flexible species distribution modelling workflow},   author = {Santiago J.E. Velazco and Brooke Rose and André F.A. Andrade and Ignacio Minoli and Janet Franklin},   journal = {Methods in Ecology and Evolution},   year = {2022},   volume = {13},   number = {8},   pages = {1661-1669},   url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13874}, }"},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"flexsdm---email-list","dir":"","previous_headings":"","what":"flexsdm - email list","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"Dear flexsdm user, interested receiving email notifications modifications made package (e.g., new functions, arguments, vignettes), please fill form can keep updated new flexsdm. Explore new R package adm construct abundance-based species distribution models.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"Species distribution modeling become standard tool several research areas ecology, conservation biology, biogeography, paleobiogeography, epidemiology. Species distribution modeling area active research theoretical methodological aspects. One exciting features flexsdm high manipulation parametrization capacity based different functions arguments. attributes enable users define complete partial modeling workflow specific modeling situation (e.g., number variables, number records, different algorithms, algorithms tuning, ensemble methods).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"structure-of-flexsdm","dir":"","previous_headings":"","what":"Structure of flexsdm","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"functions flexsdm package organized three major modeling steps","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"id_1-pre-modeling-functions","dir":"","previous_headings":"","what":"1. Pre-modeling functions","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"Set tools prepare modeling input data (e.g., species occurrences thinning, sample pseudo-absences background points, delimitation calibration area). calib_area() Delimit calibration area constructing species distribution models correct_colinvar() Collinearity reduction predictors env_outliers() Integration outliers detection methods environmental space part_random() Data partitioning training testing models part_sblock() Spatial block cross validation part_sband() Spatial band cross validation part_senv() Environmental cross-validation plot_res() Plot different resolutions used part_sblock get_block() Transform spatial partition layer spatial properties environmental variables sample_background() Sample background points sample_pseudoabs() Sampel pseudo-absence sdm_directory() Create directories saving outputs flexsdm sdm_extract() Extract environmental data based x y coordinates occfilt_env() Perform environmental filtering species occurrences occfilt_geo() Perform geographical filtering species occurrences occfilt_select() Select filtered occurrences tested different filtering values map_env_dist() Calculate environmental distance presences projection data","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"id_2-modeling-functions","dir":"","previous_headings":"","what":"2. Modeling functions","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"includes functions related modeling construction validation. Several can grouped fit_*, tune_*, esm_* family functions. fit_* construct validate models default hyper-parameter values. tune_* construct validate models searching best hyper-parameter values combination. esm_ construct validate Ensemble Small Models.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"model-evaluation","dir":"","previous_headings":"2. Modeling functions","what":"Model evaluation","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"sdm_eval() Calculate different model performance metrics","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"fit_-functions-family","dir":"","previous_headings":"2. Modeling functions","what":"fit_* functions family","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"fit_dom() Fit validate Domain models fit_gam() Fit validate Generalized Additive Models fit_gau() Fit validate Gaussian Process models fit_gbm() Fit validate Generalized Boosted Regression models fit_glm() Fit validate Generalized Linear Models fit_max() Fit validate Maximum Entropy models fit_net() Fit validate Neural Networks models fit_raf() Fit validate Random Forest models fit_svm() Fit validate Support Vector Machine models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"tune_-functions-family","dir":"","previous_headings":"2. Modeling functions","what":"tune_* functions family","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"tune_gbm() Fit validate Generalized Boosted Regression models exploration hyper-parameters tune_max() Fit validate Maximum Entropy models exploration hyper-parameters tune_net() Fit validate Neural Networks models exploration hyper-parameters tune_raf() Fit validate Random Forest models exploration hyper-parameters tune_svm() Fit validate Support Vector Machine models exploration hyper-parameters","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"model-ensemble","dir":"","previous_headings":"2. Modeling functions","what":"Model ensemble","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"fit_ensemble() Fit validate ensemble models different ensemble methods","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"esm_-functions-family","dir":"","previous_headings":"2. Modeling functions","what":"esm_* functions family","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"esm_gam() Fit validate Generalized Additive Models Ensemble Small Model approach esm_gau() Fit validate Gaussian Process models Models Ensemble Small Model approach esm_gbm() Fit validate Generalized Boosted Regression models Ensemble Small Model approach esm_glm() Fit validate Generalized Linear Models Ensemble Small Model approach esm_max() Fit validate Maximum Entropy models Ensemble Small Model approach esm_net() Fit validate Neural Networks models Ensemble Small Model approach esm_svm() Fit validate Support Vector Machine models Ensemble Small Model approach","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"id_3-post-modeling-functions","dir":"","previous_headings":"","what":"3. Post-modeling functions","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"Tools related models’ geographical predictions, evaluation, correction. sdm_predict() Spatial predictions individual ensemble model sdm_summarize() Merge model performance tables interp() Raster interpolation two time periods extra_eval() Measure model extrapolation extra_truncate() Constraint suitability values given extrapolation value msdm_priori() Create spatial predictor variables reduce overprediction species distribution models msdm_posteriori() Methods correct overprediction species distribution models based occurrences suitability patterns.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"id_4-graphical-model-exploration","dir":"","previous_headings":"","what":"4. Graphical model exploration","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"Useful tools visually explore models’ geographical environemtal predictions, model extrapolation, partial depnendece plot. p_pdp() Create partial dependence plot(s) explore marginal effect predictors suitability p_bpdp() Create partial dependence surface plot(s) explore bivariate marginal effect predictors suitability p_extra() Graphical exploration extrapolation suitability pattern environmental geographical space data_pdp() Calculate data construct partial dependence plots data_bpdp() Calculate data construct partial dependence surface plots","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"can install development version flexsdm github ⚠️ NOTE: version 1.4-22 terra package causing errors trying instal flexsdm. Please, first install version ≥ 1.5-12 terra package available CRAN development version terra flexsdm.","code":"# install.packages(\"remotes\")  # For Windows and Mac OS operating systems remotes::install_github(\"sjevelazco/flexsdm\")  # For Linux operating system remotes::install_github(\"sjevelazco/flexsdm@HEAD\")"},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"package-website","dir":"","previous_headings":"","what":"Package website","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"See package website (https://sjevelazco.github.io/flexsdm/) functions explanation vignettes.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/index.html","id":"package-citation","dir":"","previous_headings":"","what":"Package citation","title":"Tools for Data Preparation, Fitting, Prediction, Evaluation, and Post-Processing of Species Distribution Models","text":"Velazco, S.J.E., Rose, M.B., Andrade, .F.., Minoli, ., Franklin, J. (2022). flexsdm: R package supporting comprehensive flexible species distribution modelling workflow. Methods Ecology Evolution, 13(8) 1661–1669. https://doi.org/10.1111/2041-210X.13874 Test package give us feedback send e-mail sjevelazco@gmail.com.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/abies.html","id":null,"dir":"Reference","previous_headings":"","what":"A data set containing localities and environmental condition of an Abies (fir tree) species in California, USA — abies","title":"A data set containing localities and environmental condition of an Abies (fir tree) species in California, USA — abies","text":"data set containing localities environmental condition Abies (fir tree) species California, USA","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/abies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data set containing localities and environmental condition of an Abies (fir tree) species in California, USA — abies","text":"","code":"abies"},{"path":"https://sjevelazco.github.io/flexsdm/reference/abies.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data set containing localities and environmental condition of an Abies (fir tree) species in California, USA — abies","text":"tibble object 5000 rows 10 variables: ID presences absences records ID pr_ab presence absences denoted 1 0 respectively x y columns coordinates Albers Equal Area Conic coordinate system column aet landform columns values environmental variables locality","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/abies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A data set containing localities and environmental condition of an Abies (fir tree) species in California, USA — abies","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) data(\"abies\") abies } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/backg.html","id":null,"dir":"Reference","previous_headings":"","what":"A data set containing environmental conditions of background points — backg","title":"A data set containing environmental conditions of background points — backg","text":"data set containing environmental conditions background points","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/backg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data set containing environmental conditions of background points — backg","text":"","code":"backg"},{"path":"https://sjevelazco.github.io/flexsdm/reference/backg.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data set containing environmental conditions of background points — backg","text":"tibble object 5000 rows 10 variables: pr_ab background point denoted 0 x y columns geographical coordinates column aet landform columns values environmental variables coordinate locations","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/backg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A data set containing environmental conditions of background points — backg","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) data(\"backg\") backg } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/calib_area.html","id":null,"dir":"Reference","previous_headings":"","what":"Delimit calibration area for constructing species distribution models — calib_area","title":"Delimit calibration area for constructing species distribution models — calib_area","text":"function offers different methods define calibration area. output used flexsdm functions like sample_backgroud, sample_pseudoabs, sdm_predict, among others","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/calib_area.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delimit calibration area for constructing species distribution models — calib_area","text":"","code":"calib_area(data, x, y, method, groups = NULL, crs = NULL)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/calib_area.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delimit calibration area for constructing species distribution models — calib_area","text":"data data.frame tibble. Database presences x character. Column name longitude data y character. Column name latitude data method character. Method used delimiting calibration area. necessary concatenate (c()) different objects argument. following methods implemented: buffer: calibration area defined buffer around presences. Usage method = c('buffer', width=40000). value buffer width m must provided CRS longitude/latitude, map units cases mcp: calibration area defined minimum convex polygon. Usage method = 'mcp'. bmcp: calibration area defined buffered minimum convex polygon buffer width. Usage method = c('bmcp', width=40000). value buffer width m must provided CRS longitude/latitude, map units cases mask: calibration area defined selected polygons spatial vector object intersected presences. Usage method = c(\"mask\", clusters, \"DN\"). second concatenated element must SpatVector, third element character column name SpatVector used filtering polygons. groups character. Column name indicating differentiated subsets points. used mcp bmcp method. Default NULL crs character. Coordinate reference system used transforming occurrences outputs. set NULL, result mask method crs SpatVector used. Define crs  mandatory buffer, mcp bmcp method.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/calib_area.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delimit calibration area for constructing species distribution models — calib_area","text":"SpatVector","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/calib_area.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delimit calibration area for constructing species distribution models — calib_area","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr) data(\"spp\") clusters <- system.file(\"external/clusters.shp\", package = \"flexsdm\") clusters <- terra::vect(clusters)   single_spp <-   spp %>%   dplyr::filter(species == \"sp1\") %>%   dplyr::filter(pr_ab == 1) %>%   dplyr::select(-pr_ab)   plot(clusters) points(single_spp[-1], col = \"red\") crs(clusters, proj = TRUE) # coordinate reference system (CRS) used for this points database # note that the unit of this CRS is in m, consequently the buffer width # will be interpreted in m too  # buffer method ca_1 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = c(\"buffer\", width = 40000),   crs = crs(clusters) ) plot(ca_1) points(single_spp[, 2:3], pch = 19, cex = 0.5)  # mcp method ca_2 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = \"mcp\",   crs = crs(clusters) ) plot(ca_2) points(single_spp[, 2:3], pch = 19, cex = 0.5)  # mcp method for different groups single_spp <- single_spp %>% mutate(groups = ifelse(x > 150000, \"a\", \"b\"))  plot(single_spp[, 2:3], pch = 19, col = \"blue\") points(single_spp[single_spp$groups == \"a\", 2:3], col = \"red\", pch = 19) points(single_spp[, 2:3])  ca_2.1 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = c(\"mcp\"),   crs = crs(clusters),   groups = \"groups\" ) plot(ca_2.1) points(single_spp[, 2:3], pch = 19, cex = 0.5)  # bmcp method ca_3 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = c(\"bmcp\", width = 30000),   crs = crs(clusters) ) plot(ca_3) points(single_spp[, 2:3], pch = 19, cex = 0.5)  # bmcp method for different groups ca_3.1 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = c(\"bmcp\", width = 30000),   crs = crs(clusters),   groups = \"groups\" ) plot(ca_3.1) points(single_spp[, 2:3], pch = 19, cex = 0.5)  # mask method plot(clusters) names(clusters)  ca_3.1 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = c(\"mask\", clusters, \"clusters\"), ) plot(ca_3.1) points(single_spp[, 2:3], pch = 19, cex = 0.5, col = \"red\") } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/correct_colinvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Collinearity reduction of predictor variables — correct_colinvar","title":"Collinearity reduction of predictor variables — correct_colinvar","text":"Collinearity reduction predictor variables","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/correct_colinvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collinearity reduction of predictor variables — correct_colinvar","text":"","code":"correct_colinvar(   env_layer,   method,   proj = NULL,   save_proj = NULL,   restric_to_region = NULL,   restric_pca_proj = FALSE,   maxcell = NULL,   based_on_points = FALSE,   data = NULL,   x = NULL,   y = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/correct_colinvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collinearity reduction of predictor variables — correct_colinvar","text":"env_layer SpatRaster object class SpatRaster containing predictors. function allow categorical variables method character. Collinearity reduction method. necessary provide vector argument. next methods implemented: pearson: Highlights correlated variables according Pearson correlation. threshold maximum correlation   must specified. Otherwise, threshold 0.7 defined default.   Usage method = c('pearson', th='0.7'). vif: Select variables Variance Inflation Factor, threshold can specified   user. Otherwise, threshold 10 defined default.Usage method = c('vif', th = '10'). pca: Perform Principal Component Analysis use principal components   new predictors. selected components account 95% whole variation system.   Usage method = c('pca'). fa: Perform Factorial Analysis select, original predictors, number factors defined Broken-Stick variables highest correlation factors selected.  Usage method = c('fa'). proj character. used pca method. Path folder contains sub-folders different projection scenarios. Variables names must names raster used env_layer argument. Usage proj = \"C:/User/Desktop/Projections\" (see Details use argument) save_proj character. Directory save PCA projection. Default NULL. restric_to_region SpatVector. Area used restrict cells env_layer moment perform collinearity reduction. Default: NULL. restric_pca_proj logical. Area used restrict geographically PCA projection within SpatVector used restric_to_region. use PCA analysis. Default: FALSE. maxcell numeric. Number raster cells randomly sampled. Taking sample useful reduce memory usage large rasters. NULL, function use raster cells. Default NULL. Usage maxcell = 50000. based_on_points logical. TRUE, collinearity reduction method based species points data (.e., presences, absences, pseudo-absences background points). TRUE, data, x y arguments must provided. Default FALSE. data tibble data.frame. Database species data used model (.e., presence + absence, presence + pseudo-absence + background points) x y coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/correct_colinvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collinearity reduction of predictor variables — correct_colinvar","text":"#' 'pearson', returns list following elements: cor_table: matrix object pairwise correlation values environmental variables cor_variables: list object length number environmental  values containing pairwise relations exceeded correlation  threshold one environmental variables 'vif' method, returns list following elements: env_layer: SpatRaster object selected environmental variables removed_variables: character vector removed environmental variables vif_table: data frame VIF values environmental variables 'pca' method, returns list following elements: env_layer: SpatRaster scores selected principal component (PC) sum 95% whole variation original environmental variables coefficients: matrix coefficient principal component (PC) predictors cumulative_variance: tibble cumulative variance explained selected principal component (PC) 'fa' method, returns list following elements: env_layer: SpatRaster scores selected variables due correlation factors. number_factors: number factors selected according Broken-Stick criteria, removed_variables: removed variables, uniqueness: uniqueness environmental variable according factorial analysis, loadings: environmental variables loadings chosen factors","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/correct_colinvar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collinearity reduction of predictor variables — correct_colinvar","text":"case environmental variables current conditions time periods (future present), recommended perform PCA analysis current environmental condition project PCA time periods. , necessary use “proj” argument. Path folder (e.g., projections) contains sub-folders different projection scenarios (e.g., years emissions). Within sub-folder must stored single multiband rasters environmental variables. example: C:/Users/my_pc/projections/      ├── MRIESM_2050_ssp126      │   └── var1.tif     │   └── var2.tif     │   └── var3.tif     ├── MRIESM_2080_ssp585     │   └── var1.tif     │   └── var2.tif     │   └── var3.tif     ├── UKESM_2050_ssp370     │   └── var1.tif     │   └── var2.tif     │   └── var3.tif pca method run time projections, correct_colinvar function create Projection_PCA (exact path path object returned function) system sub-folders multiband raster principal components (pcs.tif) C:/Users/my_pc/Projection_PCA/       ├── MRIESM_2050_ssp126       │   └── pcs.tif           # multiband tif principal components       ├── MRIESM_2080_ssp585       │   └── pcs.tif       ├── UKESM_2050_ssp370       │   └── pcs.tif Perform collinearity reduction based points Evaluating collinearity based environmental conditions calibration area study area yield different results evaluating collinearity based points used construct models. want perform collinearity reduction based species points data, strongly recommended use point data used modeling (.e., presence + absence presence + pseudo-absence/background points).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/correct_colinvar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collinearity reduction of predictor variables — correct_colinvar","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Perform pearson collinearity control var <- correct_colinvar(env_layer = somevar, method = c(\"pearson\", th = \"0.7\")) var$cor_table var$cor_variables  # For all correct_colinvar methods it is possible to take a sample or raster to reduce memory var <- correct_colinvar(env_layer = somevar, method = c(\"pearson\", th = \"0.7\"), maxcell = 10000) var$cor_table var$cor_variables  # Perform vif collinearity control var <- correct_colinvar(env_layer = somevar, method = c(\"vif\", th = \"8\")) var$env_layer var$removed_variables var$vif_table  # Perform pca collinearity control var <- correct_colinvar(env_layer = somevar, method = c(\"pca\")) plot(var$env_layer) var$env_layer var$coefficients var$cumulative_variance   # Perform pca collinearity control with different projections ## Below will be created a set of folders to simulate the structure of the ## directory where environmental variables are stored for different scenarios dir_sc <- file.path(tempdir(), \"projections\") dir.create(dir_sc) dir_sc <- file.path(dir_sc, c(\"scenario_1\", \"scenario_2\")) sapply(dir_sc, dir.create)  somevar <-   system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  terra::writeRaster(somevar, file.path(dir_sc[1], \"somevar.tif\"), overwrite = TRUE) terra::writeRaster(somevar, file.path(dir_sc[2], \"somevar.tif\"), overwrite = TRUE)  ## Perform pca with projections dir_w_proj <- dirname(dir_sc[1]) dir_w_proj var <- correct_colinvar(env_layer = somevar, method = \"pca\", proj = dir_w_proj) var$env_layer var$coefficients var$cumulative_variance var$proj   # Perform fa colinearity control var <- correct_colinvar(env_layer = somevar, method = c(\"fa\")) var$env_layer var$number_factors var$removed_variables var$uniqueness var$loadings  ## %######################################################%## #                                                          # ####            Other option to perform PCA             #### ####      considering cell restricted to a region       #### #                                                          # ## %######################################################%## data(\"abies\")  # Define a calibration area abies2 <- abies %>%   dplyr::select(x, y, pr_ab) %>%   dplyr::filter(pr_ab == 1)  plot(somevar[[1]]) points(abies2[-3]) ca <- calib_area(abies2, x = \"x\", y = \"y\", method = c(\"mcp\"), crs = crs(somevar)) plot(ca, add = T)  # Full geographical range to perform PCA pca_fr <- correct_colinvar(   env_layer = somevar,   method = c(\"pca\"),   maxcell = NULL,   restric_to_region = NULL,   restric_pca_proj = FALSE )  # Perform PCA only with cell delimited by polygon used in restric_to_region pca_rr <- correct_colinvar(   env_layer = somevar,   method = c(\"pca\"),   maxcell = NULL,   restric_to_region = ca,   restric_pca_proj = FALSE )  # Perform and predicted PCA only with cell delimited by polygon used in restric_to_region pca_rrp <- correct_colinvar(   env_layer = somevar,   method = c(\"pca\"),   maxcell = NULL,   restric_to_region = ca,   restric_pca_proj = TRUE )  plot(pca_fr$env_layer) # PCA with all cells plot(pca_rr$env_layer) # PCA with calibration area cell but predicted for entire region plot(pca_rrp$env_layer) # PCA performed and predicted for cells within calibration area (ca)    ##%######################################################%## #                                                          # ####       Use correct_colinvar with points data        #### #                                                          # ##%######################################################%## data(\"abies\")  # Presence-absence database abies2 <- abies %>%   dplyr::select(x, y, pr_ab)  # Perform collinearity control # Pearson correct_colinvar(   env_layer = somevar,   method = c(\"pearson\", th = \"0.6\"),   based_on_points = TRUE,   data = abies2,   x = \"x\",   y = \"y\" )  # VIF correct_colinvar(   env_layer = somevar,   method = c(\"vif\", th = \"8\"),   based_on_points = TRUE,   data = abies2,   x = \"x\",   y = \"y\" )  # PCA correct_colinvar(   env_layer = somevar,   method = c(\"pca\"),   based_on_points = TRUE,   data = abies2,   x = \"x\",   y = \"y\" )  # FA correct_colinvar(   env_layer = somevar,   method = \"fa\",   based_on_points = TRUE,   data = abies2,   x = \"x\",   y = \"y\" )  } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_bpdp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate data to construct partial dependence surface plots — data_bpdp","title":"Calculate data to construct partial dependence surface plots — data_bpdp","text":"Calculate data construct Partial dependence surface plot (.e., bivariate dependence plot) two predictor set","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_bpdp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate data to construct partial dependence surface plots — data_bpdp","text":"","code":"data_bpdp(   model,   predictors,   resolution = 50,   training_data = NULL,   training_boundaries = NULL,   projection_data = NULL,   clamping = FALSE )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_bpdp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate data to construct partial dependence surface plots — data_bpdp","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector two predictor name(s) plot. NULL predictors plotted. Default NULL resolution numeric. Number equally spaced points predict continuous predictors. Default 50 training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL training_boundaries character. Plot training conditions boundaries based training data (.e., presences, presences absences, etc). training_boundaries = \"convexh\", function delimit training environmental region based convex-hull. training_boundaries = \"rectangle\", function delimit training environmental region based four straight lines. used methods necessary provide data training_data argument. NULL predictors used. Default NULL. projection_data SpatRaster. Raster layer environmental variables used model projection. Default NULL clamping logical. Perform clamping. maxent models. Default FALSE","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_bpdp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate data to construct partial dependence surface plots — data_bpdp","text":"list two tibbles \"pdpdata\" \"resid\". pspdata: data construct partial dependence surface plot, first two column includes values selected environmental variables, third column predicted suitability. training_boundaries: data plot boundaries training data.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_bpdp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate data to construct partial dependence surface plots — data_bpdp","text":"","code":"if (FALSE) { # \\dontrun{ library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  abies2 <- abies %>%   select(x, y, pr_ab)  abies2 <- sdm_extract(abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  m <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  df <- data_bpdp(   model = m$model,   predictors = c(\"aet\", \"cwd\"),   resolution = 50,   projection_data = somevar,   training_boundaries = \"rectangle\",   training_data = abies2,   clamping = TRUE )  df names(df) df$pspdata df$training_boundaries  # see p_bpdp to construct partial dependence plot with ggplot2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_pdp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate data to construct partial dependence plots — data_pdp","title":"Calculate data to construct partial dependence plots — data_pdp","text":"Calculate data construct partial dependence plots given predictor","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_pdp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate data to construct partial dependence plots — data_pdp","text":"","code":"data_pdp(   model,   predictors,   resolution = 50,   resid = FALSE,   training_data = NULL,   projection_data = NULL,   clamping = FALSE )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_pdp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate data to construct partial dependence plots — data_pdp","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector predictor name. resolution numeric. Number equally spaced points predict continuous predictors. Default 50 resid logical. Calculate residuals based training data. Default FALSE training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL projection_data SpatRaster. Raster layer environmental variables used model projection. argument used, function calculate partial dependence curves distinguishing conditions used training projection conditions (.e., projection data present projection area training). Default NULL clamping logical. Perform clamping. maxent models. Default FALSE","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_pdp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate data to construct partial dependence plots — data_pdp","text":"list two tibbles \"pdpdata\" \"resid\". pdpdata: data construct partial dependence plots, first column includes values selected environmental variable, second column predicted suitability, third  column range type, two values Training Projecting, referring suitability  calculated within outside range training conditions. Third column returned  \"projection_data\" argument used resid: data plot residuals. first column includes values selected environmental  variable second column predicted suitability.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_pdp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate data to construct partial dependence plots — data_pdp","text":"","code":"if (FALSE) { # \\dontrun{ library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  abies2 <- abies %>%   select(x, y, pr_ab)  abies2 <- sdm_extract(abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  df <- data_pdp(   model = svm_t1$model,   predictors = c(\"aet\"),   resolution = 100,   resid = TRUE,   projection_data = somevar,   training_data = abies2,   clamping = FALSE )  df names(df) df$pdpdata df$resid  plot(df$pdpdata[1:2], type = \"l\") points(df$resid[1:2], cex = 0.5)  # see p_pdp to construct partial dependence plot with ggplot2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_psp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate data to construct partial dependence surface plots — data_psp","title":"Calculate data to construct partial dependence surface plots — data_psp","text":"Calculate data construct Partial dependence surface plot (.e., bivariate dependence plot) two predictor set","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_psp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate data to construct partial dependence surface plots — data_psp","text":"","code":"data_psp(   model,   predictors,   resolution = 50,   training_data = NULL,   pchull = FALSE,   projection_data = NULL,   clamping = FALSE )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_psp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate data to construct partial dependence surface plots — data_psp","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector two predictor name(s) plot. NULL predictors plotted. Default NULL resolution numeric. Number equally spaced points predict continuous predictors. Default 50 training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL pchull logical. Extract convex-hull limit training data. Default FALSE projection_data SpatRaster. Raster layer environmental variables used model projection. Default NULL clamping logical. Perform clamping. maxent models. Default FALSE","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_psp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate data to construct partial dependence surface plots — data_psp","text":"list two tibbles \"pdpdata\" \"resid\". pspdata: data construct partial dependence surface plot, first two column includes values selected environmental variables, third column predicted suitability. pchull: data plot residuals convex hull polygon bounding calibration data.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/data_psp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate data to construct partial dependence surface plots — data_psp","text":"","code":"if (FALSE) { library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  abies2 <- abies %>%   select(x, y, pr_ab)  abies2 <- sdm_extract(abies2,                       x = \"x\",                       y = \"y\",                       env_layer = somevar ) abies2 <- part_random(abies2,                       pr_ab = \"pr_ab\",                       method = c(method = \"kfold\", folds = 5) )  m <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  df <- data_psp(   model = m$model,   predictors = c(\"aet\", \"cwd\"),   resolution = 50,   projection_data = somevar,   pchull = TRUE,   training_data = abies2,   clamping = TRUE )  df names(df) df$pspdata df$pchull  # see p_psp to construct partial dependence plot with ggplot2 }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration of outliers detection methods in environmental space — env_outliers","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"function performs different methods detecting outliers species distribution data based environmental conditions occurrences. methods need presence absence data (e.g. Two-class Support Vector Machine Random Forest) use presences (e.g. Reverse Jackknife, Box-plot, Random Forest outliers) . Outlier detection can useful procedure occurrence data cleaning (Chapman 2005, Liu et al., 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"","code":"env_outliers(data, x, y, pr_ab, id, env_layer)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"data data.frame tibble presence (presence-absence) records, coordinates x character. Column name longitude data. y character. Column name latitude data. pr_ab character. Column name presence absence data (.e. 1 0) id character. Column name row id. row (record) must unique code. env_layer SpatRaster. Raster environmental variables","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"tibble object database used 'data' argument seven additional columns, 1 0 denote presence detected outliers .out_bxpt: outliers detected Box-plot method .out_jack: outliers detected Reverse Jackknife method .out_svm: outliers detected Support Vector Machine method .out_rf: outliers detected Random Forest method .out_rfout: outliers detected Random Forest Outliers method .out_sum: frequency presences records detected outliers   based previews methods (values 0 6).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"function apply outliers detection methods occurrence data. Box-plot Reverse Jackknife method test outliers variable individually, occurrence behaves outlier least one variable highlighted outlier. user uses presence data, Support Vector Machine Random Forest Methods performed. Support Vector Machine Random Forest performed default hyper-parameter values. case species < 7 occurrences, function perform methods (.e. additional columns 0 values); nonetheless, return tibble additional columns 0 1. information methods, see Chapman (2005), Liu et al. (2018), Velazco et al. (2022).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"Chapman, . D. (2005). Principles methods data cleaning: Primary Species   Species- Occurrence Data. version 1.0. Report Global Biodiversity Information   Facility, Copenhagen. p72.  http://www.gbif.org/document/80528 Liu, C., White, M., & Newell, G. (2018). Detecting outliers species distribution   data. Journal Biogeography, 45(1), 164 - 176. https://doi.org/10.1111/jbi.13122 Velazco, S.J.E.; Bedrij, N..; Keller, H..; Rojas, J.L.; Ribeiro, B.R.; De Marco, P. (2022)   Quantifying role protected areas safeguarding uses biodiversity.   Biological Conservation, xx(xx) xx-xx. https://doi.org/10.1016/j.biocon.2022.109525","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/env_outliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integration of outliers detection methods in environmental space — env_outliers","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra) require(ggplot2)  # Environmental variables somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Species occurrences data(\"spp\") spp spp1 <- spp %>% dplyr::filter(species == \"sp1\")  somevar[[1]] %>% plot() points(spp1 %>% filter(pr_ab == 1) %>% select(x, y), col = \"blue\", pch = 19) points(spp1 %>% filter(pr_ab == 0) %>% select(x, y), col = \"red\", cex = 0.5)  spp1 <- spp1 %>% mutate(idd = 1:nrow(spp1))  # Detect outliers outs_1 <- env_outliers(   data = spp1,   pr_ab = \"pr_ab\",   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar )  # How many outliers were detected by different methods? out_pa <- outs_1 %>%   dplyr::select(starts_with(\".\"), -.out_sum) %>%   apply(., 2, function(x) sum(x, na.rm = T)) out_pa  # How many outliers were detected by the sum of different methods? outs_1 %>%   dplyr::group_by(.out_sum) %>%   dplyr::count()  # Let explor where are locate records highlighted as outliers outs_1 %>%   dplyr::filter(pr_ab == 1, .out_sum > 0) %>%   ggplot(aes(x, y)) +   geom_point(aes(col = factor(.out_sum))) +   facet_wrap(. ~ factor(.out_sum))  # Detect outliers only with presences outs_2 <- env_outliers(   data = spp1 %>% dplyr::filter(pr_ab == 1),   pr_ab = \"pr_ab\",   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar )  # How many outliers were detected by different methods out_p <- outs_2 %>%   dplyr::select(starts_with(\".\"), -.out_sum) %>%   apply(., 2, function(x) sum(x, na.rm = T))  # How many outliers were detected by the sum of different methods? outs_2 %>%   dplyr::group_by(.out_sum) %>%   dplyr::count()  # Let explor where are locate records highlighted as outliers outs_2 %>%   dplyr::filter(pr_ab == 1, .out_sum > 0) %>%   ggplot(aes(x, y)) +   geom_point(aes(col = factor(.out_sum))) +   facet_wrap(. ~ factor(.out_sum))   # Comparison of function outputs when using it with # presences-absences or only presences data.  bind_rows(out_p, out_pa) # Because the second case only were used presences, outliers methods # based in Random Forest (.out_rf) and Support Vector Machines (.out_svm) # were not performed. } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"function constructs Generalized Additive Models using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"","code":"esm_gam(data, response, predictors, partition, thr = NULL, k = 3)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1) predictors character. Vector column names quantitative predictor variables (.e. continuous variables). function allow categorical variables can construct models continuous variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\"). partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default value 0.9. user wants include one threshold type, necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified k integer. dimension basis used represent smooth term. Default 3. ESM proposed fit models little data, recommend using small values parameter.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"list object : esm_model: list \"gam\" class object mgcv package bivariate model. object can used predicting ensemble small models sdm_predict function. predictors: tibble variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metrics calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018). function fits GAM using mgvc package, Binomial distribution family thin plate regression spline smoothing basis (see ?mgvc::s).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Additive Models based on Ensembles of Small Models approach — esm_gam","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 3) ) abies2  # Without threshold specification and with kfold esm_gam_t1 <- esm_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL )  esm_gam_t1$esm_model # bivariate model esm_gam_t1$predictors esm_gam_t1$performance esm_gam_t1$performance_part  # Test with rep_kfold partition abies2 <- abies2 %>% select(-starts_with(\".\"))  set.seed(10) abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  esm_gam_t2 <- esm_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL ) esm_gam_t2$esm_model # bivariate model esm_gam_t2$predictors esm_gam_t2$performance  # Test with other bootstrap abies2 <- abies2 %>% select(-starts_with(\".\"))  set.seed(10) abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 10, proportion = 0.7) ) abies2  esm_gam_t3 <- esm_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL ) esm_gam_t3$esm_model # bivariate model esm_gam_t3$predictors esm_gam_t3$performance } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"function constructs Gaussian Process models using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"","code":"esm_gau(data, response, predictors, partition, thr = NULL, background = NULL)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1) predictors character. Vector column names quantitative predictor variables (.e. continuous variables). function allow categorical variables can construct models continuous variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\") partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default value 0.9. user wants include one threshold type, necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified background data.frame. Database response column 0 predictors variables. column names must consistent data. Default NULL","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"list object : esm_model: list \"graf\" class object bivariate model. object can used predicting ensembles small models sdm_predict function. predictors: tibble variables use modeling. performance: Performance metric (see sdm_eval). threshold dependent metric calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"method consists creating bivariate models pair-wise combinations predictors performs ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gau.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Gaussian Process models based on Ensembles of Small Models approach — esm_gau","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  # Without threshold specification and with kfold esm_gau_t1 <- esm_gau(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL )  esm_gau_t1$esm_model # bivariate model esm_gau_t1$predictors esm_gau_t1$performance esm_gau_t1$performance_part } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"function constructs Generalized Boosted Regression using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"","code":"esm_gbm(   data,   response,   predictors,   partition,   thr = NULL,   n_trees = 100,   n_minobsinnode = NULL,   shrinkage = 0.1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1) predictors character. Vector column names quantitative predictor variables (.e. continuous variables). can construct models continuous variables allow categorical variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\") partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB  (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default value 0.9. case use one threshold type necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. n_trees Integer specifying total number trees fit. equivalent number iterations number basis functions additive expansion. Default 100. n_minobsinnode Integer specifying minimum number observations terminal nodes trees. Note actual number observations, total weight. n_minobsinnode NULL, parameter assume value equal nrow(data)*0.5/4. Default NULL. shrinkage Numeric. parameter applied tree expansion. Also known learning rate step-size reduction; 0.001 0.1 usually works, smaller learning rate typically requires trees. Default 0.1.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"list object : esm_model: list \"gbm\" class object gbm package bivariate model. object can used predicting ensembles small models sdm_predict function. predictors: tibble variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metrics calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_gbm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Boosted Regression models based on Ensembles of Small Models approach — esm_gbm","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  # Without threshold specification and with kfold esm_gbm_t1 <- esm_gbm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL,   n_trees = 100,   n_minobsinnode = NULL,   shrinkage = 0.1 )  esm_gbm_t1$esm_model # bivariate model esm_gbm_t1$predictors esm_gbm_t1$performance esm_gbm_t1$performance_part } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"function constructs Generalized Linear Models using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"","code":"esm_glm(   data,   response,   predictors,   partition,   thr = NULL,   poly = 0,   inter_order = 0 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). can construct models continuous variables allow categorical variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\"). partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard highest. max_sorensen: threshold Sorensen highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default value 0.9. user wants include one threshold type, necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified poly integer >= 2. used values >= 2 model use polynomials continuous variables (.e. used predictors argument). Default 0. ESM constructed occurrences recommended use polynomials avoid overfitting. inter_order integer >= 0. interaction order explanatory variables. Default 0. ESM constructed occurrences recommended use interaction terms.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"list object : esm_model: list \"glm\" class object stats package bivariate model. object can used predicting ensembles small models sdm_predict function. predictors: tibble variables use modeling. performance: Performance metric (see sdm_eval). threshold dependent metric calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Linear Models based on Ensembles of Small Models approach — esm_glm","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  # Without threshold specification and with kfold esm_glm_t1 <- esm_glm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL,   poly = 0,   inter_order = 0 )  esm_glm_t1$esm_model # bivariate model esm_glm_t1$predictors esm_glm_t1$performance esm_glm_t1$performancePart } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"function constructs Maxent Models using Ensemble Small Model (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"","code":"esm_max(   data,   response,   predictors,   partition,   thr = NULL,   background = NULL,   clamp = TRUE,   classes = \"default\",   pred_type = \"cloglog\",   regmult = 2.5 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1) predictors character. Vector column names quantitative predictor variables (.e. continuous variables). function can construct models continuous variables, allow categorical variables Usage predictors = c(\"aet\", \"cwd\", \"tmin\"). partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard highest. max_sorensen: threshold Sorensen highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default 0.9 user wants include one threshold type, necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. background data.frame. Database response column 0 predictors variables. column names must consistent data. Default NULL clamp logical. set TRUE, predictors features restricted range seen model training. classes character. single feature combinations . Features symbolized letters: l (linear), q (quadratic), h (hinge), p (product), t (threshold). Usage classes = \"lpq\". Default \"default\" (see details). pred_type character. Type response required available \"link\", \"exponential\", \"cloglog\" \"logistic\". Default \"cloglog\" regmult numeric. constant adjust regularization. ESM used modeling species records default value 2.5","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"list object : esm_model: list \"maxnet\" class object maxnet package bivariate model. object can used predicting ensembles small models sdm_predict function. predictors: tibble variables use modeling. performance: Performance metrics (see sdm_eval). threshold dependent metric calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018). function use default regularization multiplier equal 2.5 (see  Breiner et al., 2018) argument “classes” set default MaxEnt use different features combination depending number presences (np) follow rule: np < 10 classes = \"l\", np 10  15 classes = \"lq\", np 15 80 classes = \"lqh\", np >= 80 classes = \"lqph\" presence-absence (presence-pseudo-absence) data used data argument addition background points, function fit models presences background points validate presences absences. procedure makes maxent comparable presences-absences models (e.g., random forest, support vector machine). presences background points data used, function fit validate model presences background data. presence-absences used data argument without background, function fit model specified data (recommended).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_max.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Maximum Entropy Models based on Ensemble of Small of Model approach — esm_max","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") data(\"backg\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 5, replicates = 5) ) abies2  set.seed(10) backg2 <- backg %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 100) %>%   group_by()  backg2 <- part_random(   data = backg2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 5, replicates = 5) ) backg2  # Without threshold specification and with kfold esm_max_t1 <- esm_max(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL,   background = backg2,   clamp = TRUE,   classes = \"default\",   pred_type = \"cloglog\",   regmult = 1 )  esm_max_t1$esm_model # bivariate model esm_max_t1$predictors esm_max_t1$performance esm_max_t1$performance_part } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"function constructs Neural Networks using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"","code":"esm_net(data, response, predictors, partition, thr = NULL, size = 2, decay = 0)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1) predictors character. Vector column names quantitative predictor variables (.e. continuous variables). function can construct models continuous variables allow categorical variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\"). partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity values specified, default used 0.9 user wants include one threshold type, necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified size numeric. Number units hidden layer. Can zero skip-layer units. Default 2. decay numeric. Parameter weight decay. Default 0.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"list object : esm_model: list \"nnet\" class object nnet package bivariate model. object can used predicting ensemble small model sdm_predict function. predictors: tibble variables use modeling. performance: Performance metric (see sdm_eval). threshold dependent metric calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Neural Networks based on Ensembles of Small of Models approach — esm_net","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  # Without threshold specification and with kfold esm_net_t1 <- esm_net(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   partition = \".part\",   thr = NULL )  esm_net_t1$esm_model # bivariate model esm_net_t1$predictors esm_net_t1$performance esm_net_t1$performance_part } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"function constructs Support Vector Machine models using Ensembles Small Models (ESM) approach (Breiner et al., 2015, 2018).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"","code":"esm_svm(   data,   response,   predictors,   partition,   thr = NULL,   sigma = \"automatic\",   C = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). function can construct models continuous variables allow categorical variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\"). partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default 0.9 user wants include one threshold type, necessary concatenate threshold types, e.g., thr=c('max_sens_spec', 'max_jaccard'), thr=c('max_sens_spec', 'sensitivity', sens='0.8'), thr=c('max_sens_spec', 'sensitivity'). Function use thresholds threshold specified sigma numeric. Inverse kernel width Radial Basis kernel function \"rbfdot\". Default \"automatic\". C numeric. Cost constraints violation,  'C' constant regularization term Lagrange formulation. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"list object : esm_model: list \"ksvm\" class object ksvm package bivariate model. object can used predicting ensemble small model sdm_predict function. predictors: tibble variables use modeling. performance: Performance metric (see sdm_eval). threshold dependent metric calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"method consists creating bivariate models pair-wise combinations predictors perform ensemble based average suitability weighted Somers' D metric (D = 2 x (AUC -0.5)). ESM recommended modeling species occurrences. function allow categorical variables use types variables problematic using occurrences. detail see Breiner et al. (2015, 2018). function constructs 'C-svc' classification type uses Radial Basis kernel \"Gaussian\" function (rbfdot). See details ksvm","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"Breiner, F. T., Guisan, ., Bergamini, ., & Nobis, M. P. (2015). Overcoming limitations modelling rare species using ensembles small models. Methods Ecology Evolution, 6(10), 1210-218. https://doi.org/10.1111/2041-210X.12403 Breiner, F. T., Nobis, M. P., Bergamini, ., & Guisan, . (2018). Optimizing ensembles small models predicting distribution species occurrences. Methods Ecology Evolution, 9(4), 802-808. https://doi.org/10.1111/2041-210X.12957","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/esm_svm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Support Vector Machine models based on Ensembles of Small of Models approach — esm_svm","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") require(dplyr)  # Using k-fold partition method set.seed(10) abies2 <- abies %>%   na.omit() %>%   group_by(pr_ab) %>%   dplyr::slice_sample(n = 10) %>%   group_by()  abies2 <- part_random(   data = abies2,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  # Without threshold specification and with kfold esm_svm_t1 <- esm_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(     \"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\",     \"pH\", \"awc\", \"depth\"   ),   partition = \".part\",   thr = NULL )  esm_svm_t1$esm_model # bivariate model esm_svm_t1$predictors esm_svm_t1$performance esm_svm_t1$performance_part } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"Measure extrapolation comparing environmental data used modeling calibration area model projection. function use Shape metric proposed Velazco et al., 2023","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"","code":"extra_eval(   training_data,   pr_ab,   projection_data,   metric = \"mahalanobis\",   univar_comb = FALSE,   n_cores = 1,   aggreg_factor = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"training_data data.frame tibble environmental conditions presence absence (background points pseudo-absences) used constructing models pr_ab character. Column name presence absence (background points pseudo-absences) data (.e., 1 0) projection_data SpatRaster, data.frame tibble environmental condition used projecting model (e.g., larger, encompassing region, spatially separate region, different time period). data.frame tibble used function return tibble object. Otherwise, SpatRaster object. metric character. Metric used measure degree extrapolation. Default = mahalanobis. mahalanobis: Degree extrapolation calculated based Mahalanobis distance. euclidean: Degree extrapolation calculated based Euclidean distance. univar_comb logical. true, function add layer column distinguish univariate (.e., projection data outside range training conditions) combinatorial extrapolation (.e., projection data within range training conditions) using values 1 2, respectively. Default FALSE n_cores numeric. Number cores use parallelization. Default 1 aggreg_factor positive integer. Aggregation factor expressed number cells direction reduce raster resolution. Use value higher 1 useful measuring extrapolation using raster high number cells. resolution output raster object used 'projection_data' argument. Default 1, .e., default, changes made resolution environmental variables.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"SpatRaster tibble object extrapolation values measured Shape metric. Also possible estimate univariate combinatorial extrapolation metric (see `univar_comb` argument).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"function measure model extrapolation base Shape metric (Velazco et al., 2023). Shape model-agnostic approach calculates extrapolation degree given projection data point multivariate distance nearest training data point. distances relativized factor reflects dispersion training data environmental space. Distinct approaches (e.g., MESS-Multivariate Environmental Similarity Surfaces, EO-Environmental Overlap, MOP-Mobility-Oriented Parity, EXDET-Extrapolation Detection, AOA-Area Applicability), Shape incorporates adjustable threshold control binary discrimination acceptable unacceptable extrapolation degrees (see extra_truncate). See vignette flexsdm website details Shape metric, model truncation, tools explore model extrapolation.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"Velazco, S.J.E., Brooke, M.R., De Marco Jr., P., Regan, H.M. Franklin, J. 2023. far can extrapolate species distribution model? Exploring Shape, novel method. Ecography: e06992. https://doi.org/10.1111/ecog.06992","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measure model extrapolation based on Shape extrapolation metric — extra_eval","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra)  data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f) names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\")   spp$species %>% unique() sp <- spp %>%   dplyr::filter(species == \"sp3\", pr_ab == 1) %>%   dplyr::select(x, y, pr_ab)  # Calibration area based on some criterion such as dispersal ability ca <- calib_area(sp,   x = \"x\", y = \"y\",   method = c(\"bmcp\", width = 50000),   crs = crs(somevar) )  plot(somevar[[1]]) points(sp) plot(ca, add = T)   # Sampling pseudo-absences set.seed(10) psa <- sample_pseudoabs(   data = sp,   x = \"x\",   y = \"y\",   n = nrow(sp) * 2,   method = \"random\",   rlayer = somevar,   calibarea = ca )  # Merge presences and absences databases to get a complete calibration data sp_pa <- dplyr::bind_rows(sp, psa) sp_pa  # Get environmental condition of calibration area sp_pa_2 <- sdm_extract(   data = sp_pa,   x = \"x\",   y = \"y\",   env_layer = somevar ) sp_pa_2  # Measure degree of extrapolation based on Mahalanobis and # for a projection area based on a SpatRaster object extr <-   extra_eval(     training_data = sp_pa_2,     projection_data = somevar,     pr_ab = \"pr_ab\",     n_cores = 1,     aggreg_factor = 1,     metric = \"mahalanobis\"   ) plot(extr, main = \"Extrapolation pattern\")    # Let's fit, predict and truncate a model with extra_truncate sp_pa_2 <- part_random(   data = sp_pa_2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  a_model <- fit_glm(   data = sp_pa_2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sorensen\") )  predsuit <- sdm_predict(   models = a_model,   pred = somevar,   thr = \"max_sorensen\" ) predsuit # list with a raster with two layer plot(predsuit[[1]])  # Truncate a model based on a given value of extrapolation # using 'extra_truncate' function par(mfrow = c(1, 2)) plot(extr, main = \"Extrapolation\") plot(predsuit[[1]][[1]], main = \"Suitability\") par(mfrow = c(1, 1))  predsuit_2 <- extra_truncate(   suit = predsuit[[1]],   extra = extr,   threshold = c(50, 100, 200) ) predsuit_2 # a list of continuous and binary models with # different truncated at different extrapolation thresholds  plot(predsuit_2$`50`) plot(predsuit_2$`100`) plot(predsuit_2$`200`)   ## %######################################################%## ####        Measure degree of extrapolation for         #### ####        projection area based on data.frame         #### ## %######################################################%##  extr_df <-   extra_eval(     training_data = sp_pa_2,     projection_data = as.data.frame(somevar, xy = TRUE),     pr_ab = \"pr_ab\",     n_cores = 1,     aggreg_factor = 1,     metric = \"mahalanobis\"   ) extr_df # see 'p_extra()' to explore extrapolation or suitability pattern in the # environmental and/or geographical space  ## %######################################################%## ####             Explore Shape metric with              #### ####     univariate and combinatorial extrapolation     #### ## %######################################################%## extr <-   extra_eval(     training_data = sp_pa_2,     projection_data = somevar,     pr_ab = \"pr_ab\",     n_cores = 1,     aggreg_factor = 1,     metric = \"mahalanobis\",     univar_comb = TRUE   )  extr plot(extr) # In the second layer, values equal to 1 and 2 # depict univariate and combinatorial extrapolation, respectively } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_exclude.html","id":null,"dir":"Reference","previous_headings":"","what":"Constraint of suitability based on extrapolation — extra_exclude","title":"Constraint of suitability based on extrapolation — extra_exclude","text":"Exclusion suitability values less given extrapolation value (EXPERIMENTAL)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_exclude.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constraint of suitability based on extrapolation — extra_exclude","text":"","code":"extra_exclude(suit, extra, threshold = 50)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_exclude.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constraint of suitability based on extrapolation — extra_exclude","text":"suit SpatRaster suitability values extra SpatRaster extrapolation values measured percentage (output extra_eval function) threshold numeric. Vector one values used correct extrapolation. Default 50% (FUNCTION SET PROJECTED SUITABILITY VALUES LESS THRESHOLD ZERO? UNCLEAR. PLEASE EXPLICIT)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_exclude.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constraint of suitability based on extrapolation — extra_exclude","text":"SpatRaster object corrected suitability values","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_exclude.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constraint of suitability based on extrapolation — extra_exclude","text":"","code":"if (FALSE) { # see examples in extra_eval function }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_truncate.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate suitability predictions based on an extrapolation value — extra_truncate","title":"Truncate suitability predictions based on an extrapolation value — extra_truncate","text":"Exclusion suitability predictions environmental conditions assumed extrapolative.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_truncate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate suitability predictions based on an extrapolation value — extra_truncate","text":"","code":"extra_truncate(suit, extra, threshold = 50, trunc_value = 0)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_truncate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate suitability predictions based on an extrapolation value — extra_truncate","text":"suit SpatRaster suitability values extra SpatRaster extrapolation values preferable measured extra_eval function threshold numeric. Vector one extrapolation values used truncate suitability Default 50% trunc_value numeric. Numeric value used cells assumed extrapolative","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_truncate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate suitability predictions based on an extrapolation value — extra_truncate","text":"SpatRaster object truncated suitability values","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_truncate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncate suitability predictions based on an extrapolation value — extra_truncate","text":"Exclusion suitability predictions environmental conditions assumed extrapolative. function possible use metric measuring degree extrapolation (e.g., MESS-Multivariate Environmental Similarity Surfaces, EO-Environmental Overlap, MOP-Mobility-Oriented Parity, EXDET-Extrapolation Detection, AOA-Area Applicability). However, recommend use Shape approach (see extra_eval, Velazco et al., 2023). function truncates suitability predictions assigning given value, generally 0 NA.  Usage trunc_value = NA. Default 0. cells assumed extrapolative, .e., higher given threshold given extrapolation metric. See vignette flexsdm website details Shape metric, model truncation, tools explore model extrapolation.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/extra_truncate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncate suitability predictions based on an extrapolation value — extra_truncate","text":"","code":"if (FALSE) { # \\dontrun{ # see examples in extra_eval function } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Domain models — fit_dom","title":"Fit and validate Domain models — fit_dom","text":"Fit validate Domain models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Domain models — fit_dom","text":"","code":"fit_dom(   data,   response,   predictors,   predictors_f = NULL,   partition,   thr = NULL,   fit_formula = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Domain models — fit_dom","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables; factors). Usage predictors_f = c(\"landform\") partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default used 0.9. one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use threshold types none specified. fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Domain models — fit_dom","text":"list object : model: tibble presences. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metric (see sdm_eval). Threshold dependent metrics calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition. database used fit_ensemble","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Domain models — fit_dom","text":"function fits validates Domain models. Domain model simple model uses Gower distance calculate environmental similarity presence data test data (Carpenter et al., 1993). Gower range values area based presences data. Gower distance transformed max(0, 1 - Gower). involves subtracting distance 1 ensuring result negative (clamping zero). Gower distance calculated map_env_dist function function fit validate Domain models. Domain model simple model uses Gower distance calculate similarity presences training presence-absences test data.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit and validate Domain models — fit_dom","text":"Carpenter, G., Gillison, .N., Winter, J., 1993. DOMAIN: flexible modelling procedure mapping potential distributions plants animals. Biodiversity & Conservation 2, 667–680","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_dom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Domain models — fit_dom","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra)  data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Extract data some_sp <- spp %>%   filter(species == \"sp2\")  some_sp <-   sdm_extract(     data = some_sp,     x = \"x\",     y = \"y\",     env_layer = somevar   )  # Partition some_sp <- part_random(   data = some_sp,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) )   ##%######################################################%## #                                                          # ####                Fit a Domain model                  #### #                                                          # ##%######################################################%## # Fit some models mdom <- fit_dom(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   predictors_f = NULL,   fit_formula = NULL,   partition = \".part\",   thr = c(\"max_sens_spec\") )  mdom  # Predict model ind_p <- sdm_predict(   models = mdom,   pred = somevar,   thr = \"max_sens_spec\",   con_thr = TRUE,   predict_area = NULL ) plot(ind_p$dom)  ##%######################################################%## #                                                          # ####             Explore Domain suitabiltiy             #### ####             in the environmental space             #### #                                                          # ##%######################################################%##  p_extra(   training_data = some_sp %>% dplyr::filter(pr_ab == 1), #select only presences   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = ind_p$dom$dom,   projection_data = somevar,   geo_space = FALSE,   prop_points = 0.3,   alpha_p = 0.8,   color_p = \"black\",   color_gradient = c(\"#000033\", \"#1400FF\", \"#C729D6\", \"#FF9C63\", \"#FFFF60\") )  p_extra(   training_data = some_sp %>% dplyr::filter(pr_ab == 1), #select only presences   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\"), # Just the first two predictors   extra_suit_data = ind_p$dom$dom > 0.96, # a binary map   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.4,   alpha_p = 0.8,   color_p = \"black\",   color_gradient = c(\"#1400FF\", \"#C729D6\") )  } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_ensemble.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensemble model fitting and validation — fit_ensemble","title":"Ensemble model fitting and validation — fit_ensemble","text":"Ensemble model fitting validation","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_ensemble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ensemble model fitting and validation — fit_ensemble","text":"","code":"fit_ensemble(   models,   ens_method = c(\"mean\", \"meanw\", \"meansup\", \"meanthr\", \"median\"),   thr = NULL,   thr_model = NULL,   metric = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_ensemble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensemble model fitting and validation — fit_ensemble","text":"models list. list models fitted fit_ tune_ function family. Models used ensemble must presences-absences records, partition methods, threshold types. ens_method character. Method used create ensemble different models. vector must provided argument. meansup, meanw pcasup method, necessary provide evaluation metric threshold 'metric' 'thr_model' arguments respectively. default following ensemble methods performed: mean: Simple average different models. meanw: Weighted average models based performance. evaluation metric threshold type must provided. meansup: Average best models (evaluation metric average). evaluation metric must provided. meanthr: Averaging performed cells suitability values selected threshold. median: Median different models. Usage ensemble = \"meanthr\". several ensemble methods implemented necessary concatenate , e.g., ensemble = c(\"meanw\", \"meanthr\", \"median\") thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold criterion. vector must provided argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard highest. max_sorensen: threshold Sorensen highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity values specified, default 0.9. case using one threshold type necessary concatenate threshold types, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. thr_model character. threshold needed conduct meanw, meandsup, meanthr ensemble methods. mandatory use one threshold, must threshold used fit models used \"models\" argument. Usage thr_model = 'equal_sens_spec' metric character. Performance metric used selecting best combination hyper-parameter values. One following metrics can used: SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, IMAE, BOYCE. Default TSS. Usage metric = BOYCE","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_ensemble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ensemble model fitting and validation — fit_ensemble","text":"list object : models: list models used performing ensemble. thr_metric: Threshold metric specified function. predictors: tibble quantitative (column names c) qualitative (column names f) variables used models. performance: tibble performance metrics (see sdm_eval). performance_part: Performance metric replica partition (see sdm_eval). metrics threshold-dependent calculated based threshold specified argument.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_ensemble.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ensemble model fitting and validation — fit_ensemble","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra)  # Environmental variables somevar <-   system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Species occurrences data(\"spp\") set.seed(1) some_sp <- spp %>%   dplyr::filter(species == \"sp2\") %>%   sdm_extract(     data = .,     x = \"x\",     y = \"y\",     env_layer = somevar,     variables = names(somevar),     filter_na = TRUE   ) %>%   part_random(     data = .,     pr_ab = \"pr_ab\",     method = c(method = \"kfold\", folds = 3)   )   # gam mglm <- fit_glm(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\",   poly = 2 ) mraf <- fit_raf(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\", ) mgbm <- fit_gbm(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\" )  # Fit and validate ensemble model mensemble <- fit_ensemble(   models = list(mglm, mraf, mgbm),   ens_method = \"meansup\",   thr = NULL,   thr_model = \"max_sens_spec\",   metric = \"TSS\" )  mensemble  } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Additive Models — fit_gam","title":"Fit and validate Generalized Additive Models — fit_gam","text":"Fit validate Generalized Additive Models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Additive Models — fit_gam","text":"","code":"fit_gam(   data,   response,   predictors,   predictors_f = NULL,   select_pred = FALSE,   partition,   thr = NULL,   fit_formula = NULL,   k = -1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Additive Models — fit_gam","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables; factors). Usage predictors_f = c(\"landform\") select_pred logical. Perform predictor selection. Default FALSE. partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default used 0.9. one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use threshold types none specified. fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments k integer. dimension basis used represent smooth term. Default -1 (.e., k=10). See help ?mgcv::s.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Additive Models — fit_gam","text":"list object : model: \"gam\" class object mgcv package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metric (see sdm_eval). Threshold dependent metrics calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition. database used fit_ensemble","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Generalized Additive Models — fit_gam","text":"function fits GAM using mgvc package, Binomial distribution family thin plate regression spline smoothing basis (see ?mgvc::s).","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Additive Models — fit_gam","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\")  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 10) ) abies2  gam_t1 <- fit_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   select_pred = FALSE,   partition = \".part\",   thr = \"max_sens_spec\" ) gam_t1$model gam_t1$predictors gam_t1$performance gam_t1$performance_part  # Specifying the formula explicitly require(mgcv) gam_t2 <- fit_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   select_pred = FALSE,   partition = \".part\",   thr = \"max_sens_spec\",   fit_formula = stats::formula(pr_ab ~ s(aet) +     s(ppt_jja) +     s(pH) + landform) )  gam_t2$model gam_t2$predictors gam_t2$performance %>% dplyr::select(ends_with(\"_mean\"))  # Using repeated k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 5, replicates = 5) ) abies2  gam_t3 <- fit_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"ppt_jja\", \"pH\", \"awc\"),   predictors_f = c(\"landform\"),   select_pred = FALSE,   partition = \".part\",   thr = \"max_sens_spec\" ) gam_t3 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gau.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Gaussian Process models — fit_gau","title":"Fit and validate Gaussian Process models — fit_gau","text":"Fit validate Gaussian Process models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gau.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Gaussian Process models — fit_gau","text":"","code":"fit_gau(   data,   response,   predictors,   predictors_f = NULL,   background = NULL,   partition,   thr = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gau.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Gaussian Process models — fit_gau","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") background data.frame. Database response column 0 predictors variables. column names must consistent data partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1), useful threshold-dependent performance metrics. possible use one threshold type. vector must provided argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default used 0.9. one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use threshold criteria none specified.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gau.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Gaussian Process models — fit_gau","text":"list object : model: \"graf\" class object. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metrics calculated based threshold criteria specified argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gau.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Gaussian Process models — fit_gau","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\")  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 3) ) abies2  bg <- abies2 bg$pr_ab <- 0   gaup_t1 <- fit_gau(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   background = bg,   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") )  gaup_t1$model gaup_t1$predictors gaup_t1$performance gaup_t1$performance_part gaup_t1$data_ens  # Using bootstrap partition method only with presence-absence abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 5, proportion = 0.7) ) abies2  gaup_t2 <- fit_gau(   data = abies2,   response = \"pr_ab\",   predictors = c(\"ppt_jja\", \"pH\", \"awc\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(type = c(\"lpt\", \"max_sens_spec\", \"sensitivity\"), sens = \"0.8\") ) gaup_t2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gbm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Boosted Regression models — fit_gbm","title":"Fit and validate Generalized Boosted Regression models — fit_gbm","text":"Fit validate Generalized Boosted Regression models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gbm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Boosted Regression models — fit_gbm","text":"","code":"fit_gbm(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   thr = NULL,   n_trees = 100,   n_minobsinnode = as.integer(nrow(data) * 0.5/4),   shrinkage = 0.1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gbm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Boosted Regression models — fit_gbm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments. Default NULL. partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1) needed threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default used 0.9 one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. n_trees Integer specifying total number trees fit. equivalent number iterations number basis functions additive expansion. Default 100. n_minobsinnode Integer specifying minimum number observations terminal nodes trees. Note actual number observations, total weight. default value used nrow(data)*0.5/4 shrinkage Numeric. parameter applied tree expansion. Also known learning rate step-size reduction; 0.001 0.1 usually works, smaller learning rate typically requires trees. Default 0.1.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gbm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Boosted Regression models — fit_gbm","text":"list object : model: \"gbm\" class object gbm package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metric (see sdm_eval). Threshold dependent metrics calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_gbm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Boosted Regression models — fit_gbm","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\")  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 10) ) abies2  gbm_t1 <- fit_gbm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") ) gbm_t1$model gbm_t1$predictors gbm_t1$performance gbm_t1$performance_part gbm_t1$data_ens  # Using bootstrap partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 10, proportion = 0.7) ) abies2  gbm_t2 <- fit_gbm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"ppt_jja\", \"pH\", \"awc\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = \"max_sens_spec\" ) gbm_t2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Linear Models — fit_glm","title":"Fit and validate Generalized Linear Models — fit_glm","text":"Fit validate Generalized Linear Models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Linear Models — fit_glm","text":"","code":"fit_glm(   data,   response,   predictors,   predictors_f = NULL,   select_pred = FALSE,   partition,   thr = NULL,   fit_formula = NULL,   poly = 2,   inter_order = 0 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Linear Models — fit_glm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") select_pred logical. Perform predictor selection. TRUE predictors selected based backward step wise approach. Default FALSE. partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1), needed threshold-dependent performance metrics. one threshold type can used. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. specified sensitivity values, function use default 0.9 one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments poly integer >= 2. used values >= 2 model use polynomials continuous variables (.e. used predictors argument). Default 0. inter_order integer >= 0. interaction order explanatory variables. Default 0.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Linear Models — fit_glm","text":"list object : model: \"glm\" class object stats package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metric calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Linear Models — fit_glm","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") abies  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) ) abies2  glm_t1 <- fit_glm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   select_pred = FALSE,   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   poly = 0,   inter_order = 0 ) glm_t1$model glm_t1$predictors glm_t1$performance glm_t1$performance_part glm_t1$data_ens  # Using second order polynomial terms and first-order interaction terms glm_t2 <- fit_glm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   select_pred = FALSE,   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   poly = 2,   inter_order = 1 )  # Using repeated k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) ) abies2  # Using third order polynomial terms and second-order interaction terms glm_t3 <- fit_glm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"ppt_jja\", \"pH\", \"awc\"),   predictors_f = c(\"landform\"),   select_pred = FALSE,   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   poly = 3,   inter_order = 2 ) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Maximum Entropy models — fit_max","title":"Fit and validate Maximum Entropy models — fit_max","text":"Fit validate Maximum Entropy models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_max.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Maximum Entropy models — fit_max","text":"","code":"fit_max(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   background = NULL,   thr = NULL,   clamp = TRUE,   classes = \"default\",   pred_type = \"cloglog\",   regmult = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Maximum Entropy models — fit_max","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables. See maxnet.formula function maxnet package. Note variables used must consistent used response, predictors, predictors_f arguments. Default NULL. partition character. Column name training validation partition groups. background data.frame. Database including rows 0 values response column predictors variables. column names must consistent data. Default NULL thr character. Threshold used get binary suitability values (.e. 0,1), needed threshold-dependent performance metrics. one threshold type can used. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value.  sensitivity values specified default used 0.9. one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. clamp logical. TRUE, predictors features restricted range seen model training. classes character. single feature combinations . Features symbolized letters: l (linear), q (quadratic), h (hinge), p (product), t (threshold). Usage classes = \"lpq\". Default \"default\" (see details). pred_type character. Type response required available \"link\", \"exponential\", \"cloglog\" \"logistic\". Default \"cloglog\" regmult numeric. constant adjust regularization. Default 1.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_max.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Maximum Entropy models — fit_max","text":"list object : model: \"maxnet\" class object maxnet package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metrics calculated based threshold specified thr argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_max.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Maximum Entropy models — fit_max","text":"argument “classes” set default MaxEnt use different features combination depending number presences (np) follow rule:  np < 10 classes = \"l\",  np 10  15 classes = \"lq\",  np 15 80 classes = \"lqh\",  np >= 80 classes = \"lqph\" presence-absence (presence-pseudo-absence) data used data argument addition background points, function fit models presences background points validate presences absences. procedure makes maxent comparable presences-absences models (e.g., random forest, support vector machine). presences background points data used, function fit validate model presences background data. presence-absences used data argument without background, function fit model specified data (recommended).","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_max.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Maximum Entropy models — fit_max","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") data(\"backg\") abies # environmental conditions of presence-absence data backg # environmental conditions of background points  # Using k-fold partition method # Note that the partition method, number of folds or replications must # be the same for presence-absence and background points datasets abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) ) abies2  backg2 <- part_random(   data = backg,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) ) backg2  max_t1 <- fit_max(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   background = backg2,   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   clamp = TRUE,   classes = \"default\",   pred_type = \"cloglog\",   regmult = 1 ) length(max_t1)  max_t1$model max_t1$predictors max_t1$performance max_t1$performance_part max_t1$data_ens } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Neural Networks models — fit_net","title":"Fit and validate Neural Networks models — fit_net","text":"Fit validate Neural Networks models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Neural Networks models — fit_net","text":"","code":"fit_net(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   thr = NULL,   size = 2,   decay = 0.1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Neural Networks models — fit_net","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments. Defaul NULL. partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1)., needed threshold-dependent performance metrics. one threshold type can specified. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value.  sensitivity value specified, default 0.9 one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. size numeric. Number units hidden layer. Can zero skip-layer units. Default 2. decay numeric. Parameter weight decay. Default 0.1.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Neural Networks models — fit_net","text":"list object : model: \"nnet.formula\" \"nnet\" class object nnet package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metric calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Neural Networks models — fit_net","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\")  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 10) ) abies2  nnet_t1 <- fit_net(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   fit_formula = NULL )  nnet_t1$model nnet_t1$predictors nnet_t1$performance nnet_t1$performance_part nnet_t1$data_ens  # Using bootstrap partition method and only with presence-absence # and get performance for several method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 10, proportion = 0.7) ) abies2  nnet_t2 <- fit_net(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   fit_formula = NULL ) nnet_t2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_raf.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Random Forests models — fit_raf","title":"Fit and validate Random Forests models — fit_raf","text":"Fit validate Random Forests models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_raf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Random Forests models — fit_raf","text":"","code":"fit_raf(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   thr = NULL,   mtry = sqrt(length(c(predictors, predictors_f))),   ntree = 500 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_raf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Random Forests models — fit_raf","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments. Default NULL partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1), needed threshold-dependent performance metrics. one threshold type can used. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard highest. max_sorensen: threshold Sorensen highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. specified sensitivity values, function use default 0.9 one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. mtry numeric. Number variables randomly sampled candidates split. Default sqrt(length(c(predictors, predictors_f))) ntree numeric. Number trees grow. Default 500","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_raf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Random Forests models — fit_raf","text":"list object : model: \"randomForest\" class object randomForest package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metrics (see sdm_eval). Threshold dependent metrics calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_raf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Random Forests models — fit_raf","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\")  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 10) ) abies2  rf_t1 <- fit_raf(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   fit_formula = NULL )  rf_t1$model rf_t1$predictors rf_t1$performance rf_t1$performance_part rf_t1$data_ens  # Using bootstrap partition method and only with presence-absence # and get performance for several method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 10, proportion = 0.7) ) abies2  rf_t2 <- fit_raf(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   fit_formula = NULL,   mtry = 2,   ntree = 500 ) rf_t2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_svm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Support Vector Machine models — fit_svm","title":"Fit and validate Support Vector Machine models — fit_svm","text":"Fit validate Support Vector Machine models","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_svm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Support Vector Machine models — fit_svm","text":"","code":"fit_svm(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   thr = NULL,   sigma = \"automatic\",   C = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_svm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Support Vector Machine models — fit_svm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments partition character. Column name training validation partition groups. thr character. Threshold used get binary suitability values (.e. 0,1) needed threshold-dependent performance metrics. one threshold type can used. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers sensitivity value. sensitivity value specified, default used 0.9 one threshold type used must concatenated, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. sigma numeric. Inverse kernel width Radial Basis kernel function \"rbfdot\". Default \"automatic\". C numeric. Cost constraints violation, 'C'-constant regularization term Lagrange formulation. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_svm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Support Vector Machine models — fit_svm","text":"list object : model: \"ksvm\" class object kernlab package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Performance metric (see sdm_eval). Threshold dependent metrics calculated based threshold specified argument. performance_part: Performance metric replica partition (see sdm_eval). data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_svm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Support Vector Machine models — fit_svm","text":"function constructs 'C-svc' classification type uses Radial Basis kernel \"Gaussian\" function (rbfdot). See details details ksvm.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/fit_svm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Support Vector Machine models — fit_svm","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\")  # Using k-fold partition method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) ) abies2  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   fit_formula = NULL )  names(svm_t1) svm_t1$model svm_t1$predictors svm_t1$performance svm_t1$performance_part svm_t1$data_ens  # Using bootstrap partition method and only with presence-absence # and get performance for several method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 10, proportion = 0.7) ) abies2  svm_t2 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   fit_formula = NULL ) svm_t2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/get_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","title":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","text":"Transform spatial partition layer spatial properties environmental variables","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/get_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","text":"","code":"get_block(env_layer, best_grid)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/get_block.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","text":"env_layer SpatRaster object environmental variables used block_partition band_partition function. Function always select first layer best_grid SpatRaster object returned block_partition band_partition","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/get_block.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","text":"SpatRaster layer resolution extent environmental variables","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/get_block.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","text":"Transform layer originating function block_partition band_partition spatial properties environmental variables","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/get_block.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform a spatial partition layer to the same spatial properties as environmental variables — get_block","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra) data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Example for a single species single_spp <- spp %>% dplyr::filter(species == \"sp3\")  part <- part_sblock(   env_layer = somevar,   data = single_spp,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_res_mult = 100,   max_res_mult = 500,   num_grids = 10,   min_occ = 5,   n_part = 2 )  grid_env <- get_block(env_layer = somevar, best_grid = part$grid) grid_env part$grid  plot(part$grid) plot(grid_env) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/hespero.html","id":null,"dir":"Reference","previous_headings":"","what":"A data set containing localities of Hesperocyparis stephensonii species in California, USA — hespero","title":"A data set containing localities of Hesperocyparis stephensonii species in California, USA — hespero","text":"data set containing localities Hesperocyparis stephensonii species California, USA","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/hespero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data set containing localities of Hesperocyparis stephensonii species in California, USA — hespero","text":"","code":"hespero"},{"path":"https://sjevelazco.github.io/flexsdm/reference/hespero.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data set containing localities of Hesperocyparis stephensonii species in California, USA — hespero","text":"tibble object 14 rows 4 variables: ID presences records ID x y columns coordinates Albers Equal Area Conic coordinate system pr_ab presence denoted 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/hespero.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A data set containing localities of Hesperocyparis stephensonii species in California, USA — hespero","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) data(\"hespero\") hespero } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/homogenize_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Homogenize cells with NAs across all layers — homogenize_na","title":"Homogenize cells with NAs across all layers — homogenize_na","text":"Homogenize cells NAs across layers","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/homogenize_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Homogenize cells with NAs across all layers — homogenize_na","text":"","code":"homogenize_na(x)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/homogenize_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Homogenize cells with NAs across all layers — homogenize_na","text":"x SpatRaster.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/homogenize_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Homogenize cells with NAs across all layers — homogenize_na","text":"SpatRaster","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/homogenize_na.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Homogenize cells with NAs across all layers — homogenize_na","text":"Homogenize cells NAs across layers SpatRaster resulting SpatRaster layers cells NAa","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/homogenize_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Homogenize cells with NAs across all layers — homogenize_na","text":"","code":"if (FALSE) { # \\dontrun{ #' require(terra)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  somevar2 <- homogenize_na(somevar) par(mfrow = c(2, 1)) plot(somevar$CFP_4) plot(somevar2$CFP_4) par(mfrow = c(1, 1))  # In somevar2 all layers have the same cells with NAs } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":null,"dir":"Reference","previous_headings":"","what":"Raster interpolation between two time periods — interp","title":"Raster interpolation between two time periods — interp","text":"function interpolates values year two specified years simple interpolation using two raster objects containing e.g. habitat suitability values predicted using species distribution model.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raster interpolation between two time periods — interp","text":"","code":"interp(r1, r2, y1, y2, rastername = NULL, dir_save = NULL)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raster interpolation between two time periods — interp","text":"r1 SpatRaster. Raster object initial year r2 SpatRaster. Raster object final year y1 numeric. Initial year y2 numeric. Final year rastername character. Word used prefix raster file name. Default NULL dir_save character. Directory path name folder raster files saved. NULL, function return SpatRaster object, else, save raster given directory. Default NULL","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raster interpolation between two time periods — interp","text":"dir_save NULL, function returns SpatRaster suitability interpolation year. dir_save used, function outputs saved directory specified dir_save.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Raster interpolation between two time periods — interp","text":"function interpolates suitability values assuming annual changes suitability linear. function useful linking SDM output based averaged climate data climate change scenarios models require suitability values disaggregated time periods, population dynamics (Keith et al., 2008; Conlisk et al., 2013; Syphard et al., 2013).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Raster interpolation between two time periods — interp","text":"Keith, D.., Akçakaya, H.R., Thuiller, W., Midgley, G.F., Pearson, R.G., Phillips, S.J.,  Regan, H.M., Araujo, M.B. & Rebelo, T.G. (2008) Predicting extinction risks climate  change: coupling stochastic population models dynamic bioclimatic habitat models.  Biology Letters, 4, 560-563. Conlisk, E., Syphard, .D., Franklin, J., Flint, L., Flint, . & Regan, H.M. (2013)  Management implications uncertainty assessing impacts multiple landscape-scale  threats species persistence using linked modeling approach. Global Change Biology   3, 858-869. Syphard, .D., Regan, H.M., Franklin, J. & Swab, R. (2013) functional type vulnerability multiple threats depend spatial context Mediterranean-climate regions? Diversity Distributions, 19, 1263-1274.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/interp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raster interpolation between two time periods — interp","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr)  f <- system.file(\"external/suit_time_step.tif\", package = \"flexsdm\") abma <- terra::rast(f) plot(abma)  int <- interp(   r1 = abma[[1]],   r2 = abma[[2]],   y1 = 2010,   y2 = 2020,   rastername = \"Abies\",   dir_save = NULL )  int } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/map_env_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate environmental distance between presences and projection data — map_env_dist","title":"Calculate environmental distance between presences and projection data — map_env_dist","text":"Calculate environmental distance presences projection data","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/map_env_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate environmental distance between presences and projection data — map_env_dist","text":"","code":"map_env_dist(training_data, projection_data, metric = \"domain\")"},{"path":"https://sjevelazco.github.io/flexsdm/reference/map_env_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate environmental distance between presences and projection data — map_env_dist","text":"training_data data.frame tibble environmental conditions presence used constructing models projection_data SpatRaster, data.frame tibble environmental condition used projecting model (e.g., larger, encompassing region, spatially separate region, different time period). data.frame tibble used function return tibble object. Otherwise, SpatRaster object. metric character. Metric used measuring distance. Default \"domain\".","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/map_env_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate environmental distance between presences and projection data — map_env_dist","text":"SpatRaster tibble object nearest environmental distance presences projection data. far Domain algorithm (based Gower distance; Carpenter et al., 1993) implemented.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/map_env_dist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate environmental distance between presences and projection data — map_env_dist","text":"Carpenter, G., Gillison, .N., Winter, J., 1993. DOMAIN: flexible modelling procedure mapping potential distributions plants animals. Biodiversity & Conservation 2, 667–680","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/map_env_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate environmental distance between presences and projection data — map_env_dist","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra) data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Let's use only two variables to turn more evident the pater in the environmental space somevar <- somevar[[1:2]] names(somevar) <- c(\"aet\", \"cwd\")   spp$species %>% unique() sp <- spp %>%   dplyr::filter(species == \"sp3\", pr_ab == 1) %>%   dplyr::select(x, y, pr_ab)  # Get environmental condition of presences sp_pa_2 <- sdm_extract(   data = sp,   x = \"x\",   y = \"y\",   env_layer = somevar ) sp_pa_2  # Measure environmental distance between presences and projection data envdist <-   map_env_dist(     training_data = sp_pa_2,     projection_data = somevar,     metric = \"domain\"   ) plot(envdist, main = \"Domain\") p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = envdist,   projection_data = somevar,   geo_space = FALSE,   prop_points = 0.8,   alpha_p = 0.9,   color_p = \"red\",   color_gradient = c(\"#000033\", \"#1400FF\", \"#C729D6\", \"#FF9C63\", \"#FFFF60\") )  } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"methods reduce overprediction species distribution models based posteriori methods (see Mendes et al 2020), .e., combination patterns species occurrences predicted suitability","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"","code":"msdm_posteriori(   records,   x,   y,   pr_ab,   cont_suit,   method = c(\"obr\", \"pres\", \"lq\", \"mcp\", \"bmcp\"),   thr = \"equal_sens_spec\",   buffer = NULL,   crs = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"records tibble data.frame. database spatial coordinates species presences absences (pseudo-absence) used create species distribution models. x character. Column name spatial x coordinates. y character. Column name spatial y coordinates. pr_ab character. Column name presence absence data (.e. 1 0) cont_suit SpatRaster. Raster continuous suitability predictions \"species_specific\" type calculates minimum pairwise-distances occurrences selects maximum distance, .e., value buffer maximum distance minimum distance. procedure depends spatial pattern species' occurrences; thus, species, value buffer width calculated (usage buffer=\"species_specific\"). method character. character string indicating constraint method used. thr character numeric. Threshold used get binary suitability values (.e. 0,1), needed threshold-dependent performance metrics. one threshold type can specified. necessary provide vector argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers   sensitivity value. specified sensitivity values, function use default 0.9 Also, possible specifying threshold value using numeric values (thr = 0.623).   Default \"equal_sens_spec\". buffer numeric. Buffer width use 'bmcp' approach. buffer width interpreted m Coordinate reference system used \"crs\" argument longitude/latitude, map units cases. Usage buffer=50000. Default NULL crs character. Coordinate reference system used calculating buffer \"bmcp\" method.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"function return SpatRaster continuous binary prediction.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"function help reduce overprediction species distribution models based combination patterns species occurrences predicted suitability. recommended use approaches current distribution models projected different time periods (past future). Five methods implemented: Abbreviation list SDM: species distribution model l: suitability patches intercept species occurrences k: suitability patches intercept species occurrences T: threshold distances used select suitability patches methods reduce overprediction species distribution models already fitted based occurrences suitability patterns species (see 'thr' arguments) Method 'obr' (Occurrences Based Restriction). method assumes suitable patches intercepting species occurrences (l) likely part species distributions suitable patches intercept occurrence (k). Distance k patches closest l patch calculated, k patches removed exceed species-specific distance threshold SDMs models. threshold (T) calculated maximum distance vector minimum pairwise distances occurrences. Whenever suitable pixel within k patch distance T closest l patch, suitability pixel reduced zero. assumed simple threshold surrogate species-specific dispersal ability. T low, either species sampled throughout distribution, species geographically restricted, justifying narrow inclusion k patches (Mendes et al., 2020). Method 'pres' (occurrences based restriction). restrictive variant 'obr' method. retains pixels suitability patches intercepting occurrences (k) (Mendes et al., 2020). Method 'lq' (Lower Quantile). method similar 'obr' method, except procedure define distance threshold withdrawn k patches, lower quartile distance k patches closest l patch. Whenever suitable pixel within k patch, .e., within lower quartile, suitability pixel reduced zero. means 75% k patches withdrawn model (Mendes et al., 2020). Method 'mcp' (Minimum Convex Polygon). Compiled adapted Kremen et al. (2008), method excludes SDM predictions suitable pixels intercept minimum convex polygon, interior angles smaller 180, enclosing occurrences species. Method 'bmcp' (Buffered Minimum Convex Polygon). Compiled adapted Kremen et al. (2008), similar 'mcp' method except inclusion buffer zone surrounding minimum convex polygons. method buffer width value must provided \"buffer\" argument CRS \"crs\" argument. methodological performance information methods see Mendes et al. (2020). using one constraining methods, cite Mendes et al (2020).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"Mendes, P.; Velazco S.J.E.; Andrade, .F..; De Marco, P. (2020) Dealing overprediction species distribution models: adding distance constraints can improve model accuracy, Ecological Modelling, press. https://doi.org/10.1016/j.ecolmodel.2020.109180 Kremen, C., Cameron, ., Moilanen, ., Phillips, S. J., Thomas, C. D., Beentje, H., . Zjhra, M. L. (2008). Aligning Conservation Priorities Across Taxa Madagascar High-Resolution Planning Tools. Science, 320(5873), 222-226. doi:10.1126/science.1155193","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_posteriori.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods to correct overprediction of species distribution models based on occurrences and suitability patterns. — msdm_posteriori","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra)  data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)   # Preparing data for modeling a species set.seed(10) occ <- spp %>%   dplyr::filter(species == \"sp2\") %>% # filter a species   sdm_extract(     data = ., x = \"x\", y = \"y\",     env_layer = somevar, filter_na = TRUE   ) %>% # extrac variables values   part_random(.,     pr_ab = \"pr_ab\",     method = c(method = \"kfold\", folds = 10)   ) # add columns with partition  # Fit a model m_glm <- fit_glm(   data = occ,   response = \"pr_ab\",   predictors = names(somevar),   partition = \".part\",   thr = \"equal_sens_spec\", )   # Lets predict this model m_pred <- sdm_predict(models = m_glm, pred = somevar, thr = NULL, con_thr = FALSE) plot(m_pred[[1]]) m_pred[[1]] %>% plot()  # Lets extract the raster from this list m_pred <- m_pred[[1]]  ### bmcp method m_bmcp <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"bmcp\",   cont_suit = m_pred,   thr = \"equal_sens_spec\",   buffer = 30000,   crs = crs(m_pred) )  plot(m_bmcp)   ### mcp method m_mcp <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"mcp\",   cont_suit = m_pred,   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_mcp)   ### pres method m_pres <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"pres\",   cont_suit = m_pred,   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_pres)   ### lq method m_lq <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"lq\",   cont_suit = m_pred,   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_lq)   ### obr method m_obr <- msdm_posteriori(   records = occ,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   method = \"obr\",   cont_suit = m_pred,   thr = \"equal_sens_spec\",   buffer = NULL )  plot(m_obr) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":null,"dir":"Reference","previous_headings":"","what":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"function creates geographical predictor variables , together environmental variables, can used construct constrained species distribution models.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"","code":"msdm_priori(data, x, y, method = c(\"xy\", \"min\", \"cml\", \"ker\"), env_layer)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"data tibble data.frame. database geographical coordinates species presences. x character. Column name spatial x coordinates. y character. Column name spatial y coordinates. method character. character string indicating MSDM method used. following methods available: 'xy', 'min', 'cml', 'ker'. Usage method = 'cml' env_layer raster layer used construct species distribution models. object used create constraining variables resolution, extent, pattern empty cells environmental variables. advisable use raster environmental layer used create species distribution models avoid mismatch (e.g. resolution, extent, cells NA) environmental constraining variables.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"function returns SpatRaster object. raster/s used together environmental variables construct species distribution models. 'xy' approach creates single pair raster layers can used species share study region. Otherwise, 'cml', 'min', 'ker' create species-specific raster layer.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"function creates geographical predictor variables , together environmental variables, can used construct constrained species distribution models. recommended use approaches create models projected current conditions different time periods (past future). Four methods implemented: xy (Latlong method). method assumes spatial structure can partially explain species distribution (Bahn & McGill, 2007). Therefore, two raster layers created, containing latitude longitude pixels, respectively. raster layers included covariates environmental layers construct species distribution models. method interact species occurrence generic given study region; reason, possible use method species set share study region. min (Nearest neighbor distance method). Compiled adapted Allouche et al. (2008), method calculates cell Euclidean geographic distance nearest presence point. cml (Cumulative distance method). Compiled adapted Allouche et al. (2008), method assumes pixels closer presences likely included species distributions. Therefore, raster layer created containing sum Euclidean geographic distances pixel occurrences species. Obtained values normalized vary zero one. raster layer included environmental layers construct species distribution models. ker (Kernel method). Compiled adapted Allouche et al. (2008), method, like cml, assumes pixels located areas higher density occurrences likely included actual species distribution. Thus, raster layer created containing Gaussian values based density occurrences species. standard deviation Gaussian distribution maximum value vector minimum distances pairs occurrences species. Gaussian values normalized vary zero one. raster layer included  environmental layers construct species distribution models. See Mendes et al. (2020) methodological performance details. used one constraining method cite Mendes et al 2020.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"Mendes, P.; Velazco S.J.E.; Andrade, .F..; De Marco, P. (2020) Dealing overprediction species distribution models: adding distance constraints can improve model accuracy, Ecological Modelling, press. https://doi.org/10.1016/j.ecolmodel.2020.109180 Allouche, O.; Steinitz, O.; Rotem, D.; Rosenfeld, .; Kadmon, R. (2008). Incorporating distance constraints species distribution models. Journal Applied Ecology, 45(2), 599-609. doi:10.1111/j.1365-2664.2007.01445.x Bahn, V.; McGill, B. J. (2007). Can niche-based distribution models outperform spatial interpolation? Global Ecology Biogeography, 16(6), 733-742. doi:10.1111/j.1466-8238.2007.00331.x","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/msdm_priori.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create spatial predictor variables to reduce overprediction of species distribution models — msdm_priori","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra)  data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Select the presences of a species occ <- spp %>%   dplyr::filter(species == \"sp3\", pr_ab == 1)  # Select a raster layer to be used as a basic raster a_variable <- somevar[[1]] plot(a_variable) points(occ %>% dplyr::select(x, y))  ### xy method m_xy <- msdm_priori(   data = occ,   x = \"x\",   y = \"y\",   method = \"xy\",   env_layer = a_variable )  plot(m_xy)  ### min method m_min <- msdm_priori(   data = occ,   x = \"x\",   y = \"y\",   method = \"min\",   env_layer = a_variable )  plot(m_min)  ### cml method m_cml <- msdm_priori(   data = occ,   x = \"x\",   y = \"y\",   method = \"cml\",   env_layer = a_variable )  plot(m_cml)  ### ker method m_ker <- msdm_priori(   data = occ,   x = \"x\",   y = \"y\",   method = \"ker\",   env_layer = a_variable )  plot(m_ker) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform environmental filtering on species occurrences — occfilt_env","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"function perform filtering species occurrences based environmental conditions.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"","code":"occfilt_env(data, x, y, id, env_layer, nbins)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"data data.frame. Data.frame tibble object presences (presence-absence) records, coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates id character. Column names rows id. important row unique code. env_layer SpatRaster. Raster variables used fit model. Factor variables removed. nbins integer. number classes used split environmental condition. possible use single several values. several values provided, function return list results. Usage nbins =  5 nbins = c(5, 10, 15)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"one value used filter occurrence funtion return tibble object filtered data. several values used filter occurrences, function return list tibbles filtered data.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"function uses approach adapted approach proposed Varela et al. (2014).  consists filtering occurrences  environmental space. First, regular  multidimensional grid created  environmental space. multidimensional  grid determined environmental variables (always use continuous variables)  grid cell size defined number bins, used dividing variable range  interval classes (Varela et al. 2014; Castellanos et al., 2019). number bins set  \"nbins\" argument. , single occurrence randomly selected within cell  multidimensional grid. Consider trade-number bins number  filtered records number bins decreases, cell size grids  increases, number filtered records decreases (Castellanos et al., 2019).  occfilt_env works number dimensions (variables) original variables  without performing PCA beforehand. greater number predictor variables (.e., number dimensions  multidimensional environmental grid) greater number bins, greater time processing  computer memory used. Therefore, recommended use small number bins  2-5 ten variables used. Environmental filters sensitive number bins. procedure selecting number  bins used Velazco et al. (2020) implemented occfilt_select.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"Castellanos, . ., Huntley, J. W., Voelker, G., & Lawing, . M. (2019). Environmental filtering improves ecological niche models across multiple scales. Methods Ecology Evolution, 10(4), 481-492. https://doi.org/10.1111/2041-210X.13142 Varela, S., Anderson, R. P., Garcia-Valdes, R., & Fernandez-Gonzalez, F. (2014). Environmental filters reduce effects sampling bias improve predictions ecological niche models. Ecography, 37, 1084-1091. https://doi.org/10.1111/j.1600-0587.2013.00441.x Velazco, S. J. E., Svenning, J-C., Ribeiro, B. R., & Laureto, L. M. O. (2020). opportunities threats conserve phylogenetic diversity Neotropical palms. Diversity Distributions, 27, 512–523. https://doi.org/10.1111/ddi.13215","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_env.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform environmental filtering on species occurrences — occfilt_env","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr) require(ggplot2)  # Environmental variables somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  plot(somevar)  # Species occurrences data(\"spp\") spp spp1 <- spp %>% dplyr::filter(species == \"sp1\", pr_ab == 1)  somevar[[1]] %>% plot() points(spp1 %>% select(x, y))  spp1$idd <- 1:nrow(spp1)   # split environmental variables into 5 bins filtered_1 <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = 5 )  # split into 8 bins filtered_2 <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = 8 )  # split into 12 bins filtered_3 <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = 12 )   ## %######################################################%## ####         ' # Test different number of bins          #### ## %######################################################%##  filtered_dif_bins <- occfilt_env(   data = spp1,   x = \"x\",   y = \"y\",   id = \"idd\",   env_layer = somevar,   nbins = c(4, 6, 8, 10, 12, 14) )  class(filtered_dif_bins) names(filtered_dif_bins) # each elements of this list has the names of the bins  filtered_dif_bins %>%   dplyr::bind_rows(.id = \"bins\") %>%   dplyr::mutate(bins = as.numeric(bins)) %>%   ggplot(aes(x = x, y = y)) +   geom_point() +   facet_wrap(~bins) # note that the higher the nbins parameter the more # classes must be processed (4 variables, 30 bins = 923521 classes)  # While the greater the greater the number of bins, the greater records retained   # It is possible select the best of filtered # datasets using the occfilt_selec function  occ_selected <- occfilt_select(   occ_list = filtered_dif_bins,   x = \"x\",   y = \"y\",   env_layer = somevar,   filter_prop = TRUE )  occ_selected } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform geographical filtering on species occurrences — occfilt_geo","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"function perform geographical filtering species occurrences based different approach define minimum nearest-neighbor distance points.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"","code":"occfilt_geo(   data,   x,   y,   env_layer,   method,   prj = \"+proj=longlat +datum=WGS84\",   reps = 20 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"data data.frame. Data.frame tibble object presences (presence-absence) records, coordinates x character. Column name longitude data y character. Column name latitude data env_layer SpatRaster. Raster variables used fit model. Factor variables removed. method character. Method perform geographical thinning. Pairs points filtered based geographical distance criteria. three method, possible use several values. several values provided, function return list results. following methods available: moran: records filtered based smallest distance Moran's value provided. Moran's   values provided use 0.1. Usage method: method = c('moran')  method = c('moran', val = c(0.1, 0.15, 0.2, 0.25, 0.3, 0.35)). cellsize: records filtered based resolution environmental variables   can aggregated coarser resolution defined factor.   Usage method: method = c('cellsize', factor = '2') method = c('cellsize', factor = c(1, 4, 8)). defined: records filtered based  distance value (d) provided km.   Usage method: method = c('defined', d = c(20, 40, 60, 80)). prj character. Projection string (PROJ4) occurrences. necessary projection used WGS84 (\"+proj=longlat +datum=WGS84\"). Default \"+proj=longlat +datum=WGS84\" reps integer. Number times repeat thinning process. Default 20","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"one value used filter occurrence function return tibble object filtered data. several values used filter occurrences, function return list tibbles filtered data.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"function three alternatives implemented determine distance threshold pair points: ' \"moran\" determines minimum nearest-neighbor distance approximate spatial autocorrelation occurrence data, following Moran's . , Principal Component Analysis environmental variables performed first Principal Component used calculate semivariograms. , method allow use continuous variables. Sometimes, method can () greatly reduce number presences. \"cellsize\" filters occurrences based predictors' resolution. method calculate distance first two cells environmental variable use distance minimum nearest-neighbor distance filter occurrences. resolution raster aggregated based values used \"factor\". Thus, distance used filtering can adjusted represent larger grid size. \"determined\" method uses minimum nearest-neighbor distance specified km. \"thin\" function spThin package used filter data (Aiello-Lammens et al., 2015) following argument settings reps = 20, write.files = FALSE, locs.thinned.list.return = TRUE, write.log.file = FALSE. case one value used methods, possible use use occfilt_select function automatically select filtered database based number records spatial autocorrelation.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"Aiello-Lammens, M. E., Boria, R. ., Radosavljevic, ., Vilela, B., & Anderson, R. P. (2015). spThin: R package spatial thinning species occurrence records use ecological niche models. Ecography, 38(5), 541-545. https://doi.org/10.1111/ecog.01132","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_geo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform geographical filtering on species occurrences — occfilt_geo","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr) require(ggplot2)  # Environmental variables somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  plot(somevar)  # Species occurrences data(\"spp\") spp spp1 <- spp %>% dplyr::filter(species == \"sp1\", pr_ab == 1)  somevar[[1]] %>% plot() points(spp1 %>% select(x, y))  ## %######################################################%## ####                  Cellsize method                   #### ## %######################################################%##  # Using cellsize method filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"cellsize\", factor = \"3\"),   prj = crs(somevar) )  somevar[[1]] %>% plot(col = gray.colors(10)) points(spp1 %>% select(x, y)) # raw data points(filtered_occ %>% select(x, y), pch = 19, col = \"yellow\") # filtered data   # Using cellsize method with several values filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"cellsize\", factor = c(1, 4, 8, 12, 16, 20)),   prj = crs(somevar) )  filtered_occ # Note that several values are provided for any filtering method # fuction will return a list of tibbles with the results. # So user must select the desired filtered dataset  # Let's explore the results bind_rows(filtered_occ, .id = \"cellSize\") %>%   dplyr::mutate(cellSize = as.numeric(cellSize)) %>%   ggplot(aes(x, y)) +   geom_point() +   facet_wrap(~cellSize)   ## %######################################################%## ####                   Defined method                   #### ## %######################################################%## # Using defined method filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"defined\", d = \"30\"),   prj = crs(somevar) )  somevar[[1]] %>% plot(col = gray.colors(10)) points(spp1 %>% select(x, y)) # raw data points(filtered_occ %>% select(x, y), pch = 19, col = \"yellow\") # filtered data  # Using defined method with several values filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"defined\", factor = c(5, 10, 15, 30, 35, 40)),   prj = crs(somevar) )  bind_rows(filtered_occ, .id = \"cellSize\") %>%   dplyr::mutate(cellSize = as.numeric(cellSize)) %>%   ggplot(aes(x, y)) +   geom_point() +   facet_wrap(~cellSize)   ## %######################################################%## ####                  Moran's I method                  #### ## %######################################################%##  # Using Moran's I method filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"moran\"),   prj = crs(somevar) )  somevar[[1]] %>% plot(col = gray.colors(10)) points(spp1 %>% select(x, y)) # raw data points(filtered_occ %>% select(x, y), pch = 19, col = \"yellow\") # filtered data  # Using Moran's I method with several values filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"moran\", c(0.05, 0.15, 0.2, 0.5, 0.7)),   prj = crs(somevar) )  bind_rows(filtered_occ, .id = \"moran\") %>%   dplyr::mutate(moran = as.numeric(moran)) %>%   ggplot(aes(x, y)) +   geom_point() +   facet_wrap(~moran)  # It is possible select the best of filtered # datasets using the occfilt_selec function  occ_selected <- occfilt_select(   occ_list = filtered_occ,   x = \"x\",   y = \"y\",   env_layer = somevar,   filter_prop = TRUE )  occ_selected } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":null,"dir":"Reference","previous_headings":"","what":"Select filtered occurrences — occfilt_select","title":"Select filtered occurrences — occfilt_select","text":"Select filtered occurrences based number records spatial autocorrelation (see details)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select filtered occurrences — occfilt_select","text":"","code":"occfilt_select(occ_list, x, y, env_layer, filter_prop = FALSE)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select filtered occurrences — occfilt_select","text":"occ_list list. list filtered specie occurrences testing several values (see occfilt_env occfilt_geo) x character. Column name longitude data y character. Column name latitude data env_layer SpatRaster. Raster variables used fit model. Factor variables removed. filter_prop logical. TRUE, function return list filtered occurrences tibble spatial autocorrelation number occurrence values","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select filtered occurrences — occfilt_select","text":"filter_prop = FALSE, tibble selected filtered occurrences. filter_prop = TRUE, list following objects: tibble selected filtered occurrences tibble filter properties columns: filt_value: values used filtering, value asterisk denote one selected n_records: number occurrence mean_autocorr: mean spatial autocorrelation. remaining columns spatial autocorrelation values variable.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select filtered occurrences — occfilt_select","text":"function implement approach used Velazco et al. (2020) consists calculating filtered dataset: 1- number occurrence. 2- spatial autocorrelation based Morans'variable 3- mean spatial autocorrelation among variables function select dataset average spatial autocorrelation lower mean dataset, subset select one highest number occurrences. use occfilt_select cite Velazco et al. (2020) reference.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Select filtered occurrences — occfilt_select","text":"Velazco, S. J. E., Svenning, J-C., Ribeiro, B. R., & Laureto, L. M. O. (2020). opportunities threats conserve phylogenetic diversity Neotropical palms. Diversity Distributions, 27, 512–523. https://doi.org/10.1111/ddi.13215","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/occfilt_select.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select filtered occurrences — occfilt_select","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr)  # Environmental variables somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  plot(somevar)  # Species occurrences data(\"spp\") spp spp1 <- spp %>% dplyr::filter(species == \"sp1\", pr_ab == 1)  ## %######################################################%## ####                  Cellsize method                   #### ## %######################################################%## # Using cellsize method filtered_occ <- occfilt_geo(   data = spp1,   x = \"x\",   y = \"y\",   env_layer = somevar,   method = c(\"cellsize\", factor = c(1, 4, 8, 12, 16, 20)),   prj = crs(somevar) )  filtered_occ  # Select filtered occurrences based on # number of records and spatial autocorrelation occ_selected <- occfilt_select(   occ_list = filtered_occ,   x = \"x\",   y = \"y\",   env_layer = somevar,   filter_prop = FALSE ) occ_selected  occ_selected <- occfilt_select(   occ_list = filtered_occ,   x = \"x\",   y = \"y\",   env_layer = somevar,   filter_prop = TRUE ) occ_selected$occ  occ_selected$filter_prop } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/palms.html","id":null,"dir":"Reference","previous_headings":"","what":"A data set containing presences of palms species from Southern Brazil — palms","title":"A data set containing presences of palms species from Southern Brazil — palms","text":"data set contains presences 11 palm species Southern Brazil sourced Calambás-Trochez et al. (2021).","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/palms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data set containing presences of palms species from Southern Brazil — palms","text":"","code":"palms"},{"path":"https://sjevelazco.github.io/flexsdm/reference/palms.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data set containing presences of palms species from Southern Brazil — palms","text":"tibble 327 rows 3 variables: species species names x longitude species occurrences y latitude species occurrences","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/palms.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A data set containing presences of palms species from Southern Brazil — palms","text":"Calambás-Trochez, L.F., Velazco, S.J.E., Hoffmann, P.M., Brum, F.T., Carlucci, M.B., 2021. Climate land-use changes coupled low coverage protected areas threaten palm species South Brazilian grasslands. Perspectives Ecology Conservation 9. https://doi.org/10.1016/j.pecon.2021.03.010","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/palms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A data set containing presences of palms species from Southern Brazil — palms","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) data(\"palms\")  } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_random.html","id":null,"dir":"Reference","previous_headings":"","what":"Conventional data partitioning methods — part_random","title":"Conventional data partitioning methods — part_random","text":"function provides different conventional (randomized, non-spatial) partitioning methods based cross validation folds (kfold, rep_kfold, loocv), well bootstrap (boot)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_random.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conventional data partitioning methods — part_random","text":"","code":"part_random(data, pr_ab, method = NULL)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_random.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conventional data partitioning methods — part_random","text":"data data.frame. Database presences, presence-absence, pseudo-absence, records given species pr_ab character. Column name \"data\" presences, presence-absence, pseudo-absence. Presences must represented 1 absences 0 method character. Vector data partitioning method used. Usage   part=c(method= 'kfold', folds='5'). Methods include: kfold: Random partitioning k-folds cross-validation. 'folds' refers number folds data   partitioning, assumes value >=1. Usage method = c(method = \"kfold\", folds = 10). rep_kfold: Random partitioning repeated k-folds  cross-validation.   Usage method = c(method = \"rep_kfold\", folds = 10, replicates=10). 'folds' refers   number folds data partitioning, assumes value >=1. 'replicate' refers   number replicates, assumes value >=1. loocv: Leave-one-cross-validation (.k.. Jackknife). special case k-fold   cross validation number partitions equal number records.   Usage method = c(method = \"loocv\"). boot: Random bootstrap partitioning. Usage method=c(method='boot', replicates='2',   proportion='0.7'). 'replicate' refers number replicates, assumes value >=1.   'proportion' refers proportion occurrences used model fitting, assumes   value >0 <=1. example proportion='0.7' mean 70% data used   model training, 30% used model testing.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_random.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conventional data partitioning methods — part_random","text":"tibble object information used 'data' argument additional columns named .part containing partition groups. rep_kfold boot method return many \".part\" columns replicated defined. rest methods, single .part column returned. kfold, rep_kfold, loocv partition methods, groups defined integers. contrast, boot method, partition groups defined characters 'train' 'test'.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_random.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conventional data partitioning methods — part_random","text":"Fielding, . H., & Bell, J. F. (1997). review methods assessment prediction errors conservation presence/absence models. Environmental Conservation, 24(1), 38-49. https://doi.org/10.1017/S0376892997000088","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_random.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conventional data partitioning methods — part_random","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") abies$partition <- NULL abies <- tibble(abies)  # K-fold method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 10) ) abies2  # Repeated K-fold method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 10, replicates = 10) ) abies2  # Leave-one-out cross-validation (loocv) method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"loocv\") ) abies2  # Bootstrap method abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"boot\", replicates = 50, proportion = 0.7) ) abies2 abies2$.part1 %>% table() # Note that for this method .partX columns have train and test words. } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial band cross-validation — part_sband","title":"Spatial band cross-validation — part_sband","text":"function explores different numbers spatial bands returns suitable value given presence presence-absence database. selection best number bands performed automatically considering spatial autocorrelation, environmental similarity, number presence absence records partition.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial band cross-validation — part_sband","text":"","code":"part_sband(   env_layer,   data,   x,   y,   pr_ab,   type = \"lon\",   n_part = 2,   min_bands = 2,   max_bands = 20,   min_occ = 10,   prop = 0.5 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial band cross-validation — part_sband","text":"env_layer SpatRaster. Raster environmental variable. Used evaluate spatial autocorrelation environmental similarity training testing partitions. function calculate dissimilarity based Euclidean distances, can used continuous environmental variables data data.frame. Data.frame tibble object presences (presence-absence, presence-pseudo-absence) records, coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates pr_ab character. Column presences, presence-absence, -pseudo-absence. Presences must represented 1 absences 0 type character. Specify bands across different degrees longitude 'lon' latitude 'lat'. Default 'lon'. n_part integer. Number partition. Default 2, values 2 yet implemented. min_bands integer. Minimum number spatial bands tested, default 2. max_bands integer. Maximum number spatial bands tested, default 20. min_occ numeric. Minimum number presences absences partition fold. min_occ value base number predictors order avoid -fitting error fitting models given fold. Default 10. prop numeric. Proportion points used testing autocorrelation groups (values > 0 <=1). smaller number , faster function work. Default 0.5","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial band cross-validation — part_sband","text":"list : part: tibble object information used 'data' arguments additional column   .part partition group. best_part_info: tibble information best partition. contains   number best partition (n_grid), number bands (n_bands), standard deviation   presences (sd_p), standard deviation absences (sd_a), Moran's spatial autocorrelation   (spa_auto), environmental similarity based Euclidean distance (env_sim). grid: SpatRaster object bands","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spatial band cross-validation — part_sband","text":"part_sbands function allows testing different numbers partitions using range latitudinal longitudinal bands. function explores range numbers bands given number partitions automatically selects best number bands given presence, presence-absences, presence-pseudo-absences dataset. Selection number bands based optimization procedure explores partitions three dimensions determined spatial autocorrelation (measured Moran's ), environmental similarity (Euclidean distance), difference amount data among partition groups (Standard Deviation - SD; Velazco et al., 2019). procedure iterative; first select partitions autocorrelation values less lowest quartile Morans , environmental similarity values greater third quartile Euclidean distances, difference amount data less lowest quartile SD. selection repeated one partition retained (Velazco et al., 2019). main benefits partition selection ) subjective, ii) balances environmental similarity special autocorrelation partitions groups, iii) controls selection partitions little data may problematic model fitting (\"min_occ\" argument). Partitions geographically structured tend evaluate model transferability directly conventional ones (e.g., performed part_random) (Roberts et al., 2017; Santini et al., 2021), relevant models used projections regions outside calibration area time periods. Band partitions can option species best partition found part_sblock species distributed linearly (e.g., species inhabit coastlines). function can interact get_block, sample_background, sample_pseudoabs sampling background points pseudo-absences within spatial partition broups","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Spatial band cross-validation — part_sband","text":"Roberts, D. R., Bahn, V., Ciuti, S., Boyce, M. S., Elith, J., Guillera-Arroita, G., Hauenstein, S., Lahoz-Monfort, J. J., Schroder, B., Thuiller, W., Warton, D. ., Wintle, B. ., Hartig, F., & Dormann, C. F. (2017). Cross-validation strategies data temporal, spatial,  hierarchical, phylogenetic structure. Ecography, 40,  913-929. https://doi.org/10.1111/ecog.02881 Santini, L., Benitez-Lopez, ., Maiorano, L., Cengic, M., & Huijbregts, M. . J. (2021).  Assessing reliability species distribution projections climate change research.  Diversity Distributions, ddi.13252. https://doi.org/10.1111/ddi.13252 Velazco, S. J. E., Villalobos, F., Galvao, F., & De Marco Junior, P. (2019). dark scenario Cerrado plant species: Effects future climate, land use protected areas ineffectiveness. Diversity Distributions, 25(4), 660-673. https://doi.org/10.1111/ddi.12886","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sband.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatial band cross-validation — part_sband","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr)  # Load datasets data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Example of two longitudinal partitions with presences and absences single_spp <- spp %>% dplyr::filter(species == \"sp1\") part_1 <- part_sband(   env_layer = somevar,   data = single_spp,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   type = \"lon\",   min_bands = 2,   max_bands = 20,   n_part = 2,   min_occ = 10,   prop = 0.5 )  part_1$part # database with partition fold (.part) part_1$part %>%   group_by(pr_ab, .part) %>%   count() # number of presences and absences in each fold part_1$best_part_info # information of the best partition part_1$grid # raster with folds  # Explore grid object and presences and absences points plot(part_1$grid, col = gray.colors(20)) points(part_1$part[c(\"x\", \"y\")],   col = rainbow(8)[part_1$part$.part],   cex = 0.9,   pch = c(1, 19)[part_1$part$pr_ab + 1] )   # Example of four latitudinal partition and only presences single_spp <- spp %>% dplyr::filter(species == \"sp1\", pr_ab == 1) part_2 <- part_sband(   env_layer = somevar,   data = single_spp,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   type = \"lat\",   min_bands = 8,   max_bands = 40,   n_part = 8,   min_occ = 10,   prop = 0.5 )  part_2$part part_2$best_part_info part_2$grid  # Explore Grid object and presences points plot(part_2$grid, col = gray.colors(20)) points(part_2$part[c(\"x\", \"y\")],   col = rainbow(8)[part_2$part$.part],   cex = 0.5,   pch = 19 ) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial block cross-validation — part_sblock","title":"Spatial block cross-validation — part_sblock","text":"function explores spatial blocks different cell sizes returns suitable size given presence presence-absence database. selection best grid size performed automatically considering spatial autocorrelation, environmental similarity, number presence absence records partition.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial block cross-validation — part_sblock","text":"","code":"part_sblock(   env_layer,   data,   x,   y,   pr_ab,   n_part = 3,   min_res_mult = 3,   max_res_mult = 200,   num_grids = 30,   min_occ = 10,   prop = 0.5 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial block cross-validation — part_sblock","text":"env_layer SpatRaster. Raster environmental variable. Used evaluate spatial autocorrelation environmental similarity training testing partitions. function calculate dissimilarity based Euclidean distances, can used continuous environmental variables data data.frame. Data.frame tibble object presence (presence-absence, presences-pseudo-absence) records, coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates pr_ab character. Column presence, presence-absence, pseudo-absence records. Presences must represented 1 absences 0 n_part integer. Number partition. Default 2. min_res_mult integer. Minimum value used multiplying raster resolution define finest resolution tested, default 3. max_res_mult integer. Maximum value used multiplying raster resolution define coarsest resolution tested, default 200. num_grids integer. Number grid tested min_res_mult X (raster resolution) max_res_mult X (raster resolution), default 30 min_occ numeric. Minimum number presences absences partition fold. min_occ value base amount predictors order avoid -fitting error fitting models given fold. Default 10. prop numeric. Proportion point used testing autocorrelation groups (values > 0 <=1). smaller proportion , faster function work. Default 0.5","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial block cross-validation — part_sblock","text":"list : part: tibble object information used 'data' arguments additional column   .part partition group. best_part_info: tibble information best partition. contains   number best partition (n_grid), cell size (cell_size), standard deviation   presences (sd_p), standard deviation absences (sd_a), Moran's spatial autocorrelation   (spa_auto), environmental similarity based Euclidean distance (env_sim). grid: SpatRaster object blocks","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spatial block cross-validation — part_sblock","text":"part_sblock allows test different numbers partitions using square blocks (like checkerboard). function explores range block sizes automatically selects best size given given presence, presence-absences, presence-pseudo-absences dataset. Number partition selection based optimization procedure explores partition size three dimensions determined spatial autocorrelation (measured Moran's ), environmental similarity (Euclidean distance), difference amount data among partition groups (Standard Deviation - SD; Velazco et al., 2019). procedure iteratively select partitions, first partitions autocorrelation values less lowest quartile Morans , environmental similarity values greater third quartile Euclidean distances difference amount data less lowest quartile SD. selection repeated one partition retained (Velazco et al., 2019). main benefit partition selection ) subjective, ii) balances environmental similarity special autocorrelation partitions, iii) controls selection partitions data may problematic model fitting (\"min_occ\" argument). Geographically structured partitions tend evaluate model transferability directly conventional ones (e.g., performed part_random) (Roberts et al., 2017; Santini et al., 2021), relevant models used projections regions outside calibration area time periods. function can interact get_block, sample_background, sample_pseudoabs sampling background points pseudo-absences within spatial partition broups","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Spatial block cross-validation — part_sblock","text":"Roberts, D. R., Bahn, V., Ciuti, S., Boyce, M. S., Elith, J., Guillera-Arroita, G., Hauenstein, S., Lahoz-Monfort, J. J., Schroder, B., Thuiller, W., Warton, D. ., Wintle, B. ., Hartig, F., & Dormann, C. F. (2017). Cross-validation strategies data temporal, spatial,  hierarchical, phylogenetic structure. Ecography, 40,  913-929. https://doi.org/10.1111/ecog.02881 Santini, L., Benitez-Lopez, ., Maiorano, L., Cengic, M., & Huijbregts, M. . J. (2021).  Assessing reliability species distribution projections climate change research.  Diversity Distributions, ddi.13252. https://doi.org/10.1111/ddi.13252 Velazco, S. J. E., Villalobos, F., Galvao, F., & De Marco Junior, P. (2019). dark scenario Cerrado plant species: Effects future climate, land use protected areas ineffectiveness. Diversity Distributions, 25(4), 660-673. https://doi.org/10.1111/ddi.12886","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_sblock.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatial block cross-validation — part_sblock","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr)  # Load datasets data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Example for one single species single_spp <- spp %>% dplyr::filter(species == \"sp3\") part <- part_sblock(   env_layer = somevar,   data = single_spp,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_res_mult = 10,   max_res_mult = 500,   num_grids = 30,   n_part = 2,   min_occ = 5,   prop = 0.5 ) part  part$part # database with partition fold (.part) part$part %>%   group_by(pr_ab, .part) %>%   count() # number of presences and absences in each fold part$best_part_info # information of the best partition part$grid # raster with folds  # Explore the Grid object  plot(part$grid) points(part$part[c(\"x\", \"y\")],   col = c(\"blue\", \"red\")[part$part$.part],   cex = 0.5,   pch = 19 )  terra::res(part$grid) terra::res(somevar)  # Note that this is a layer with block partition, but it has a # different resolution than the original environmental variables. # If you wish have a layer with the same properties # (i.e. resolution, extent, NAs) as your original environmental # variables you can use the \\code{\\link{get_block}} function.  grid_env <- get_block(env_layer = somevar, best_grid = part$grid)  plot(grid_env) # this is a block layer with the same layer # properties as environmental variables. points(part$part[c(\"x\", \"y\")],   col = c(\"blue\", \"red\")[part$part$.part],   cex = 0.5,   pch = 19 ) # This layer is very useful if you need to sample # pseudo_absence or background point # See examples in \\code{\\link{backgroudp}} and \\code{\\link{pseudoabs}}   # Example of a higher number of partitions part <- part_sblock(   env_layer = somevar,   data = single_spp,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_res_mult = 10,   max_res_mult = 500,   num_grids = 30,   n_part = 4,   min_occ = 2,   prop = 0.5 )  # Explore the Grid object plot(part$grid, col = gray.colors(4)) points(part$part[c(\"x\", \"y\")],   col = rainbow(n = 4)[part$part$.part],   cex = 0.5,   pch = 19 )   # Using these functions with several species spp2 <- split(spp, spp$species) class(spp2) length(spp2) names(spp2)  part_list <- lapply(spp2, function(x) {   result <- part_sblock(     env_layer = somevar,     data = x,     x = \"x\",     y = \"y\",     pr_ab = \"pr_ab\",     min_res_mult = 10,     max_res_mult = 500,     num_grids = 30,     n_part = 2,     min_occ = 5,     prop = 0.5   )   result })  part_list$sp3 # For this dataset a suitable partition was not found  # Create a single database for all species occ_part <- lapply(part_list, function(x) {   if (!length(x) > 0) {     x[[1]]   } }) %>%   dplyr::bind_rows(.id = \"species\") occ_part  # Get the best grid info for all species grid_info <- dplyr::bind_rows(lapply(   part_list,   function(x) x[[2]] ), .id = \"species\")  # Get the best grid layer for all species grid_layer <- lapply(part_list, function(x) x$grid) grid_layer2 <-   lapply(grid_layer, function(x) {     get_block(env_layer = somevar[[1]], best_grid = x)   }) grid_layer2 <- terra::rast(grid_layer2) grid_layer2 plot(grid_layer2)   # Block partition for presences-only database single_spp <- spp %>%   dplyr::filter(species == \"sp1\", pr_ab == 1) single_spp single_spp$pr_ab %>% unique() # only presences  part <- part_sblock(   env_layer = somevar,   data = single_spp,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_res_mult = 10,   max_res_mult = 500,   num_grids = 30,   n_part = 4,   min_occ = 10,   prop = 0.5 )  part$part %>% dim() part$best_part_info part$grid  plot(part$grid) points(   part$part[c(\"x\", \"y\")],   col = c(\"blue\", \"red\", \"green\", \"black\")[part$part$.part],   cex = 0.5,   #' pch = 19 ) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":null,"dir":"Reference","previous_headings":"","what":"Environmental and spatial cross-validation — part_senv","title":"Environmental and spatial cross-validation — part_senv","text":"function explores different numbers environmental partitions (clusters) based K-means clustering algorithm returns number partitions best suited given presence, presence-absences, presence-pseudo-absences database. Selection best number partitions performed automatically considering spatial autocorrelation, environmental similarity, number presence /absence records partition.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Environmental and spatial cross-validation — part_senv","text":"","code":"part_senv(   env_layer,   data,   x,   y,   pr_ab,   min_n_groups = 2,   max_n_groups = 10,   min_occ = 10,   prop = 0.5 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Environmental and spatial cross-validation — part_senv","text":"env_layer SpatRaster. Raster environmental variable. used evaluate spatial autocorrelation environmental similarity training testing partitions. function calculate dissimilarity based Euclidean distances, can used continuous variables data data.frame. Data.frame tibble object presence (presence-absence, presences-pseudo-absence) records, coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates pr_ab character. Column presences, presence-absence, pseudo-absence. Presences must represented 1 absences 0 min_n_groups integer. Minimum number groups tested. Default 2. max_n_groups integer. Maximum number groups tested. Default 10. min_occ numeric. Minimum number presences absences partition fold. min_occ value base amount predictors order avoid -fitting error fitting models given fold. Default 10. prop numeric. Proportion point used testing autocorrelation groups (values > 0 <=1). smaller number , faster function work. Default 0.5","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Environmental and spatial cross-validation — part_senv","text":"list : part: tibble object information used 'data' arguments additional column   .part partition group. best_part_info: tibble information best partition. contains   number partition (n_groups), standard deviation presences (sd_p), standard deviation   absences (sd_a), Moran's spatial autocorrelation (spa_auto) environmental similarity   based Euclidean distance (env_sim)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Environmental and spatial cross-validation — part_senv","text":"part_sblock allows test different numbers partitions defined envirnomental clusters delimited K-mean cluster algorithm. function explores range environmental clusters automatically selects best number cluster given given presence, presence-absences, presence-pseudo-absences dataset. selection number clusters based optimization procedure explores partition size three dimensions determined spatial autocorrelation (measured Moran's ), environmental similarity (Euclidean distance), difference amount data among clusters (Standard Deviation - SD; Velazco et al., 2019). procedure cyclically select partitions autocorrelation values less lowest quartile Morans , environmental similarity values greater third quartile Euclidean distances difference amount data less lowest quartile SD. selection repeated one partition retained (Velazco et al., 2019). main benefit partition selection ) subjective, ii) balances environmental similarity special autocorrelation partitions, iii) controls partition selection data may problematic model fitting (\"min_occ\" argument).. Partitions geographically structured tend evaluate model transferability directly conventional ones (e.g., performed part_random) (Roberts et al., 2017; Santini et al., 2021), relevant models want used projections regions outside calibration area periods. function can interact get_block, sample_background, sample_pseudoabs sampling background points pseudo-absences within spatial partition broups","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Environmental and spatial cross-validation — part_senv","text":"Roberts, D. R., Bahn, V., Ciuti, S., Boyce, M. S., Elith, J., Guillera-Arroita, G., Hauenstein, S., Lahoz-Monfort, J. J., Schroder, B., Thuiller, W., Warton, D. ., Wintle, B. ., Hartig, F., & Dormann, C. F. (2017). Cross-validation strategies data temporal, spatial,  hierarchical, phylogenetic structure. Ecography, 40,  913-929. https://doi.org/10.1111/ecog.02881 Santini, L., Benitez-Lopez, ., Maiorano, L., Cengic, M., & Huijbregts, M. . J. (2021).  Assessing reliability species distribution projections climate change research.  Diversity Distributions, ddi.13252. https://doi.org/10.1111/ddi.13252 Velazco, S. J. E., Villalobos, F., Galvao, F., & De Marco Junior, P. (2019). dark scenario Cerrado plant species: Effects future climate, land use protected areas ineffectiveness. Diversity Distributions, 25(4), 660-673. https://doi.org/10.1111/ddi.12886","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/part_senv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Environmental and spatial cross-validation — part_senv","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(ggplot2)  f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Select a species spp1 <- spp %>% dplyr::filter(species == \"sp1\")  part1 <- part_senv(   env_layer = somevar,   data = spp1,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_n_groups = 2,   max_n_groups = 10,   min_occ = 10,   prop = 0.2 )  part1  ggplot(part1$part, aes(x, y, col = factor(.part))) +   geom_point(aes(shape = factor(pr_ab)))  ggplot(part1$part, aes(x, y, col = factor(.part))) +   geom_point(aes(shape = factor(pr_ab))) +   facet_wrap(. ~ .part)  ggplot(part1$part, aes(x, y, col = factor(.part))) +   geom_point(aes(shape = factor(pr_ab))) +   facet_wrap(. ~ pr_ab) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/pdp_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate data to construct partial dependence plots — pdp_data","title":"Calculate data to construct partial dependence plots — pdp_data","text":"Calculate data construct partial dependence plots given predictor","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/pdp_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate data to construct partial dependence plots — pdp_data","text":"","code":"pdp_data(   model,   predictors,   resolution = 50,   resid = FALSE,   training_data = NULL,   projection_data = NULL,   clamping = FALSE )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/pdp_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate data to construct partial dependence plots — pdp_data","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector predictor name(s) plot. NULL predictors plotted. Default NULL resolution numeric. Number equally spaced points predict continuous predictors. Default 50 resid logical. Calculate residuals based training data. Default FALSE training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL projection_data SpatRaster. Raster layer environmental variables used model projection. argument used, function calculate partial dependence curves distinguishing conditions used training projection conditions (.e., projection data present projection area training). Default NULL clamping logical. Perform clamping. maxent models. Default FALSE","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/pdp_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate data to construct partial dependence plots — pdp_data","text":"list two tibbles \"pdpdata\" \"resid\". #' pdpdata: data construct partial dependence plots, first column includes values selected environmental variable, second column predicted suitability, third  column range type, two values Training Projecting, referring suitability  calculated within outside range training conditions. Third column returned  \"projection_data\" argument used resid: data plot residuals. first column includes values selected environmental  variable second column predicted suitability.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/pdp_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate data to construct partial dependence plots — pdp_data","text":"","code":"if (FALSE) { library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  abies2 <- abies %>%   select(x, y, pr_ab)  abies2 <- sdm_extract(abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  df <- pdp_data(   model = svm_t1$model,   predictors = c(\"aet\"),   resolution = 100,   resid = TRUE,   projection_data = somevar,   training_data = abies2,   clamping = FALSE )  df names(df) df$pdpdata df$resid  plot(df$pdpdata[1:2], type = \"l\") points(df$resid[1:2], cex = 0.5)  # see p_pdp to construct partial dependence plot with ggplot2 }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/plot_res.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot different resolutions to be used in part_sblock — plot_res","title":"Plot different resolutions to be used in part_sblock — plot_res","text":"function useful display maximum minimum resolution want test block_partition function. Note resolution tested fine, plot display may take long time.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/plot_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot different resolutions to be used in part_sblock — plot_res","text":"","code":"plot_res(r, res_mult)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/plot_res.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot different resolutions to be used in part_sblock — plot_res","text":"r SpatRaster. raster layer, preferably layer environmental variables used res_mult numeric. Maximum minimum resolution tested.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/plot_res.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot different resolutions to be used in part_sblock — plot_res","text":"plot original raster overlapped grid resolution used","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/plot_res.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot different resolutions to be used in part_sblock — plot_res","text":"","code":"if (FALSE) { # \\dontrun{ f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") r <- terra::rast(f) r <- r$CFP_1 plot_res(r, res_mult = 100) plot_res(r, res_mult = 200) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_bpdp.html","id":null,"dir":"Reference","previous_headings":"","what":"Bivariate partial dependence plot — p_bpdp","title":"Bivariate partial dependence plot — p_bpdp","text":"Create bivariate partial dependence plot(s) explore bivariate marginal effect predictors suitability","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_bpdp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bivariate partial dependence plot — p_bpdp","text":"","code":"p_bpdp(   model,   predictors = NULL,   resolution = 50,   training_data = NULL,   training_boundaries = NULL,   projection_data = NULL,   clamping = FALSE,   color_gradient = c(\"#000004\", \"#1B0A40\", \"#4A0C69\", \"#781B6C\", \"#A42C5F\", \"#CD4345\",     \"#EC6824\", \"#FA990B\", \"#F7CF3D\", \"#FCFFA4\"),   color_training_boundaries = \"white\",   theme = ggplot2::theme_classic() )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_bpdp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bivariate partial dependence plot — p_bpdp","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector predictor names calculate partial dependence plots. NULL predictors used. Default NULL resolution numeric. Number equally spaced points predict suitability values continuous predictors. Default 50 training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL training_boundaries character. Plot training conditions boundaries based training data (.e., presences, presences absences, etc). training_boundaries = \"convexh\", function delimit training environmental region based convex-hull. training_boundaries = \"rectangle\", function delimit training environmental region based four straight lines. used methods necessary provide data training_data argument. NULL predictors used. Default NULL. projection_data SpatRaster. Raster layer environmental variables used model projection. Default NULL clamping logical. Perform clamping. maxent models. Default FALSE color_gradient character. vector range colors plot. Default c(\"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\", \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\") color_training_boundaries character. vector one color used color points residuals, Default \"white\" theme ggplot2 theme. Default ggplot2::theme_classic()","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_bpdp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bivariate partial dependence plot — p_bpdp","text":"function creates partial dependent surface plots explore bivariate marginal effect predictors suitability. projection_data used, function extract minimum maximum values found region time period model projected. Partial dependence surface plot used interpret model explore model extrapolate outside environmental conditions used train model (convex hull polygon).","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_bpdp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bivariate partial dependence plot — p_bpdp","text":"","code":"if (FALSE) { # \\dontrun{ library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  # set seed abies2 <- abies %>%   dplyr::select(x, y, pr_ab) %>%   dplyr::group_by(pr_ab) %>%   dplyr::slice_sample(prop = 0.5)  abies2 <- sdm_extract(abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  # Partial depence surface plot p_bpdp(model = svm_t1$model, training_data = abies2) p_bpdp(model = svm_t1$model, training_data = abies2, predictors = c(\"aet\", \"cwd\")) p_bpdp(model = svm_t1$model, training_data = abies2, resolution = 10) p_bpdp(model = svm_t1$model, training_data = abies2, resolution = 70) # With training condition boundaires p_bpdp(   model = svm_t1$model, training_data = abies2,   training_boundaries = \"convexh\" ) p_bpdp(   model = svm_t1$model, training_data = abies2,   training_boundaries = \"rectangle\", color_training_boundaries = \"yellow\" ) p_bpdp(   model = svm_t1$model, training_data = abies2, training_boundaries = \"convexh\",   color_training_boundaries = \"orange\",   color_gradient = c(\"#00007F\", \"#007FFF\", \"#7FFF7F\", \"#FF7F00\", \"#7F0000\") ) # With projection data p_bpdp(   model = svm_t1$model, training_data = abies2, training_boundaries = \"rectangle\",   projection_data = somevar, # a SpatRaster used to predict or project the model   color_training_boundaries = \"white\",   color_gradient = c(\"#00007F\", \"#007FFF\", \"#7FFF7F\", \"#FF7F00\", \"#7F0000\") )  # Bivariate partial dependence plot for training and projection condition plot(somevar[[1]], main = \"Projection area\") p_bpdp(   model = svm_t1$model, training_data = abies2,   projection_data = somevar, # a SpatRaster used to predict or project the model   training_boundaries = \"convexh\" )   # Bivariate partial dependece plot with categorical variables somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") cat <- system.file(\"external/clusters.shp\", package = \"flexsdm\") cat <- terra::vect(cat) cat$clusters <- paste0(\"c\", cat$clusters) cat <- terra::rasterize(cat, somevar, field = \"clusters\") somevar <- c(somevar, cat) plot(somevar)  # set seed abies2 <- abies %>%   dplyr::select(x, y, pr_ab) %>%   dplyr::group_by(pr_ab) %>%   dplyr::slice_sample(prop = 0.5)  abies2 <- sdm_extract(   data = abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   predictors_f = \"clusters\",   partition = \".part\",   thr = c(\"max_sens_spec\") )  p_bpdp(model = svm_t1$model, training_data = abies2, training_boundaries = \"convexh\") } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_extra.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical exploration of extrapolation or suitability pattern in the environmental and geographical space — p_extra","title":"Graphical exploration of extrapolation or suitability pattern in the environmental and geographical space — p_extra","text":"Graphical exploration extrapolation suitability pattern environmental geographical space","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_extra.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical exploration of extrapolation or suitability pattern in the environmental and geographical space — p_extra","text":"","code":"p_extra(   training_data,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data,   projection_data,   predictors = NULL,   geo_space = TRUE,   geo_position = \"right\",   prop_points = 0.2,   maxcells = 1e+05,   alpha_p = 0.5,   color_p = \"black\",   alpha_gradient = 0.5,   color_gradient = c(\"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\",     \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\"),   theme = ggplot2::theme_classic() )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_extra.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical exploration of extrapolation or suitability pattern in the environmental and geographical space — p_extra","text":"training_data data.frame. Database response (0,1) predictor values used fit model. x character. Column name spatial x coordinates y character. Column name spatial y coordinates pr_ab character. Column name species absence-presence, pseudo-absence-presence, background-presence data (0,1). extra_suit_data SpatRaster. Raster layer extrapolation suitability values. extra_suit_data must resolution extent projection_data projection_data SpatRaster. Raster layer environmental variables used model projection. projection_data must resolution extent extra_suit_data predictors character. Vector predictor name(s) calculate partial dependence plots. NULL predictors used. Default NULL. geo_space logical. TRUE produced map. Default TRUE geo_position character. Map position regarding plot environmental space, right, left, bottom, upper. Default \"right\" prop_points numeric. Proportion cells extra_suit_data projection_data select plotting. default. 0.5. maxcells integer. Maximum number cells used plot geographical space. Default 100000 alpha_p numeric. value 0 1 control transparency presence-absence points. Lower values corresponding transparent colors. Default 0.5 color_p character. vector color used color presence-absence points. Default \"black\" alpha_gradient numeric. value 0 1 control transparency projection data Lower values corresponding transparent colors. Default 0.5 color_gradient character. vector colors used color projection data. Default  c( \"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\", \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\") theme ggplot2 theme. Default ggplot2::theme_classic()","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_extra.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical exploration of extrapolation or suitability pattern in the environmental and geographical space — p_extra","text":"plot","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_extra.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical exploration of extrapolation or suitability pattern in the environmental and geographical space — p_extra","text":"","code":"if (FALSE) { # \\dontrun{  require(dplyr) require(terra) require(ggplot2)  data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f) names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\")  spp$species %>% unique() sp <- spp %>%   dplyr::filter(species == \"sp2\", pr_ab == 1) %>%   dplyr::select(x, y, pr_ab)  # Calibration area based on some criterion such as dispersal ability ca <- calib_area(sp,   x = \"x\", y = \"y\",   method = c(\"buffer\", width = 50000), crs = crs(somevar) )  plot(somevar[[1]]) points(sp) plot(ca, add = T)   # Sampling pseudo-absences set.seed(10) psa <- sample_pseudoabs(   data = sp,   x = \"x\",   y = \"y\",   n = nrow(sp) * 2,   method = \"random\",   rlayer = somevar,   calibarea = ca )  # Merge presences and abasences databases to get a complete calibration data sp_pa <- dplyr::bind_rows(sp, psa) sp_pa  # Get environmental condition of calibration area sp_pa_2 <- sdm_extract(data = sp_pa, x = \"x\", y = \"y\", env_layer = somevar) sp_pa_2  # Measure extrapolation based on calibration data (presence and pseudo-absences) # using SHAPE metric extr <-   extra_eval(     training_data = sp_pa_2,     pr_ab = \"pr_ab\",     projection_data = somevar,     metric = \"mahalanobis\",     univar_comb = FALSE,     n_cores = 1,     aggreg_factor = 1   ) plot(extr)  ## %######################################################%## ####            Explore extrapolation in the            #### ####        environmental and geographical space        #### ## %######################################################%##  p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = extr,   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05 )  p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = extr,   projection_data = somevar,   predictors = c(\"tmn\", \"cwd\"),   geo_space = TRUE,   prop_points = 0.05 )  p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = extr,   projection_data = somevar,   predictors = c(\"cwd\", \"tmx\", \"aet\"),   geo_space = TRUE,   geo_position = \"left\",   prop_points = 0.05,   color_p = \"white\",   alpha_p = 0.5,   alpha_gradient = 0.2,   color_gradient = c(\"#404096\", \"#529DB7\", \"#7DB874\", \"#E39C37\", \"#D92120\"),   theme = ggplot2::theme_dark() )  p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = extr,   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05,   color_p = \"white\",   alpha_p = 0.5,   alpha_gradient = 0.2,   color_gradient = c(\"#404096\", \"#529DB7\", \"#7DB874\", \"#E39C37\", \"#D92120\"),   theme = ggplot2::theme_dark() )  # Explore extrapolation only in the environmental space p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = extr,   projection_data = somevar,   geo_space = FALSE,   prop_points = 0.05,   color_p = \"black\",   color_gradient = c(\"#085CF8\", \"#65AF1E\", \"#F3CC1D\", \"#FC6A9B\", \"#D70500\"),   theme = ggplot2::theme_minimal() )   ## %######################################################%## ####                 Explore univariate                 #### ####          and combinatorial extrapolation           #### ## %######################################################%## extr <-   extra_eval(     training_data = sp_pa_2,     pr_ab = \"pr_ab\",     projection_data = somevar,     metric = \"mahalanobis\",     univar_comb = TRUE,     n_cores = 1,     aggreg_factor = 1   )  plot(extr)   p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = extr$uni_comb, # use  uni_comb layer   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05,   color_gradient = c(\"#B3DC2B\", \"#25818E\") )  ## %######################################################%## ####           With p_extra also is possible            #### ####       to explore the patterns of suitability       #### ## %######################################################%##  sp_pa_2 <- part_random(   data = sp_pa_2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  rf_m1 <- fit_raf(   data = sp_pa_2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sorensen\") )  suit <- sdm_predict(models = rf_m1, pred = somevar) plot(suit$raf) suit <- suit$raf  # Pasterns of suitability in geographical and environmental space p_extra(   training_data = sp_pa_2,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = suit,   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05, )  # Pasterns of suitability plotting as points only presences p_extra(   training_data = sp_pa_2 %>%     dplyr::filter(pr_ab == 1),   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = suit,   projection_data = somevar,   geo_space = TRUE,   prop_points = 0.05, )  # Pasterns of suitability in the environmental space only # and plotting as points only presences p_extra(   training_data = sp_pa_2 %>%     dplyr::filter(pr_ab == 1),   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   extra_suit_data = suit,   projection_data = somevar,   geo_space = FALSE,   prop_points = 0.05, ) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_pdp.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Dependent Plot — p_pdp","title":"Partial Dependent Plot — p_pdp","text":"Create partial dependence plot(s) explore marginal effect predictors suitability","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_pdp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Dependent Plot — p_pdp","text":"","code":"p_pdp(   model,   predictors = NULL,   resolution = 100,   resid = FALSE,   training_data = NULL,   projection_data = NULL,   clamping = FALSE,   rug = FALSE,   colorl = c(\"#462777\", \"#6DCC57\"),   colorp = \"black\",   alpha = 0.2,   theme = ggplot2::theme_classic() )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_pdp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Dependent Plot — p_pdp","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector predictor name(s) calculate partial dependence plots. NULL predictors used. Default NULL resolution numeric. Number equally spaced points predict suitability values continuous predictors. Default 50 resid logical. Calculate residuals based training data. Default FALSE training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL projection_data SpatRaster. Raster layer environmental variables used model projection. argument used, function calculate partial dependence curves distinguishing conditions used training projection conditions (.e., projection data present projection area training). Default NULL clamping logical. Perform clamping. maxent models. Default FALSE rug logical. Display training data rug plot x-axis. Note: time-consuming large databases. Default FALSE colorl character. vector one two colors used color lines. projection_data argument used necessary provide two colors. Default c(\"#462777\", \"#6DCC57\") colorp character. vector one color used color points residuals, Default \"black\" alpha numeric. value 0 1 control transparency residual points. Lower values corresponding transparent colors. Default 0.2 theme ggplot2 theme. Default ggplot2::theme_classic()","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_pdp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Dependent Plot — p_pdp","text":"function creates partial dependent plots explore marginal effect predictors suitability. projection_data used, function extract minimum maximum values found region time period model projected. range projection data greater training data plotted different color. Partial dependence curves used interpret model explore model may extrapolate outside environmental conditions used train model.","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_pdp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Dependent Plot — p_pdp","text":"","code":"if (FALSE) { # \\dontrun{ library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  # set seed abies2 <- abies %>%   dplyr::select(x, y, pr_ab) %>%   dplyr::group_by(pr_ab) %>%   dplyr::slice_sample(prop = 0.5)  abies2 <- sdm_extract(abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  # Partial depence plot p_pdp(model = svm_t1$model, training_data = abies2) p_pdp(model = svm_t1$model, training_data = abies2, predictors = c(\"aet\", \"cwd\")) p_pdp(model = svm_t1$model, training_data = abies2, resolution = 5) p_pdp(model = svm_t1$model, training_data = abies2, resolution = 50) p_pdp(model = svm_t1$model, training_data = abies2, resid = TRUE) p_pdp(   model = svm_t1$model, training_data = abies2, resid = TRUE,   colorl = \"black\", colorp = \"red\", alpha = 0.1 ) p_pdp(   model = svm_t1$model, training_data = abies2, resid = TRUE,   colorl = \"black\", colorp = \"red\", alpha = 0.1, rug = TRUE )  # Partial depence plot for training and projection condition found in a projection area plot(somevar[[1]], main = \"Projection area\") p_pdp(model = svm_t1$model, training_data = abies2, projection_data = somevar) p_pdp(   model = svm_t1$model, training_data = abies2, projection_data = somevar,   colorl = c(\"#CC00FF\", \"#CCFF00\") ) p_pdp(   model = svm_t1$model, training_data = abies2, projection_data = somevar,   colorl = c(\"#CC00FF\", \"#CCFF00\"), resid = TRUE, colorp = \"gray\" ) p_pdp(   model = svm_t1$model, training_data = abies2, projection_data = somevar,   colorl = c(\"#CC00FF\", \"#CCFF00\"), resid = TRUE, colorp = \"gray\", rug = TRUE,   theme = ggplot2::theme_dark() ) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_psp.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Dependent Suface Plot — p_psp","title":"Partial Dependent Suface Plot — p_psp","text":"Create partial dependence surface plot(s) explore bivariate marginal effect predictors suitability","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_psp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Dependent Suface Plot — p_psp","text":"","code":"p_psp(   model,   predictors = NULL,   resolution = 50,   training_data = NULL,   pchull = FALSE,   projection_data = NULL,   clamping = FALSE,   color_gradient = c(\"#000004\", \"#1B0A40\", \"#4A0C69\", \"#781B6C\", \"#A42C5F\", \"#CD4345\",     \"#EC6824\", \"#FA990B\", \"#F7CF3D\", \"#FCFFA4\"),   color_chull = \"white\",   theme = ggplot2::theme_classic() )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_psp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Dependent Suface Plot — p_psp","text":"model model object class \"gam\", \"gbm\", \"glm\", \"graf\", \"ksvm\", \"ksvm\", \"maxnet”, “nnet\", \"randomForest\" model can found first element list returned function fit_, tune_, esm_ function families predictors character. Vector predictor names calculate partial dependence plots. NULL predictors used. Default NULL resolution numeric. Number equally spaced points predict suitability values continuous predictors. Default 50 training_data data.frame. Database response (0,1) predictor values used fit model. Default NULL pchull logical. Plot convex-hull limit training data. Default FALSE. TRUE necessary provide data training_data argument projection_data SpatRaster. Raster layer environmental variables used model projection. Default NULL clamping logical. Perform clamping. maxent models. Default FALSE color_gradient character. vector range colors plot. Default c(\"#FDE725\", \"#B3DC2B\", \"#6DCC57\", \"#36B677\", \"#1F9D87\", \"#25818E\", \"#30678D\", \"#3D4988\", \"#462777\", \"#440154\") color_chull character. vector one color used color points residuals, Default \"white\" theme ggplot2 theme. Default ggplot2::theme_classic()","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_psp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Dependent Suface Plot — p_psp","text":"function creates partial dependent surface plots explore bivariate marginal effect predictors suitability. projection_data used, function extract minimum maximum values found region time period model projected. Partial dependence surface plot used interpret model explore model extrapolate outside environmental conditions used train model (convex hull polygon).","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/p_psp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Dependent Suface Plot — p_psp","text":"","code":"if (FALSE) { library(terra) library(dplyr)  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") data(abies)  # set seed abies2 <- abies %>%   dplyr::select(x, y, pr_ab) %>%   dplyr::group_by(pr_ab) %>%   dplyr::slice_sample(prop = 0.5)  abies2 <- sdm_extract(abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   partition = \".part\",   thr = c(\"max_sens_spec\") )  # Partial depence surface plot p_psp(model = svm_t1$model, training_data = abies2) p_psp(model = svm_t1$model, training_data = abies2, predictors = c(\"aet\", \"cwd\")) p_psp(model = svm_t1$model, training_data = abies2, resolution = 10) p_psp(model = svm_t1$model, training_data = abies2, resolution = 70) p_psp(model = svm_t1$model, training_data = abies2, pchull = TRUE) p_psp(   model = svm_t1$model, training_data = abies2, pchull = TRUE,   color_chull = \"orange\",   color_gradient = c(\"#00007F\", \"#007FFF\", \"#7FFF7F\", \"#FF7F00\", \"#7F0000\") )  # Partial depence surface plot for training and projection condition plot(somevar[[1]], main = \"Projection area\") p_psp(model = svm_t1$model, training_data = abies2, projection_data = somevar, pchull = TRUE)   # PSP with categorical variables somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar) # environmental data names(somevar) <- c(\"aet\", \"cwd\", \"tmx\", \"tmn\") cat <- system.file(\"external/clusters.shp\", package = \"flexsdm\") cat <- terra::vect(cat) cat$clusters <- paste0(\"c\", cat$clusters) cat <- terra::rasterize(cat, somevar, field = \"clusters\") somevar <- c(somevar, cat) plot(somevar)  # set seed abies2 <- abies %>%   dplyr::select(x, y, pr_ab) %>%   dplyr::group_by(pr_ab) %>%   dplyr::slice_sample(prop = 0.5)  abies2 <- sdm_extract(   data = abies2,   x = \"x\",   y = \"y\",   env_layer = somevar ) abies2 <- part_random(abies2,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  svm_t1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"cwd\", \"tmx\", \"tmn\"),   predictors_f = \"clusters\",   partition = \".part\",   thr = c(\"max_sens_spec\") )  p_psp(model = svm_t1$model, training_data = abies2) }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_background.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample background points — sample_background","title":"Sample background points — sample_background","text":"Sampling background points options using different geographical restrictions sampling methods.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_background.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample background points — sample_background","text":"","code":"sample_background(   data,   x,   y,   n,   method = \"random\",   rlayer,   maskval = NULL,   calibarea = NULL,   rbias = NULL,   sp_name = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_background.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample background points — sample_background","text":"data data.frame tibble. Database presences records, coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates n integer. Number background point sampled method character. Background allocation method. methods implemented : random: Random allocation background points. Usage method = 'random' thickening: Thickening background points based Vollering et al. (2019) method. method, buffer width must defined used around presences points. buffer can defined using argument method = c(\"thickening\", width = 20000). Buffer width must m raster (used rlayer) longitude/latitude CRS, map units cases. buffer width provided function use width value equal mean pair-wise presence distances. width value provided, argument must used method = 'thickening'. biased: method, similar \"thickening\", sample background biased bias presences. However, background points sampled used presences probability throughout entire study area, restricting bias within buffers “thickening” approach. using method, necessary provide layer presences bias \"rbias\" argument (Phillips et al., 2009). Usage method='thickening' method = c(\"thickening\", width = 20000). Default 'random' rlayer SpatRaster used sampling background points. best use layer resolution extent environmental variables used modeling. using maskval argument, raster layer must contain values  constrain sampling maskval integer, character, factor. Values raster layer used constraining sampling background points calibarea SpatVect delimits calibration area used given species (see calib_area function). rbias SpatRaster used choosing background points using bias method. raster bias data must provided. recommended rbias match resolution extent rlayer. sp_name character. Species name output used. argument used, first output column species name. Default NULL.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_background.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample background points — sample_background","text":"tibble object x y coordinates sampled background points","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_background.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample background points — sample_background","text":"Phillips, S. J., Dudík, M., Elith, J., Graham, C. H., Lehmann, ., Leathwick, J., & Ferrier, S. (2009). Sample selection bias presence-distribution models: Implications background pseudo-absence data. Ecological Applications, 19(1), 181-197. Vollering, J., Halvorsen, R., Auestad, ., & Rydgren, K. (2019). Bunching background betters bias species distribution models. Ecography, 42(10), 1717-1727. https://doi.org/10.1111/ecog.04503","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_background.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample background points — sample_background","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr) data(spp) somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Example for a single species spp_pa <- spp %>% dplyr::filter(species == \"sp3\")  # Spatially structured partition part <- part_sblock(   env_layer = somevar,   data = spp_pa,   x = \"x\",   y = \"y\",   pr_ab = \"pr_ab\",   min_res_mult = 100,   max_res_mult = 500,   num_grids = 30,   min_occ = 5,   n_part = 2 )  grid_env <- get_block(env_layer = somevar, best_grid = part$grid) plot(grid_env)   ## %######################################################%## #                                                          # ####             Random background method               #### #                                                          # ## %######################################################%##  # Sample background points throughout study area with random sampling method spp_p <- spp_pa %>% dplyr::filter(pr_ab == 1) bg <-   sample_background(     data = spp_p,     x = \"x\",     y = \"y\",     n = 1000,     method = \"random\",     rlayer = grid_env,     sp_name = \"sp3\"   )  bg plot(grid_env) points(bg[-1])  # Sample random background points constrained to a region with a give set of values plot(grid_env) sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 1000,   method = \"random\",   rlayer = grid_env,   maskval = 1 ) %>% points()  plot(grid_env) sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 1000,   method = \"random\",   rlayer = grid_env,   maskval = 2 ) %>% points()  plot(grid_env) sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 1000,   method = \"random\",   rlayer = grid_env,   maskval = c(1, 2) ) %>% points()  # Sample random background within a calibration area and constrained to a region ca_ps1 <- calib_area(   data = spp_pa,   x = \"x\",   y = \"y\",   method = c(\"buffer\", width = 50000),   crs = crs(somevar) ) plot(grid_env) plot(ca_ps1, add = T) points(spp_pa[-1], col = \"blue\", cex = 0.7, pch = 19) sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 1000,   method = \"random\",   rlayer = grid_env,   maskval = 1,   calibarea = ca_ps1 ) %>%   points(col = \"red\")    ## %######################################################%## #                                                          # ####            Thickening background method            #### #                                                          # ## %######################################################%##  # Thickening background without constraining them spp_p # presences database of a species grid_env # The raster layer used for sampling background bg <- sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 5000,   method = \"thickening\",   rlayer = grid_env, )  plot(grid_env) bg %>%   points(col = \"red\")   # Thickening background spp_p # presences database of a species grid_env # The raster layer used for sampling background bg <- sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 5000,   method = c(\"thickening\", width = 150000),   rlayer = grid_env )  plot(grid_env) bg %>%   points(col = \"red\")  # Sample thickening background within a calibration area and constrained to a region bg <- sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 3000,   method = \"thickening\",   rlayer = grid_env,   maskval = 2,   calibarea = ca_ps1 )  plot(grid_env) plot(ca_ps1, add = T) bg %>%   points(col = \"red\", cex = 0.3) points(spp_p[c(\"x\", \"y\")], pch = 19)  ## %######################################################%## #                                                          # ####             Biased background method               #### #                                                          # ## %######################################################%## require(dplyr) require(terra) data(spp)  # Select the presences of a species spp_p <- spp %>% dplyr::filter(species == \"sp1\", pr_ab == 1)  # Raster layer with density of points to obtain a biased sampling background occ_density <- system.file(\"external/occ_density.tif\", package = \"flexsdm\") occ_density <- terra::rast(occ_density) plot(occ_density) points(spp_p %>% dplyr::select(x, y), cex = 0.5)  # A layer with region used to contrain background sampling area regions <- system.file(\"external/regions.tif\", package = \"flexsdm\") regions <- terra::rast(regions) plot(regions) points(spp_p %>% dplyr::select(x, y), cex = 0.5)   # Biased background points spp_p # presences database of a species bg <- sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 3000,   method = \"biased\",   rlayer = regions,   rbias = occ_density )  plot(occ_density) bg %>%   points(col = \"red\", cex = 0.1) spp_p %>%   dplyr::select(x, y) %>%   points(., col = \"black\", pch = 19, cex = 0.5)   # Biased background points constrained to a region # It will be selected region 6 plot(regions) plot(regions %in% c(1, 6))  bg <- sample_background(   data = spp_p,   x = \"x\",   y = \"y\",   n = 500,   method = \"biased\",   rlayer = regions,   rbias = occ_density,   maskval = c(1, 2) )  plot(occ_density) bg %>%   points(col = \"red\", cex = 0.5) spp_p %>%   dplyr::select(x, y) %>%   points(., col = \"black\", pch = 19, cex = 0.5) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_pseudoabs.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample pseudo-absences — sample_pseudoabs","title":"Sample pseudo-absences — sample_pseudoabs","text":"function provide several methods sampling pseudo-absences, instance totally random sampling method, options using different environmental geographical constraints.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_pseudoabs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample pseudo-absences — sample_pseudoabs","text":"","code":"sample_pseudoabs(   data,   x,   y,   n,   method,   rlayer,   maskval = NULL,   calibarea = NULL,   sp_name = NULL )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_pseudoabs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample pseudo-absences — sample_pseudoabs","text":"data data.frame tibble. Database presences (presence-absence, presences-pseudo-absence) records, coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates n integer. Number pseudo-absences sampled method character. Pseudo-absence allocation method. necessary provide vector argument. methods implemented : random: Random allocation pseudo-absences throughout area used model fitting. Usage method='random'. kmeans: Pseudo-absences sampled randomly within environmental clusters defined K-means cluster analysis (number clusters equal number pseudo-absences defined 'n'). method, necessary provide raster object environmental variables. Usage method = c('kmeans', env = somevar). throughout area used model fitting. Usage method='random'. env_const: Pseudo-absences environmentally constrained regions lower suitability values predicted Bioclim model. method, necessary provide raster object environmental variables Usage method=c(method='env_const', env = somevar). geo_const: Pseudo-absences allocated far occurrences based geographical buffer. value buffer width m must provided raster (used rlayer) longitude/latitude CRS, map units cases. Usage method=c('geo_const', width='50000'). geo_env_const: Pseudo-absences constrained environmentally (based Bioclim model) distributed geographically far occurrences based geographical buffer. method, raster environmental variables stored SpatRaster object provided. value buffer width m must provided raster (used rlayer) longitude/latitude CRS, map units cases. Usage method=c('geo_env_const', width='50000', env = somevar). geo_env_km_const: Pseudo-absences constrained using three-level procedure; similar geo_env_const additional step distributes pseudo-absences environmental space using K-means cluster analysis. method, necessary provide raster object environmental variables value buffer width m raster (used rlayer) longitude/latitude CRS, map units cases. Usage method=c('geo_env_km_const', width='50000', env = somevar). rlayer SpatRaster. raster layer used sampling pseudo-absence layer resolution extent environmental variables used modeling recommended. case use maskval argument, raster layer must contain values used constrain sampling maskval integer, character, factor. Values raster layer used constraining pseudo-absence sampling calibarea SpatVector SpatVector delimit calibration area used given species (see calib_area function). sp_name character. Species name output used. argument used, first output column species name. Default NULL.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_pseudoabs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample pseudo-absences — sample_pseudoabs","text":"tibble object x y coordinates sampled pseudo-absence points","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/sample_pseudoabs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample pseudo-absences — sample_pseudoabs","text":"","code":"if (FALSE) { # \\dontrun{ require(terra) require(dplyr) data(\"spp\")  somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  regions <- system.file(\"external/regions.tif\", package = \"flexsdm\") regions <- terra::rast(regions)  plot(regions)   single_spp <-   spp %>%   dplyr::filter(species == \"sp3\") %>%   dplyr::filter(pr_ab == 1) %>%   dplyr::select(-pr_ab)   # Pseudo-absences randomly sampled throughout study area ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = \"random\",     rlayer = regions,     maskval = NULL,     sp_name = \"sp3\"   ) plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) # presences points(ps1[-1], col = \"red\", cex = 0.7, pch = 19) # absences   # Pseudo-absences randomly sampled within a regions where a species occurs ## Regions where this species occurrs samp_here <- terra::extract(regions, single_spp[2:3])[, 2] %>%   unique() %>%   na.exclude()  ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = \"random\",     rlayer = regions,     maskval = samp_here   )  plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) points(ps1, col = \"red\", cex = 0.7, pch = 19)  # Pseudo-absences sampled with K-means approach set.seed(123) ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = c(method='kmeans', env = somevar),     rlayer = regions   )  plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) points(ps1, col = \"red\", cex = 0.7, pch = 19)  # Pseudo-absences sampled with geographical constraint ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = c(\"geo_const\", width = \"30000\"),     rlayer = regions,     maskval = samp_here   ) plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) points(ps1, col = \"red\", cex = 0.7, pch = 19)  # Pseudo-absences sampled with environmental constraint ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = c(\"env_const\", env = somevar),     rlayer = regions,     maskval = samp_here   ) plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) points(ps1, col = \"red\", cex = 0.7, pch = 19)  # Pseudo-absences sampled with environmental and geographical constraint ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = c(\"geo_env_const\", width = \"50000\", env = somevar),     rlayer = regions,     maskval = samp_here   ) plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) points(ps1, col = \"red\", cex = 0.7, pch = 19)  # Pseudo-absences sampled with environmental and geographical constraint and with k-mean clustering ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 10,     method = c(\"geo_env_km_const\", width = \"50000\", env = somevar),     rlayer = regions,     maskval = samp_here   ) plot(regions, col = gray.colors(9)) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) points(ps1, col = \"red\", cex = 0.7, pch = 19)  # Sampling pseudo-absence using a calibration area ca_ps1 <- calib_area(   data = single_spp,   x = \"x\",   y = \"y\",   method = c(\"buffer\", width = 50000),   crs = crs(somevar) ) plot(regions, col = gray.colors(9)) plot(ca_ps1, add = T) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19)  ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 50,     method = \"random\",     rlayer = regions,     maskval = NULL,     calibarea = ca_ps1   ) plot(regions, col = gray.colors(9)) plot(ca_ps1, add = T) points(ps1, col = \"red\", cex = 0.7, pch = 19) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19)   ps1 <-   sample_pseudoabs(     data = single_spp,     x = \"x\",     y = \"y\",     n = nrow(single_spp) * 50,     method = \"random\",     rlayer = regions,     maskval = samp_here,     calibarea = ca_ps1   ) plot(regions, col = gray.colors(9)) plot(ca_ps1, add = T) points(ps1, col = \"red\", cex = 0.7, pch = 19) points(single_spp[-1], col = \"blue\", cex = 0.7, pch = 19) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Create directories for saving the outputs of the flexsdm — sdm_directory","title":"Create directories for saving the outputs of the flexsdm — sdm_directory","text":"function assists creating directory system different sub-folders assist organisation modelling process outputs.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create directories for saving the outputs of the flexsdm — sdm_directory","text":"","code":"sdm_directory(   main_dir = NULL,   projections = NULL,   calibration_area = TRUE,   algorithm = NULL,   ensemble = NULL,   threshold = FALSE,   return_vector = TRUE )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_directory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create directories for saving the outputs of the flexsdm — sdm_directory","text":"main_dir character. Directory path containing main folder saving model inputs outputs. NULL function assumes directory path current working R session creates sub-folder name 'flexsdm_results'. Default NULL projections vector. Vector folder names future scenarios/different regions/time periods save model projections output. calibration_area logical. TRUE, function creates folder 1_Inputs storing calibration area. Default TRUE algorithm vector. Vector model names used. Usage algorithm = c(gam, tune_max, tune_net, esm_glm).  \"\" used function creates folders algorithms available flexsdm . .e. 'gam', 'gau', 'gbm', 'glm', 'max', 'net', 'raf', 'svm'. Default NULL ensemble vector. Vector methods used ensemble different models. Usage ensemble = c(\"mean\", \"meanthr\"). Default NULL threshold logical. TRUE sub-folders \"/1_con\", \"/2_bin\" created within algorithm /ensemble folder. Used storing continuous binarized models separately. Default FALSE return_vector logical. TRUE function returns vector path folders. Default TRUE","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_directory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create directories for saving the outputs of the flexsdm — sdm_directory","text":"character vector paths created folders","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_directory.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create directories for saving the outputs of the flexsdm — sdm_directory","text":"sdm_directory function assists saving workflow outputs creating folders (directories) based user specifications, choice algorithms, ensemble methods, model projections new geographic regions periods. function first creates two folders within user-specified project folder, one model inputs (1_Inputs) one model outputs (2_Outputs). Within 1_Inputs, three sub-folders users store model inputs: 1_Occurrences, 2_Predictors, 3_Calibration_area. user chooses include projections modeling framework, 2_Projections subfolder created within 2_Predictors folder store environmental data projection scenarios provided \"projections\" argument. Additionally, sdm_directory offers users enhanced flexibility saving modeling outputs, giving offers users option save results modeling ensemble technique presented flexsdm","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_directory.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create directories for saving the outputs of the flexsdm — sdm_directory","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) # require(sf)  # Implement sdm_directory without specific path and project name dirs_1 <- sdm_directory(   main_dir = NULL,   projections = NULL,   calibration_area = TRUE,   algorithm = c(\"gam\", \"tune_max\"),   ensemble = c(\"mean\", \"meanthr\"),   threshold = FALSE,   return_vector = TRUE ) dirs_1 dirs_1[1] %>% fs::dir_tree(., recurse = TRUE)  unlink(dirs_1[1], recursive = TRUE) # this directory and sub-folder will be removed  # Implement sdm_directory with specific path and project name getwd() %>% dirname()  dirs_2 <- sdm_directory(   main_dir = getwd() %>% dirname() %>% file.path(., \"my_project_name\"),   projections = c(     \"cnrm_rpc8.5_2050\",     \"cnrm_rpc4.5_2050\"   ),   calibration_area = TRUE,   algorithm = \"all\",   ensemble = c(\"mean\", \"meanthr\"),   threshold = TRUE ) dirs_2[1] %>% fs::dir_tree(., recurse = TRUE) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate different model performance metrics — sdm_eval","title":"Calculate different model performance metrics — sdm_eval","text":"function calculates threshold dependent independent model performance metrics.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate different model performance metrics — sdm_eval","text":"","code":"sdm_eval(p, a, bg = NULL, thr = NULL)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate different model performance metrics — sdm_eval","text":"p numeric. Predicted suitability presences numeric. Predicted suitability absences bg numeric. Predicted suitability background points, used BOYCE metric. bg set NULL, BOYCE metric calculated presences absences suitabilities values thr character. Threshold criterion used get binary suitability values (.e. 0,1). Used threshold-dependent performance metrics. possible use one threshold type. vector must provided argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold Sensitivity Specificity equal. max_sens_spec: Threshold sum Sensitivity Specificity highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified Sensitivity value. Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers Sensitivity value. sensitivity value specified, default value 0.9 one threshold type used, concatenate threshold types, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold type specified","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate different model performance metrics — sdm_eval","text":"tibble next columns threshold: threshold names thr_value: threshold values n_presences: number presences n_absences: number absences TPR IMAE: performance metrics","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_eval.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate different model performance metrics — sdm_eval","text":"function used evaluating different models approaches base combination presence-absences presence-pseudo-absences background point data suitability predicted model flexsdm modeling function families (fit_, esm_, tune_.) calculates next performance metric: \\* BOYCE calculated based presences background points, case background points provided calculated using presences absences. codes calculating metric adaptation enmSdm package (https://github.com/adamlilith/enmSdm) \\** IMAE calculated 1-(Mean Absolute Error) order consistent metrics higher value given performance metric, greater model's accuracy","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate different model performance metrics — sdm_eval","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr)  set.seed(0) p <- rnorm(50, mean = 0.7, sd = 0.3) %>% abs() p[p > 1] <- 1 p[p < 0] <- 0  set.seed(0) a <- rnorm(50, mean = 0.3, sd = 0.2) %>% abs() a[a > 1] <- 1 a[a < 0] <- 0  set.seed(0) backg <- rnorm(1000, mean = 0.4, sd = 0.4) %>% abs() backg[backg > 1] <- 1 backg[backg < 0] <- 0  # Function use without threshold specification e <- sdm_eval(p, a) e  # Function use with threshold specification sdm_eval(p, a, thr = \"max_sorensen\") sdm_eval(p, a, thr = c(\"lpt\", \"max_sens_spec\", \"max_jaccard\")) sdm_eval(p, a, thr = c(\"lpt\", \"max_sens_spec\", \"sensitivity\")) sdm_eval(p, a, thr = c(\"lpt\", \"max_sens_spec\", \"sensitivity\", sens = \"0.95\"))  # Use of bg argument (it will only be used for calculating BOYCE index) sdm_eval(p, a, thr = \"max_sens_spec\") sdm_eval(p, a, thr = c(\"max_sens_spec\"), bg = backg)  # If background will be used to calculate all other metrics # background values can be used in \"a\" argument sdm_eval(p, backg, thr = \"max_sens_spec\") } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract environmental data values from a spatial raster based on x and y coordinates — sdm_extract","title":"Extract environmental data values from a spatial raster based on x and y coordinates — sdm_extract","text":"Extract environmental data values spatial raster based x y coordinates","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract environmental data values from a spatial raster based on x and y coordinates — sdm_extract","text":"","code":"sdm_extract(data, x, y, env_layer, variables = NULL, filter_na = TRUE)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract environmental data values from a spatial raster based on x and y coordinates — sdm_extract","text":"data data.frame. Database species presence, presence-absence, pseudo-absence records x y coordinates x character. Column name spatial x coordinates y character. Column name spatial y coordinates env_layer SpatRaster. Raster raster stack environmental variables. variables character. Vector variable names predictor (environmental) variables Usage variables. = c(\"aet\", \"cwd\", \"tmin\"). variable specified, function return data layers. Default NULL filter_na logical. filter_na = TRUE (default), rows NA values environmental variables removed returned tibble.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract environmental data values from a spatial raster based on x and y coordinates — sdm_extract","text":"tibble returns original data base additional columns extracted environmental variables xy location SpatRaster object used 'env_layer'","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_extract.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract environmental data values from a spatial raster based on x and y coordinates — sdm_extract","text":"","code":"if (FALSE) { # \\dontrun{ require(terra)  # Load datasets data(spp) f <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(f)  # Extract environmental data from somevar for all locations in spp ex_spp <-   sdm_extract(     data = spp,     x = \"x\",     y = \"y\",     env_layer = somevar,     variables = NULL,     filter_na = FALSE   )  # Extract environmental for two variables and remove rows with NAs ex_spp2 <-   sdm_extract(     data = spp,     x = \"x\",     y = \"y\",     env_layer = somevar,     variables = c(\"CFP_3\", \"CFP_4\"),     filter_na = TRUE   )  ex_spp ex_spp2 } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial predictions from individual and ensemble models — sdm_predict","title":"Spatial predictions from individual and ensemble models — sdm_predict","text":"function allows geographical prediction one models constructed fit_ tune_ function set, models fitted esm_ function set (.e., ensemble small models approach), models constructed fit_ensemble function. can return continuous continuous binary predictions one thresholds","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial predictions from individual and ensemble models — sdm_predict","text":"","code":"sdm_predict(   models,   pred,   nchunk = 1,   thr = NULL,   con_thr = FALSE,   predict_area = NULL,   clamp = TRUE,   pred_type = \"cloglog\" )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial predictions from individual and ensemble models — sdm_predict","text":"models list one models fitted fit_ tune_ functions. case use models fitted fit_ensemble esm_ family function one model used. Usage models = mglm models = list(mglm, mraf, mgbm) pred SpatRaster. Raster layer predictor variables. Names layers must exactly match used model fitting. nchunk integer. Number chunks split data used predict models (.e., SpatRaster used pred argument). Predicting models chunks helps reduce memory requirements cases models predicted large scales high resolution. Default = 1 thr character. Threshold used get binary suitability values (.e., 0,1). possible use one threshold type. mandatory use threshold/s used fit models. following threshold types available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB highest. sensitivity: Threshold based specified sensitivity value used fit models. : threshold used model outputs used 'models' argument used. Usage thr = c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity'), thr=''. threshold specified (.e., thr = NULL) function return continuous prediction . Default NULL con_thr logical. true predictions suitability values threshold/s returned. Default = FALSE predict_area SpatVector, SpatialPolygon, SpatialPolygonDataFrame. Spatial polygon used restring prediction given region. Default = NULL clamp logical. set TRUE, predictors features restricted range seen model training. valid Maxent model (see tune_mx fit_mx). Default TRUE. pred_type character. Type response required available \"link\", \"exponential\", \"cloglog\" \"logistic\". valid Maxent model (see tune_mx fit_mx). Default \"cloglog\".","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial predictions from individual and ensemble models — sdm_predict","text":"list SpatRaster continuous /binary predictions","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatial predictions from individual and ensemble models — sdm_predict","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) require(terra)  data(\"spp\") somevar <- system.file(\"external/somevar.tif\", package = \"flexsdm\") somevar <- terra::rast(somevar)  # Extract data some_sp <- spp %>%   filter(species == \"sp3\")  some_sp <-   sdm_extract(     data = some_sp,     x = \"x\",     y = \"y\",     env_layer = somevar   )  # Partition some_sp <- part_random(   data = some_sp,   pr_ab = \"pr_ab\",   method = c(method = \"rep_kfold\", folds = 3, replicates = 5) )   ## %######################################################%## #                                                          # ####          Create different type of models           #### #                                                          # ## %######################################################%## # Fit some models mglm <- fit_glm(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\",   poly = 2 ) mraf <- fit_raf(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\", ) mgbm <- fit_gbm(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\" )  # Fit an ensemble model mensemble <- fit_ensemble(   models = list(mglm, mraf, mgbm),   ens_method = \"meansup\",   thr = NULL,   thr_model = \"max_sens_spec\",   metric = \"TSS\" )  # Fit a model with the Ensembles of Small Models approach # Without threshold specification and with kfold msmall <- esm_gam(   data = some_sp,   response = \"pr_ab\",   predictors = c(\"CFP_1\", \"CFP_2\", \"CFP_3\", \"CFP_4\"),   partition = \".part\",   thr = NULL )   ## %######################################################%## #                                                           # ####      Predict different kind of models               #### #                                                           # ## %######################################################%##  # sdm_predict can be used for predict one or more models fitted with fit_ or tune_ functions  # a single model ind_p <- sdm_predict(   models = mglm,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL )  # a list of models list_p <- sdm_predict(   models = list(mglm, mraf, mgbm),   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL )  # Predict an ensemble model # (only is possilbe use one fit_ensemble) ensemble_p <- sdm_predict(   models = mensemble,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL )  # Predict an ensemble of small models # (only is possible to use one ensemble of small models) small_p <- sdm_predict(   models = msmall,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL )  ## %######################################################%## #                                                          # ####              Predict model using chunks            #### #                                                          # ## %######################################################%## # Predicting models in chunks helps reduce memory requirements in # cases where models are predicted for large scales and high resolution  ind_p <- sdm_predict(   models = mglm,   pred = somevar,   thr = \"max_fpb\",   con_thr = FALSE,   predict_area = NULL,   nchunk = 4 ) } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_summarize.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge model performance tables — sdm_summarize","title":"Merge model performance tables — sdm_summarize","text":"Merge model performance tables","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_summarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge model performance tables — sdm_summarize","text":"","code":"sdm_summarize(models)"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_summarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge model performance tables — sdm_summarize","text":"models list one models fitted fit_ tune_ functions, fit_ensemble output, esm_ family function output. list single several models fitted fit_ tune_ functions object returned fit_ensemble function. Usage models = list(mod1, mod2, mod3)","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_summarize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge model performance tables — sdm_summarize","text":"Combined model performance table input models. Models fit tune include model performance best hyperparameters.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_summarize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge model performance tables — sdm_summarize","text":"","code":"if (FALSE) { # \\dontrun{ data(abies) abies  # In this example we will partition the data using the k-fold method  abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  # Build a generalized additive model using fit_gam  gam_t1 <- fit_gam(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") )  gam_t1$performance  # Build a generalized linear model using fit_glm  glm_t1 <- fit_glm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   poly = 0,   inter_order = 0 )  glm_t1$performance  # Build a tuned random forest model using tune_raf  tune_grid <-   expand.grid(     mtry = seq(1, 7, 1),     ntree = c(300, 500, 700)   )  rf_t1 <-   tune_raf(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),     metric = \"TSS\",   )  rf_t1$performance  # Merge sdm performance tables  merge_df <- sdm_summarize(models = list(gam_t1, glm_t1, rf_t1))  merge_df } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_varimp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","title":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","text":"function calculates variable importance scores species distribution models (SDMs) based permutation-based approach.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_varimp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","text":"","code":"sdm_varimp(   models,   data,   response,   predictors,   n_sim = 50,   n_cores = 1,   thr = NULL,   clamp = TRUE,   pred_type = \"cloglog\" )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_varimp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","text":"models list one models fitted fit_ tune_ functions. case use models fitted fit_ensemble esm_ family function one model used. Usage models = mglm models = list(mglm, mraf, mgbm) data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names predictor variables. Usage predictors = c(\"aet\", \"cwd\", \"tmin\") n_sim integer. number Monte Carlo replications perform. Default 50. results replication averaged together (standard deviation also returned). n_cores numeric. Number cores use parallelization. Default 1 thr character. Threshold criterion used get binary suitability values (.e. 0,1). Used threshold-dependent performance metrics. possible use one threshold type. vector must provided argument. following threshold criteria available: lpt: highest threshold omission. equal_sens_spec: Threshold Sensitivity Specificity equal. max_sens_spec: Threshold sum Sensitivity Specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified Sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers   Sensitivity value. sensitivity value specified,    default value 0.9 #' one threshold type used, concatenate threshold types, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold type specified clamp logical. TRUE, predictors features restricted range seen model training. pred_type character. Type response required available \"link\", \"exponential\", \"cloglog\" \"logistic\". Default \"cloglog\"","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_varimp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","text":"tibble columns: model: model name threshold: threshold names predictors: predictor names TPR IMAE: performance metrics","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_varimp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","text":"function calculates variable importance scores species distribution models (SDMs) based permutation-based approach. Thus, function calculates model performance using original data permuted data. difference two performances variable importance score.","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/sdm_varimp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate permutation-based variable importance scores for SDMs — sdm_varimp","text":"","code":"if (FALSE) { # \\dontrun{ require(tidyr) require(dplyr)  data(abies) abies  data(backg) backg  # In this example we will partition the data using the k-fold method  abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  backg2 <- part_random(   data = backg,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  max_t1 <- fit_max(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   background = backg2,   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   clamp = TRUE,   classes = \"default\",   pred_type = \"cloglog\",   regmult = 1 )  net_t1 <- fit_net(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") )  svm_f1 <- fit_svm(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\") )  vip_t <- sdm_varimp(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"ppt_jja\", \"pH\", \"awc\", \"depth\", \"landform\"),   models = list(max_t1, net_t1, svm_f1),   clamp = TRUE,   pred_type = \"cloglog\",   thr = c(\"max_sens_spec\", \"equal_sens_spec\", \"max_sorensen\"),   n_sim = 50,   n_cores = 5 )  vip_t  # Plot the variable importance for AUC TSS and SORENSEN for the # threshold that maximizes Sorensen metric and Maxent vip_t %>%   pivot_longer(     cols = TPR:IMAE,     names_to = \"metric\",     values_to = \"value\"   ) %>%   dplyr::filter(threshold == \"max_sorensen\") %>%   dplyr::filter(metric %in% c(\"AUC\", \"TSS\", \"SORENSEN\")) %>%   dplyr::filter(model == \"max\") %>%   ggplot(aes(x = reorder(predictors, value), y = value, fill = predictors)) +   geom_col(     col = \"black\",     show.legend = FALSE   ) +   facet_wrap(~metric, scales = \"free_x\") +   labs(x = \"Predictors\", y = \"Variable Importance\") +   theme_classic() +   coord_flip() } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/spp.html","id":null,"dir":"Reference","previous_headings":"","what":"A data set containing presences and absences of three virtual species — spp","title":"A data set containing presences and absences of three virtual species — spp","text":"data set containing presences absences three virtual species","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/spp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data set containing presences and absences of three virtual species — spp","text":"","code":"spp"},{"path":"https://sjevelazco.github.io/flexsdm/reference/spp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data set containing presences and absences of three virtual species — spp","text":"tibble 1150 rows 3 variables: species virtual species names x longitude species occurrences y latitude species occurrences pr_ab presences absences denoted 1 0 respectively","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/spp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A data set containing presences and absences of three virtual species — spp","text":"","code":"if (FALSE) { # \\dontrun{ require(dplyr) data(\"spp\") spp } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_gbm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Generalized Boosted Regression models with exploration of hyper-parameters that optimize performance — tune_gbm","title":"Fit and validate Generalized Boosted Regression models with exploration of hyper-parameters that optimize performance — tune_gbm","text":"Fit validate Generalized Boosted Regression models exploration hyper-parameters optimize performance","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_gbm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Generalized Boosted Regression models with exploration of hyper-parameters that optimize performance — tune_gbm","text":"","code":"tune_gbm(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   grid = NULL,   thr = NULL,   metric = \"TSS\",   n_cores = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_gbm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Generalized Boosted Regression models with exploration of hyper-parameters that optimize performance — tune_gbm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments. Default NULL. partition character. Column name training validation partition groups. grid data.frame. data frame object algorithm hyper-parameter values tested. recommended generate data.frame grid() function. Hyper-parameters needed tuning 'n.trees', 'shrinkage', 'n.minobsinnode'. thr character. Threshold used get binary suitability values (.e. 0,1) needed threshold-dependent performance metrics. possible use one threshold type. Provide vector argument. following threshold types available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers   sensitivity value. sensitivity value specified, default used 0.9 one threshold type used must concatenate, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use threshold types threshold specified. metric character. Performance metric used selecting best combination hyper-parameter values. following metrics can used: SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, BOYCE. TSS used default. n_cores numeric. Number cores use parallelization. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_gbm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Generalized Boosted Regression models with exploration of hyper-parameters that optimize performance — tune_gbm","text":"list object : model: \"gbm\" class object gbm package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Hyper-parameter values performance metric (see sdm_eval) best hyper-parameter combination. performance_part: Performance metric replica partition (see sdm_eval). hyper_performance: Performance metric (see sdm_eval) combination hyper-parameters. data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_gbm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Generalized Boosted Regression models with exploration of hyper-parameters that optimize performance — tune_gbm","text":"","code":"if (FALSE) { # \\dontrun{ data(abies) abies  # Partition the data with the k-fold method  abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  # pr_ab is the name of the column with species presence and absences (i.e. the response variable) # from aet to landform are the predictors variables (landform is a qualitative variable)  # Hyper-parameter values for tuning tune_grid <-   expand.grid(     n.trees = c(20, 50, 100),     shrinkage = c(0.1, 0.5, 1),     n.minobsinnode = c(1, 3, 5, 7, 9)   )  gbm_t <-   tune_gbm(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\", \"ppt_jja\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = \"max_sens_spec\",     metric = \"TSS\",     n_cores = 1   )  # Outputs gbm_t$model gbm_t$predictors gbm_t$performance gbm_t$performance_part gbm_t$data_ens gbm_t$hyper_performance  # Graphical exploration of performance of each hyper-parameter setting require(ggplot2) pg <- position_dodge(width = 0.5) ggplot(gbm_t$hyper_performance, aes(factor(n.minobsinnode),   TSS_mean,   col = factor(shrinkage) )) +   geom_errorbar(aes(ymin = TSS_mean - TSS_sd, ymax = TSS_mean + TSS_sd),     width = 0.2, position = pg   ) +   geom_point(position = pg) +   geom_line(     data = gbm_t$tune_performance,     aes(as.numeric(factor(n.minobsinnode)),       TSS_mean,       col = factor(shrinkage)     ), position = pg   ) +   facet_wrap(. ~ n.trees) +   theme(legend.position = \"bottom\") } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","title":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","text":"Fit validate Maximum Entropy models exploration hyper-parameters optimize performance","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_max.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","text":"","code":"tune_max(   data,   response,   predictors,   predictors_f = NULL,   background = NULL,   partition,   grid = NULL,   thr = NULL,   metric = \"TSS\",   clamp = TRUE,   pred_type = \"cloglog\",   n_cores = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") background data.frame. Database response variable column containing 0 values, predictors variables. column names must consistent data partition character. Column name training validation partition groups. grid data.frame. data frame object algorithm hyper-parameters values tested. recommended generate data.frame grid() function. Hyper-parameters needed tuning 'regmult' 'classes' (combination following letters l -linear-, q  -quadratic-, h -hinge-, p -product-, t -threshold-). thr character. Threshold used get binary suitability values (.e. 0,1)., needed  threshold-dependent performance metrics. one threshold type can used.  necessary provide vector argument. following threshold types available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold # FPB (F-measure presence-background data)   highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers   sensitivity value.  sensitivity value specified, default 0.9 used. one threshold type used, concatenate , e.g., thr=c('lpt', 'max_sens_spec',  'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt',   'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. metric character. Performance metric used selecting best combination hyper -parameter values. One following metrics can used: SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, BOYCE. TSS used default. clamp logical. TRUE, predictors features restricted range seen model training. pred_type character. Type response required available \"link\", \"exponential\", \"cloglog\" \"logistic\". Default \"cloglog\" n_cores numeric. Number cores use parallelization. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_max.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","text":"list object : model: \"maxnet\" class object maxnet package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names)  variables use modeling. performance: Hyper-parameters values performance metrics (see sdm_eval) best hyper-parameters combination. performance_part: Performance metric replica partition (see sdm_eval). hyper_performance: Performance metrics (see sdm_eval) combination hyper-parameters. data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_max.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","text":"presence-absence (presence-pseudo-absence) data used data argument addition background points, function fit models presences background points validate presences absences. procedure makes maxent comparable presences-absences models (e.g., random forest, support vector machine). presences background points data used, function fit validate model presences background data. presence-absences used data argument without background, function fit model specified data (recommended).","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_max.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Maximum Entropy models with exploration of hyper-parameters that optimize performance — tune_max","text":"","code":"if (FALSE) { # \\dontrun{ data(\"abies\") data(\"backg\") abies # environmental conditions of presence-absence data backg # environmental conditions of background points  # Using k-fold partition method # Remember that the partition method, number of folds or replications must # be the same for presence-absence and background points datasets abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 3) ) abies2  set.seed(1) backg <- dplyr::sample_n(backg, size = 2000, replace = FALSE) backg2 <- part_random(   data = backg,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 3) ) backg   gridtest <-   expand.grid(     regmult = seq(0.1, 3, 0.5),     classes = c(\"l\", \"lq\", \"lqh\")   )  max_t1 <- tune_max(   data = abies2,   response = \"pr_ab\",   predictors = c(\"aet\", \"pH\", \"awc\", \"depth\"),   predictors_f = c(\"landform\"),   partition = \".part\",   background = backg2,   grid = gridtest,   thr = \"max_sens_spec\",   metric = \"TSS\",   clamp = TRUE,   pred_type = \"cloglog\",   n_cores = 2 # activate two cores to speed up this process )  length(max_t1) max_t1$model max_t1$predictors max_t1$performance max_t1$performance_part max_t1$data_ens } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Neural Networks models with exploration of hyper-parameters — tune_net","title":"Fit and validate Neural Networks models with exploration of hyper-parameters — tune_net","text":"Fit validate Neural Networks models exploration hyper-parameters","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Neural Networks models with exploration of hyper-parameters — tune_net","text":"","code":"tune_net(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   grid = NULL,   thr = NULL,   metric = \"TSS\",   n_cores = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Neural Networks models with exploration of hyper-parameters — tune_net","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variable names used must consistent used response, predictors, predictors_f arguments. Defaul NULL. partition character. Column name training validation partition groups. grid data.frame.  data frame object algorithm hyper-parameters values tested. recommended generate data.frame grid() function. thr character. Threshold used get binary suitability values (.e. 0,1), needed threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold types available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers   sensitivity value. specified sensitivity values, function use default   0.9. using one threshold type concatenate , e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. metric character. Performance metric used selecting best combination hyper-parameter values. One following metrics can used: SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, BOYCE. TSS used default. n_cores numeric. Number cores use parallelization. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Neural Networks models with exploration of hyper-parameters — tune_net","text":"list object : model: \"nnet\" class object nnet package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Hyper-parameters values performance metric (see sdm_eval) best hyper-parameters combination. performance_part: Performance metric replica partition (see sdm_eval). hyper_performance: Performance metric (see sdm_eval) combination hyper-parameters. data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Neural Networks models with exploration of hyper-parameters — tune_net","text":"","code":"if (FALSE) { # \\dontrun{ data(abies) abies  # Partitioning the data with the k-fold method  abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  # pr_ab columns is species presence and absences (i.e. the response variable) # from aet to landform are the predictors variables (landform is a qualitative variable)  # Hyper-parameter values for tuning tune_grid <-   expand.grid(     size = c(2, 4, 6, 8, 10),     decay = c(0.001, 0.05, 0.1, 1, 3, 4, 5, 10)   )  net_t <-   tune_net(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = \"max_sens_spec\",     metric = \"TSS\",     n_cores = 1   )  # Outputs net_t$model net_t$predictors net_t$performance net_t$performance_part net_t$hyper_performance net_t$data_ens } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_raf.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Random Forest models with exploration of hyper-parameters that optimize performance — tune_raf","title":"Fit and validate Random Forest models with exploration of hyper-parameters that optimize performance — tune_raf","text":"Fit validate Random Forest models exploration hyper-parameters optimize performance","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_raf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Random Forest models with exploration of hyper-parameters that optimize performance — tune_raf","text":"","code":"tune_raf(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   grid = NULL,   thr = NULL,   metric = \"TSS\",   n_cores = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_raf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Random Forest models with exploration of hyper-parameters that optimize performance — tune_raf","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variables used must consistent used response, predictors, predictors_f arguments. Default NULL partition character. Column name training validation partition groups. grid data.frame. data frame object algorithm hyper-parameters values tested. recommended generate data.frame grid() function. Hyper-parameter needed tuning 'mtry' 'ntree'. maximum mtry exceed total number predictors. thr character. Threshold used get binary suitability values (.e. 0,1), needed threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. following threshold types available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold FPB highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers   sensitivity value. specified sensitivity values, function use default   0.9 using one threshold type concatenate , e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified. metric character. Performance metric used selecting best combination hyper -parameter values. One following metrics can used: SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, BOYCE. TSS used default. n_cores numeric. Number cores use parallelization. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_raf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Random Forest models with exploration of hyper-parameters that optimize performance — tune_raf","text":"list object : model: \"randomForest\" class object randomForest package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names) variables use modeling. performance: Hyper-parameters values performance metric (see sdm_eval) best hyper-parameters combination. performance_part: Performance metric replica partition (see sdm_eval). hyper_performance: Performance metric (see sdm_eval) combination hyper-parameters. data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_raf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Random Forest models with exploration of hyper-parameters that optimize performance — tune_raf","text":"","code":"if (FALSE) { # \\dontrun{ data(abies) abies  # Partition the data with the k-fold method  abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  tune_grid <- expand.grid(   mtry = seq(1, 7, 1),   ntree = c(400, 600, 800) )  tune_grid  rf_t <-   tune_raf(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = \"max_sens_spec\",     metric = \"TSS\",     n_cores = 1   )  # Outputs rf_t$model rf_t$predictors rf_t$performance_part rf_t$hyper_performance rf_t$data_ens } # }"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_svm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and validate Support Vector Machine models with exploration of hyper-parameters that optimize performance — tune_svm","title":"Fit and validate Support Vector Machine models with exploration of hyper-parameters that optimize performance — tune_svm","text":"Fit validate Support Vector Machine models exploration hyper-parameters optimize performance","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_svm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and validate Support Vector Machine models with exploration of hyper-parameters that optimize performance — tune_svm","text":"","code":"tune_svm(   data,   response,   predictors,   predictors_f = NULL,   fit_formula = NULL,   partition,   grid = NULL,   thr = NULL,   metric = \"TSS\",   n_cores = 1 )"},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_svm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and validate Support Vector Machine models with exploration of hyper-parameters that optimize performance — tune_svm","text":"data data.frame. Database response (0,1) predictors values. response character. Column name species absence-presence data (0,1). predictors character. Vector column names quantitative predictor variables (.e. continuous variables). Usage predictors = c(\"aet\", \"cwd\", \"tmin\") predictors_f character. Vector column names qualitative predictor variables (.e. ordinal nominal variables type). Usage predictors_f = c(\"landform\") fit_formula formula. formula object response predictor variables (e.g. formula(pr_ab ~ aet + ppt_jja + pH + awc + depth + landform)). Note variable names used must consistent used response, predictors, predictors_f arguments. Default NULL partition character. Column name training validation partition groups. grid data.frame. Provide data frame object algorithm hyper-parameters values tested. recommended generate data.frame grid() function. Hyper-parameters  needed tuning 'size' 'decay'. thr character. Threshold used get binary suitability values (.e. 0,1). useful threshold-dependent performance metrics. possible use one threshold type. necessary provide vector argument. next threshold area available: lpt: highest threshold omission. equal_sens_spec: Threshold sensitivity specificity equal. max_sens_spec: Threshold sum sensitivity specificity   highest (aka threshold maximizes TSS). max_jaccard: threshold Jaccard index highest. max_sorensen: threshold Sorensen index highest. max_fpb: threshold # FPB (F-measure presence-background data) highest. sensitivity: Threshold based specified sensitivity value.   Usage thr = c('sensitivity', sens='0.6') thr = c('sensitivity'). 'sens' refers    sensitivity value. sensitivity value specified, default used 0.9. case use one threshold type necessary concatenate threshold types, e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), thr=c('lpt', 'max_sens_spec', 'sensitivity', sens='0.8'), thr=c('lpt', 'max_sens_spec', 'sensitivity'). Function use thresholds threshold specified metric character. Performance metric used selecting best combination hyper-parameter values. One following metrics can used: SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, BOYCE. TSS used default. n_cores numeric. Number cores use parallelization. Default 1","code":""},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_svm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and validate Support Vector Machine models with exploration of hyper-parameters that optimize performance — tune_svm","text":"list object : model: \"ksvm\" class object kernlab package. object can used predicting. predictors: tibble quantitative (c column names) qualitative (f column names)  variables use modeling. performance: Hyper-parameters values performance metric (see sdm_eval) best hyper-parameters combination. performance_part: Performance metric replica partition (see sdm_eval). hyper_performance: Performance metrics (see sdm_eval) combination hyper-parameters. data_ens: Predicted suitability test partition based best model. database used fit_ensemble","code":""},{"path":[]},{"path":"https://sjevelazco.github.io/flexsdm/reference/tune_svm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and validate Support Vector Machine models with exploration of hyper-parameters that optimize performance — tune_svm","text":"","code":"if (FALSE) { # \\dontrun{ data(abies) abies  # Partition the data with the k-fold method  abies2 <- part_random(   data = abies,   pr_ab = \"pr_ab\",   method = c(method = \"kfold\", folds = 5) )  # pr_ab column is species presence and absences (i.e. the response variable) # from aet to landform are the predictors variables (landform is a qualitative variable)  # Hyper-parameter values for tuning tune_grid <-   expand.grid(     C = c(2, 4, 8, 16, 20),     sigma = c(0.01, 0.1, 0.2, 0.3, 0.4)   )  svm_t <-   tune_svm(     data = abies2,     response = \"pr_ab\",     predictors = c(       \"aet\", \"cwd\", \"tmin\", \"ppt_djf\",       \"ppt_jja\", \"pH\", \"awc\", \"depth\"     ),     predictors_f = c(\"landform\"),     partition = \".part\",     grid = tune_grid,     thr = \"max_sens_spec\",     metric = \"TSS\",     n_cores = 1   )  # Outputs svm_t$model svm_t$predictors svm_t$performance svm_t$performance_part svm_t$hyper_performance svm_t$data_ens } # }"},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-138","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.8","title":"flexsdm 1.3.8","text":"fit_, tune_, esm_ fit_ensemble functions now return performance table partition replicate (performance_part), @sjevelazco #432 434 p_pdp improved depict exactly training range values projection data used, @sjevelazco #429 sample_pseudoabs sample approach implemented based environmental K-means, @sjevelazco #410 sample_pseudoabs K-means step improved geo_env_km_const approach, @sjevelazco #410 p_extra Now can handle binary maps plot suitability extrapolation values geographical environmental space, @sjevelazco 418 map_env_dist new function calculates environmental distance presences projection data. nearest Gower distance implemented (Domain algorithm), @sjevelazco 419 fit_dom new function fit validate Domain algorithm, @sjevelazco","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-136","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.6","title":"flexsdm 1.3.6","text":"occfilt_geo adapted test different values three methods @sjevelazco 386 occfilt_env now can filter several bins @sjevelazco 388 occfilt_select created test protocol written @sjevelazco 389 occfit_select included vignette website @sjevelazco 390 mean change sdm_predict handle 0 weight value weighted mean @sjevelazco 391 documentation occfilt_select improved @sjevelazco 392 possible tune ntree hyperparameter random forest algorithm @sjevelazco 393 correct_colinvar can used species points @sjevelazco 394 Update pkg_citation.md @mrose048 396 sdm_varimp added tested @mrose048 @sjevelazco 399 min change warning message calib_area @sjevelazco 400","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-134-5","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.4-5","title":"flexsdm 1.3.4-5","text":"min change interp function @sjevelazco 362 min change occfilt_geo @sjevelazco 364 Rlof removed dependencies @sjevelazco 365 min change occfilt_geo @sjevelazco 370 new argument occfilt_geo @sjevelazco 371 esm_ functions improved @sjevelazco 373 & 373 geographically constraint cell env_var argument correct_colinvar @sjevelazco 374 new argument correct_colinvar @sjevelazco 375 calib_area sped @sjevelazco 377 correct_colivar fixed improved, FA method @sjevelazco 383 occfilt_geo ‘defined’ method fixed @sjevelazco 384","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-134","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.4","title":"flexsdm 1.3.4","text":"possible restrict cell used perform collinearity reduction analysis geographical area smaller full extent environmental variables correct_clinvar() esm_ family function improved debugged occfilt_geo new argument “rep” control number o repetition filter occurrences","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-134-1","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.4","title":"flexsdm 1.3.4","text":"rgeos removed dependencies #356 New vignette use different tools explore model extrapolation truncate models added #352 Univariate combinatorial extrapolation metric added extra_eval. Minor bugs fixed project PCA time periods #351 Best grid raster names changed .part part_sblock part_sband Improvements correct_colinvar speed function using maxcell argument Improvements correct_colinvar project PCA time periods","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-133","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.3","title":"flexsdm 1.3.3","text":"Improvements correct_colinvar now possible sample rasters reduce machine memory speed process Improvements sdm_predict possible predict model chunks reduce machine memory p_extra, p_pdp, p_bpdp fixed New function p_bpdp Bivariate Partial Dependent Plot New function data_bpdp Calculate data construct bivariate partial dependence plots Improvements p_dpd Calculate data construct partial dependence plots","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-132","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.2","title":"flexsdm 1.3.2","text":"New function p_extra Graphical exploration extrapolation suitability pattern environmental geographical space New function p_pdp Partial Dependent Plot New function data_pdp Calculate data construct partial dependence plots","code":""},{"path":"https://sjevelazco.github.io/flexsdm/news/index.html","id":"flexsdm-131","dir":"Changelog","previous_headings":"","what":"flexsdm 1.3.1","title":"flexsdm 1.3.1","text":"New argument “crs” added function msdm_posteriori New argument “sp_name” sample_background sample_pseudoabs raster, flexclust, ape, sp removed dependencies Functions using CRS data improved codes possible use numeric value specify threshold msdm_posteriori extra_eval can use tibble SpatRaster object env_calib argument extra_truncate new argument define values used model truncation documentation improved. #","code":""}]
