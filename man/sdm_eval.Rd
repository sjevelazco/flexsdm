% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sdm_eval.R
\name{sdm_eval}
\alias{sdm_eval}
\title{Calculate different model performance metrics}
\usage{
sdm_eval(p, a, bg = NULL, thr = NULL)
}
\arguments{
\item{p}{numeric. Predicted suitability for presences}

\item{a}{numeric. Predicted suitability for absences}

\item{bg}{numeric. Predicted suitability for background points, used for BOYCE metric.
If not provided (NULL), the Boyce index will be calculated using absence data instead.
\strong{Note:} Using absence data for the Boyce index is not standard practice and may result in inflated performance values. It is highly recommended to provide background points for a correct calculation.
The Boyce index is calculated using the \code{boyce} function, which is an adaptation of the method implemented in the \code{ecospat} package.}

\item{thr}{character. Threshold criterion used to get binary suitability values (i.e. 0,1).
Used for threshold-dependent performance metrics.
It is possible to use more than one threshold type.
A vector must be provided for this argument. The following threshold criteria are available:
\itemize{
\item lpt: The highest threshold at which there is no omission.
\item equal_sens_spec: Threshold at which the Sensitivity and Specificity are equal.
\item max_sens_spec: Threshold at which the sum of the Sensitivity and Specificity
is the highest (aka threshold that maximizes the TSS).
\item max_jaccard: The threshold at which the Jaccard index is the highest.
\item max_sorensen: The threshold at which the Sorensen index is the highest.
\item max_fpb: The threshold at which FPB (F-measure on presence-background data) is the highest.
\item sensitivity: Threshold based on a specified Sensitivity value.
Usage thr = c('sensitivity', sens='0.6') or thr = c('sensitivity'). 'sens' refers
to Sensitivity value. If a sensitivity value is not specified, the
default value is 0.9
}
If more than one threshold type is used, concatenate threshold types,
e.g., thr=c('lpt', 'max_sens_spec', 'max_jaccard'), or thr=c('lpt', 'max_sens_spec',
'sensitivity', sens='0.8'), or thr=c('lpt', 'max_sens_spec', 'sensitivity').
Function will use all thresholds if no threshold type is specified}
}
\value{
a tibble with next columns
\itemize{
\item threshold: threshold names
\item thr_value: threshold values
\item n_presences: number of presences
\item n_absences: number of absences
\item from TPR to CRPS: performance metrics
}
}
\description{
This function calculates threshold dependent and independent model performance
metrics.
}
\details{
This function is used for evaluating different models approaches base on the combination
of presence-absences or presence-pseudo-absences and background point data and
suitability predicted by any model or flexsdm modeling function families (fit_, esm_, and tune_.)
\subsection{Performance Metrics Formulas}{

It calculates the next performance metric:\tabular{lcr}{
   Performance metric \tab Threshold dependent \tab Values ranges \cr
   TPR (True Positive Rate, also called Sensitivity) \tab yes \tab 0 - 1 \cr
   TNR (True Negative Rate, also called Specificity) \tab yes \tab 0 - 1 \cr
   W_TPR_TNR (Weighted TPR-TNR; Li et al. 2020) \tab yes \tab 0 - 1 \cr
   SORENSEN \tab yes \tab 0 - 1 \cr
   JACCARD \tab yes \tab 0 - 1 \cr
   FPB (F-measure on presence-background) \tab yes \tab 0 - 2 \cr
   OR (Omission Rate) \tab yes \tab 0 - 1 \cr
   TSS (True Skill Statistic) \tab yes \tab -1 - 1 \cr
   KAPPA \tab yes \tab 0 - 1 \cr
   MCC (Matthews Correlation Coefficient; Matthews 1975) \tab yes \tab -1 - 1 (1 is best) \cr
   AUC (Area Under Curve) \tab no \tab 0 - 1 \cr
   BOYCE  (continuous Boyce index)* \tab no \tab -1 - 1 \cr
   IMAE (Inverse Mean Absolute Error)** \tab no \tab 0 - 1 \cr
   CRPS (Continuous Ranked Probability Score based on Brier Score, Brier 1950)** \tab no \tab 0 - 1 \cr
}


\* The continuous Boyce index is calculated based on presences and background points. If background points are not provided, it will be calculated using presences and absences, which is not standard and may lead to misleading results. The code for calculating this metric is an adaptation of the \code{ecospat} package (see \code{\link[=boyce_]{boyce_()}}).

\** IMAE and CRPS are calculated as 1-(Mean Absolute Error) and 1-(CRPS), respectively, in order to be consistent with the other
metrics where the higher the value of a given performance metric, the greater the model's.

To define the formulas, the following components of the confusion matrix are used:
\itemize{
\item \code{tp}: True Positives (presences correctly predicted as presences)
\item \code{tn}: True Negatives (absences correctly predicted as absences)
\item \code{fp}: False Positives (absences incorrectly predicted as presences)
\item \code{fn}: False Negatives (presences incorrectly predicted as absences)
\item \code{np}: Number of presences (\code{length(p)})
\item \code{na}: Number of absences (\code{length(a)})
}

The formulas are:
\itemize{
\item \strong{TPR (Sensitivity)}: \deqn{TPR = \frac{tp}{tp + fn}}{TPR = tp / (tp + fn)}
\item \strong{TNR (Specificity)}: \deqn{TNR = \frac{tn}{tn + fp}}{TNR = tn / (tn + fp)}
\item \strong{W_TPR_TNR} (Li et al. 2020): \deqn{W\_TPR\_TNR = w \cdot TPR + (1-w) \cdot TNR}{W_TPR_TNR = w * TPR + (1-w) * TNR}, where \deqn{w = \frac{na}{na + np}}{w = na / (na + np)}
\item \strong{SORENSEN}: \deqn{Sorensen = \frac{2 \cdot tp}{fn + 2 \cdot tp + fp}}{Sorensen = 2*tp / (fn + 2*tp + fp)}
\item \strong{JACCARD}: \deqn{Jaccard = \frac{tp}{fn + tp + fp}}{Jaccard = tp / (fn + tp + fp)}
\item \strong{FPB}: \deqn{FPB = 2 \cdot Jaccard}{FPB = 2 * Jaccard}
\item \strong{OR}: \deqn{OR = 1 - TPR}{OR = 1 - TPR}
\item \strong{TSS}: \deqn{TSS = TPR + TNR - 1}{TSS = TPR + TNR - 1}
\item \strong{KAPPA}: \deqn{KAPPA = \frac{Pr(a) - Pr(e)}{1 - Pr(e)}}{KAPPA = (Pr(a) - Pr(e)) / (1 - Pr(e))}, where \deqn{Pr(a) = \frac{tp+tn}{tp+tn+fp+fn}}{Pr(a) = (tp+tn)/(tp+tn+fp+fn)} and \deqn{Pr(e) = \frac{(tp+fp)(tp+fn) + (fn+tn)(fp+tn)}{(tp+tn+fp+fn)^2}}{Pr(e) = ((tp+fp)*(tp+fn) + (fn+tn)*(fp+tn))/(tp+tn+fp+fn)^2}
\item \strong{MCC} (Matthews 1975): \deqn{MCC = \frac{(tp \cdot tn) - (fp \cdot fn)}{\sqrt{(tp+fp)(tp+fn)(tn+fp)(tn+fn)}}}{MCC = (tp*tn - fp*fn) / sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))}
\item \strong{AUC}: Calculated as the Wilcoxon-Mann-Whitney U statistic, which is equivalent to the area under the ROC curve.
\item \strong{BOYCE}: The continuous Boyce index, which measures how model predictions differ from a random distribution of observed presences across the prediction gradient.
\item \strong{CRPS} (Brier 1950): For binary outcomes, this is calculated as \deqn{1 - \frac{\sum(predicted - observed)^2}{N}}{1 - (sum(predicted - observed)^2/N)}, which is 1 minus the Brier Score.
\item \strong{IMAE}: \deqn{IMAE = 1 - \frac{\sum|predicted - observed|}{N}}{IMAE = 1 - (sum|predicted - observed|/N)}, where N is the total number of records.
}
}
}
\examples{
\dontrun{
require(dplyr)

set.seed(0)
p <- rnorm(50, mean = 0.7, sd = 0.3) \%>\% abs()
p[p > 1] <- 1
p[p < 0] <- 0

set.seed(0)
a <- rnorm(50, mean = 0.3, sd = 0.2) \%>\% abs()
a[a > 1] <- 1
a[a < 0] <- 0

set.seed(0)
backg <- rnorm(1000, mean = 0.4, sd = 0.4) \%>\% abs()
backg[backg > 1] <- 1
backg[backg < 0] <- 0

# Function use without threshold specification
e <- sdm_eval(p, a)
e

# Function use with threshold specification
sdm_eval(p, a, thr = "max_sorensen")
sdm_eval(p, a, thr = c("lpt", "max_sens_spec", "max_jaccard"))
sdm_eval(p, a, thr = c("lpt", "max_sens_spec", "sensitivity"))
sdm_eval(p, a, thr = c("lpt", "max_sens_spec", "sensitivity", sens = "0.95"))

# Use of bg argument (it will only be used for calculating BOYCE index)
sdm_eval(p, a, thr = "max_sens_spec")
sdm_eval(p, a, thr = c("max_sens_spec"), bg = backg)

# If background will be used to calculate all other metrics
# background values can be used in "a" argument
sdm_eval(p, backg, thr = "max_sens_spec")
}
}
\references{
\itemize{
\item Brier GW. (1950) Verification of forecasts expressed in terms of probability. Monthly Weather Review 78(1): 1–3. https://doi.org/10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2
\item Li, J., Liu, H., & Li, L. (2020). A novel performance metric for imbalanced learning and its application in credit default prediction. Expert Systems with Applications, 152, 113382. https://doi.org/10.1016/j.eswa.2020.113382
\item Matthews BW. (1975) Comparison of the predicted and observed secondary structure of T4 phage lysozyme. Biochim Biophys Acta (BBA) Protein Struct. 405(2):442–51. https://doi.org/10.1016/0005-2795(75)90109-9
}
}
